{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # Numpy concat\n",
    "    return np.concatenate((embeddings1, embeddings2), axis=1)\n",
    "\n",
    "def concat_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    return np.concatenate((embeddings1, embeddings2, embeddings3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_concat_dynahate_train = concat_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_concat_dynahate_dev = concat_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_concat_dynahate_test = concat_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_dynahate_train = concat_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_concat_dynahate_dev = concat_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_concat_dynahate_test = concat_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_dynahate_train = concat_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_concat_dynahate_dev = concat_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_concat_dynahate_test = concat_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_dynahate_train = concat_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_dynahate_dev = concat_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_dynahate_test = concat_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_concat_olid_train = concat_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_concat_olid_dev = concat_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_concat_olid_test = concat_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_olid_train = concat_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_concat_olid_dev = concat_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_concat_olid_test = concat_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_olid_train = concat_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_concat_olid_dev = concat_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_concat_olid_test = concat_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_olid_train = concat_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_olid_dev = concat_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_olid_test = concat_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_concat_latenthatred_train = concat_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_concat_latenthatred_dev = concat_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_concat_latenthatred_test = concat_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_latenthatred_train = concat_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_concat_latenthatred_dev = concat_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_concat_latenthatred_test = concat_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_latenthatred_train = concat_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_concat_latenthatred_dev = concat_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_concat_latenthatred_test = concat_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_latenthatred_train = concat_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_latenthatred_dev = concat_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_latenthatred_test = concat_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=7)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6930639585133967\n",
      "Accuracy Test:  0.6643203883495146\n",
      "Weighted F1 Train Dev:  0.6889238428969063\n",
      "Weighted F1 Test:  0.659219421651573\n",
      "Macro F1 Train Dev:  0.6851662233230584\n",
      "Macro F1 Test:  0.6528470428337239\n",
      "Micro F1 Train Dev:  0.6930639585133967\n",
      "Micro F1 Test:  0.6643203883495146\n",
      "Weighted Recall Train Dev:  0.6930639585133967\n",
      "Weighted Recall Test:  0.6643203883495146\n",
      "Macro Recall Train Dev:  0.6850186603671318\n",
      "Macro Recall Test:  0.6526177905767538\n",
      "Micro Recall Train Dev:  0.6930639585133967\n",
      "Micro Recall Test:  0.6643203883495146\n",
      "Confusion Matrix Train Dev: \n",
      "[[ 9898  7219]\n",
      " [ 4145 15762]]\n",
      "Confusion Matrix Test: \n",
      "[[ 994  858]\n",
      " [ 525 1743]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_dynahate_train_dev = np.concatenate((bert_bertweet_concat_dynahate_train, bert_bertweet_concat_dynahate_dev))\n",
    "bert_bertweet_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_dynahate_train_dev, bert_bertweet_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_concat_dynahate_seed_7\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_dynahate_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7037864680322781\n",
      "Accuracy Test:  0.6949720670391062\n",
      "Weighted F1 Train Dev:  0.6719729008101402\n",
      "Weighted F1 Test:  0.6597402541673847\n",
      "Macro F1 Train Dev:  0.46249873677724196\n",
      "Macro F1 Test:  0.4473027273200441\n",
      "Micro F1 Train Dev:  0.7037864680322781\n",
      "Micro F1 Test:  0.6949720670391062\n",
      "Weighted Recall Train Dev:  0.7037864680322781\n",
      "Weighted Recall Test:  0.6949720670391062\n",
      "Macro Recall Train Dev:  0.4584016043001567\n",
      "Macro Recall Test:  0.44483418305840733\n",
      "Micro Recall Train Dev:  0.7037864680322781\n",
      "Micro Recall Test:  0.6949720670391062\n",
      "Confusion Matrix Train Dev: \n",
      "[[8942  992   11]\n",
      " [2966 2369   12]\n",
      " [ 442  349   27]]\n",
      "Confusion Matrix Test: \n",
      "[[3017  328    1]\n",
      " [1041  707    5]\n",
      " [ 143  120    8]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_latenthatred_train_dev = np.concatenate((bert_bertweet_concat_latenthatred_train, bert_bertweet_concat_latenthatred_dev))\n",
    "bert_bertweet_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_latenthatred_train_dev, bert_bertweet_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_concat_latenthatred_seed_7\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_latenthatred_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7719788519637463\n",
      "Accuracy Test:  0.8162790697674419\n",
      "Weighted F1 Train Dev:  0.7651286465424271\n",
      "Weighted F1 Test:  0.8021860760685957\n",
      "Macro F1 Train Dev:  0.7288772614760904\n",
      "Macro F1 Test:  0.739914708562066\n",
      "Micro F1 Train Dev:  0.7719788519637462\n",
      "Micro F1 Test:  0.8162790697674419\n",
      "Weighted Recall Train Dev:  0.7719788519637463\n",
      "Weighted Recall Test:  0.8162790697674419\n",
      "Macro Recall Train Dev:  0.7191438708350473\n",
      "Macro Recall Test:  0.7168010752688172\n",
      "Micro Recall Train Dev:  0.7719788519637463\n",
      "Micro Recall Test:  0.8162790697674419\n",
      "Confusion Matrix Train Dev: \n",
      "[[7750 1090]\n",
      " [1929 2471]]\n",
      "Confusion Matrix Test: \n",
      "[[584  36]\n",
      " [122 118]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_olid_train_dev = np.concatenate((bert_bertweet_concat_olid_train, bert_bertweet_concat_olid_dev))\n",
    "bert_bertweet_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_olid_train_dev, bert_bertweet_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_concat_olid_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_olid_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7330650388936906\n",
      "Accuracy Test:  0.6990291262135923\n",
      "Weighted F1 Train Dev:  0.7303935024877725\n",
      "Weighted F1 Test:  0.6962307600298425\n",
      "Macro F1 Train Dev:  0.7274439233138464\n",
      "Macro F1 Test:  0.6912980467567924\n",
      "Micro F1 Train Dev:  0.7330650388936906\n",
      "Micro F1 Test:  0.6990291262135923\n",
      "Weighted Recall Train Dev:  0.7330650388936906\n",
      "Weighted Recall Test:  0.6990291262135923\n",
      "Macro Recall Train Dev:  0.7263678790843157\n",
      "Macro Recall Test:  0.6900857455213107\n",
      "Micro Recall Train Dev:  0.7330650388936906\n",
      "Micro Recall Test:  0.6990291262135923\n",
      "Confusion Matrix Train Dev: \n",
      "[[10912  6205]\n",
      " [ 3678 16229]]\n",
      "Confusion Matrix Test: \n",
      "[[1114  738]\n",
      " [ 502 1766]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_dynahate_train_dev = np.concatenate((bert_hatebert_concat_dynahate_train, bert_hatebert_concat_dynahate_dev))\n",
    "bert_hatebert_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_dynahate_train_dev, bert_hatebert_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_concat_dynahate_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_dynahate_seed_7\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6980757293606455\n",
      "Accuracy Test:  0.6893854748603352\n",
      "Weighted F1 Train Dev:  0.6626336263595646\n",
      "Weighted F1 Test:  0.6506618387495098\n",
      "Macro F1 Train Dev:  0.48464289170510505\n",
      "Macro F1 Test:  0.46431753731155334\n",
      "Micro F1 Train Dev:  0.6980757293606455\n",
      "Micro F1 Test:  0.6893854748603352\n",
      "Weighted Recall Train Dev:  0.6980757293606455\n",
      "Weighted Recall Test:  0.6893854748603352\n",
      "Macro Recall Train Dev:  0.46755289076842615\n",
      "Macro Recall Test:  0.4516471914149458\n",
      "Micro Recall Train Dev:  0.6980757293606455\n",
      "Micro Recall Test:  0.6893854748603352\n",
      "Confusion Matrix Train Dev: \n",
      "[[9156  758   31]\n",
      " [3275 2002   70]\n",
      " [ 427  303   88]]\n",
      "Confusion Matrix Test: \n",
      "[[3074  258   14]\n",
      " [1124  603   26]\n",
      " [ 151   95   25]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_latenthatred_train_dev = np.concatenate((bert_hatebert_concat_latenthatred_train, bert_hatebert_concat_latenthatred_dev))\n",
    "bert_hatebert_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_latenthatred_train_dev, bert_hatebert_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_concat_latenthatred_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_latenthatred_seed_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7692598187311178\n",
      "Accuracy Test:  0.7941860465116279\n",
      "Weighted F1 Train Dev:  0.7601741571776652\n",
      "Weighted F1 Test:  0.7739632222552065\n",
      "Macro F1 Train Dev:  0.721496940209948\n",
      "Macro F1 Test:  0.6993547444159816\n",
      "Micro F1 Train Dev:  0.7692598187311178\n",
      "Micro F1 Test:  0.7941860465116279\n",
      "Weighted Recall Train Dev:  0.7692598187311178\n",
      "Weighted Recall Test:  0.7941860465116279\n",
      "Macro Recall Train Dev:  0.710258638420403\n",
      "Macro Recall Test:  0.678494623655914\n",
      "Micro Recall Train Dev:  0.7692598187311178\n",
      "Micro Recall Test:  0.7941860465116279\n",
      "Confusion Matrix Train Dev: \n",
      "[[7834 1006]\n",
      " [2049 2351]]\n",
      "Confusion Matrix Test: \n",
      "[[583  37]\n",
      " [140 100]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_olid_train_dev = np.concatenate((bert_hatebert_concat_olid_train, bert_hatebert_concat_olid_dev))\n",
    "bert_hatebert_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_olid_train_dev, bert_hatebert_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_concat_olid_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_olid_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.746542783059637\n",
      "Accuracy Test:  0.7075242718446602\n",
      "Weighted F1 Train Dev:  0.7449912898567735\n",
      "Weighted F1 Test:  0.7060459283763534\n",
      "Macro F1 Train Dev:  0.742586475392335\n",
      "Macro F1 Test:  0.7019184727869867\n",
      "Micro F1 Train Dev:  0.7465427830596371\n",
      "Micro F1 Test:  0.7075242718446602\n",
      "Weighted Recall Train Dev:  0.746542783059637\n",
      "Weighted Recall Test:  0.7075242718446602\n",
      "Macro Recall Train Dev:  0.741410739819814\n",
      "Macro Recall Test:  0.7008225056281212\n",
      "Micro Recall Train Dev:  0.746542783059637\n",
      "Micro Recall Test:  0.7075242718446602\n",
      "Confusion Matrix Train Dev: \n",
      "[[11525  5592]\n",
      " [ 3792 16115]]\n",
      "Confusion Matrix Test: \n",
      "[[1175  677]\n",
      " [ 528 1740]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_dynahate_train_dev = np.concatenate((hatebert_bertweet_concat_dynahate_train, hatebert_bertweet_concat_dynahate_dev))\n",
    "hatebert_bertweet_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_dynahate_train_dev, hatebert_bertweet_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_concat_dynahate_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_dynahate_seed_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7121663563004346\n",
      "Accuracy Test:  0.6951582867783985\n",
      "Weighted F1 Train Dev:  0.6822338779187935\n",
      "Weighted F1 Test:  0.6610959299216783\n",
      "Macro F1 Train Dev:  0.4742761381424028\n",
      "Macro F1 Test:  0.44255708316619535\n",
      "Micro F1 Train Dev:  0.7121663563004346\n",
      "Micro F1 Test:  0.6951582867783985\n",
      "Weighted Recall Train Dev:  0.7121663563004346\n",
      "Weighted Recall Test:  0.6951582867783985\n",
      "Macro Recall Train Dev:  0.46822627871811906\n",
      "Macro Recall Test:  0.44335320751495616\n",
      "Micro Recall Train Dev:  0.7121663563004346\n",
      "Micro Recall Test:  0.6951582867783985\n",
      "Confusion Matrix Train Dev: \n",
      "[[8953  982   10]\n",
      " [2854 2488    5]\n",
      " [ 392  394   32]]\n",
      "Confusion Matrix Test: \n",
      "[[3001  338    7]\n",
      " [1022  727    4]\n",
      " [ 134  132    5]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_latenthatred_train_dev = np.concatenate((hatebert_bertweet_concat_latenthatred_train, hatebert_bertweet_concat_latenthatred_dev))\n",
    "hatebert_bertweet_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_latenthatred_train_dev, hatebert_bertweet_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_concat_latenthatred_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_latenthatred_seed_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7808912386706949\n",
      "Accuracy Test:  0.7988372093023256\n",
      "Weighted F1 Train Dev:  0.7728645070903745\n",
      "Weighted F1 Test:  0.7836455029687682\n",
      "Macro F1 Train Dev:  0.7366830977333971\n",
      "Macro F1 Test:  0.7157296393599235\n",
      "Micro F1 Train Dev:  0.7808912386706949\n",
      "Micro F1 Test:  0.7988372093023256\n",
      "Weighted Recall Train Dev:  0.7808912386706949\n",
      "Weighted Recall Test:  0.7988372093023256\n",
      "Macro Recall Train Dev:  0.7250190250925546\n",
      "Macro Recall Test:  0.6957661290322581\n",
      "Micro Recall Train Dev:  0.7808912386706949\n",
      "Micro Recall Test:  0.7988372093023256\n",
      "Confusion Matrix Train Dev: \n",
      "[[7882  958]\n",
      " [1943 2457]]\n",
      "Confusion Matrix Test: \n",
      "[[576  44]\n",
      " [129 111]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_olid_train_dev = np.concatenate((hatebert_bertweet_concat_olid_train, hatebert_bertweet_concat_olid_dev))\n",
    "hatebert_bertweet_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_olid_train_dev, hatebert_bertweet_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_concat_olid_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_olid_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7464347450302506\n",
      "Accuracy Test:  0.7048543689320388\n",
      "Weighted F1 Train Dev:  0.7436027907962717\n",
      "Weighted F1 Test:  0.7023928932461856\n",
      "Macro F1 Train Dev:  0.7406958179070879\n",
      "Macro F1 Test:  0.6976957653318968\n",
      "Micro F1 Train Dev:  0.7464347450302505\n",
      "Micro F1 Test:  0.7048543689320388\n",
      "Weighted Recall Train Dev:  0.7464347450302506\n",
      "Weighted Recall Test:  0.7048543689320388\n",
      "Macro Recall Train Dev:  0.7394229694926063\n",
      "Macro Recall Test:  0.6964166676189715\n",
      "Micro Recall Train Dev:  0.7464347450302506\n",
      "Micro Recall Test:  0.7048543689320388\n",
      "Confusion Matrix Train Dev: \n",
      "[[11064  6053]\n",
      " [ 3335 16572]]\n",
      "Confusion Matrix Test: \n",
      "[[1135  717]\n",
      " [ 499 1769]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_concat_dynahate_train, bert_hatebert_bertweet_concat_dynahate_dev))\n",
    "bert_bertweet_hatebert_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_dynahate_train_dev, bert_bertweet_hatebert_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_concat_dynahate_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_dynahate_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.716139044072005\n",
      "Accuracy Test:  0.7018621973929237\n",
      "Weighted F1 Train Dev:  0.7025819285794722\n",
      "Weighted F1 Test:  0.6874450592515028\n",
      "Macro F1 Train Dev:  0.544814954720557\n",
      "Macro F1 Test:  0.5346778759197685\n",
      "Micro F1 Train Dev:  0.716139044072005\n",
      "Micro F1 Test:  0.7018621973929237\n",
      "Weighted Recall Train Dev:  0.716139044072005\n",
      "Weighted Recall Test:  0.7018621973929237\n",
      "Macro Recall Train Dev:  0.5241011396766605\n",
      "Macro Recall Test:  0.5121547608355986\n",
      "Micro Recall Train Dev:  0.716139044072005\n",
      "Micro Recall Test:  0.7018621973929237\n",
      "Confusion Matrix Train Dev: \n",
      "[[8530 1332   83]\n",
      " [2359 2860  128]\n",
      " [ 301  370  147]]\n",
      "Confusion Matrix Test: \n",
      "[[2845  479   22]\n",
      " [ 839  873   41]\n",
      " [  94  126   51]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_concat_latenthatred_train, bert_hatebert_bertweet_concat_latenthatred_dev))\n",
    "bert_bertweet_hatebert_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_latenthatred_train_dev, bert_bertweet_hatebert_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_concat_latenthatred_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_latenthatred_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7768126888217523\n",
      "Accuracy Test:  0.8034883720930233\n",
      "Weighted F1 Train Dev:  0.7715007940322363\n",
      "Weighted F1 Test:  0.7908967947521313\n",
      "Macro F1 Train Dev:  0.7373693716509757\n",
      "Macro F1 Test:  0.7270994695582782\n",
      "Micro F1 Train Dev:  0.7768126888217523\n",
      "Micro F1 Test:  0.8034883720930233\n",
      "Weighted Recall Train Dev:  0.7768126888217523\n",
      "Weighted Recall Test:  0.8034883720930233\n",
      "Macro Recall Train Dev:  0.7288137597696421\n",
      "Macro Recall Test:  0.7079301075268817\n",
      "Micro Recall Train Dev:  0.7768126888217523\n",
      "Micro Recall Test:  0.8034883720930233\n",
      "Confusion Matrix Train Dev: \n",
      "[[7708 1132]\n",
      " [1823 2577]]\n",
      "Confusion Matrix Test: \n",
      "[[573  47]\n",
      " [122 118]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_olid_train_dev = np.concatenate((bert_hatebert_bertweet_concat_olid_train, bert_hatebert_bertweet_concat_olid_dev))\n",
    "bert_bertweet_hatebert_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_olid_train_dev, bert_bertweet_hatebert_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_concat_olid_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_olid_seed_7\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
