{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet_dynahate_train_embeddings = reshape_embeddings(bertweet_dynahate_train_embeddings)\n",
    "bertweet_dynahate_dev_embeddings = reshape_embeddings(bertweet_dynahate_dev_embeddings)\n",
    "bertweet_dynahate_test_embeddings = reshape_embeddings(bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bertweet_latenthatred_train_embeddings = reshape_embeddings(bertweet_latenthatred_train_embeddings)\n",
    "bertweet_latenthatred_dev_embeddings = reshape_embeddings(bertweet_latenthatred_dev_embeddings)\n",
    "bertweet_latenthatred_test_embeddings = reshape_embeddings(bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bertweet_olid_train_embeddings = reshape_embeddings(bertweet_olid_train_embeddings)\n",
    "bertweet_olid_dev_embeddings = reshape_embeddings(bertweet_olid_dev_embeddings)\n",
    "bertweet_olid_test_embeddings = reshape_embeddings(bertweet_olid_test_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7304181071737251\n",
      "Accuracy Test:  0.6509708737864077\n",
      "Weighted F1 Train Dev:  0.7287511364287667\n",
      "Weighted F1 Test:  0.6498670057737984\n",
      "Macro F1 Train Dev:  0.7261858587793271\n",
      "Macro F1 Test:  0.645364955840019\n",
      "Micro F1 Train Dev:  0.7304181071737251\n",
      "Micro F1 Test:  0.6509708737864077\n",
      "Weighted Recall Train Dev:  0.7304181071737251\n",
      "Weighted Recall Test:  0.6509708737864077\n",
      "Macro Recall Train Dev:  0.72516736475367\n",
      "Macro Recall Test:  0.6448503167365658\n",
      "Micro Recall Train Dev:  0.7304181071737251\n",
      "Micro Recall Test:  0.6509708737864077\n",
      "Confusion Matrix Train Dev: \n",
      "[[11220  5897]\n",
      " [ 4084 15823]]\n",
      "Confusion Matrix Test: \n",
      "[[1082  770]\n",
      " [ 668 1600]]\n"
     ]
    }
   ],
   "source": [
    "bertweet_dynahate_train_dev = np.concatenate((bertweet_dynahate_train_embeddings, bertweet_dynahate_dev_embeddings))\n",
    "\n",
    "grid_results = gridsearch.fit(bertweet_dynahate_train_dev, dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bertweet_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bertweet_dynahate_test_embeddings)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bertweet_dynahate\")\n",
    "save_model(mlp, \"Saves/bertweet_dynahate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6893234016139044\n",
      "Accuracy Test:  0.6851024208566108\n",
      "Weighted F1 Train Dev:  0.6622075764139792\n",
      "Weighted F1 Test:  0.6567015249706182\n",
      "Macro F1 Train Dev:  0.46226313050038875\n",
      "Macro F1 Test:  0.45128273623264553\n",
      "Micro F1 Train Dev:  0.6893234016139044\n",
      "Micro F1 Test:  0.6851024208566108\n",
      "Weighted Recall Train Dev:  0.6893234016139044\n",
      "Weighted Recall Test:  0.6851024208566108\n",
      "Macro Recall Train Dev:  0.4559170290340389\n",
      "Macro Recall Test:  0.4470656977873792\n",
      "Micro Recall Train Dev:  0.6893234016139044\n",
      "Micro Recall Test:  0.6851024208566108\n",
      "Confusion Matrix Train Dev: \n",
      "[[8644 1280   21]\n",
      " [2897 2424   26]\n",
      " [ 445  336   37]]\n",
      "Confusion Matrix Test: \n",
      "[[2904  438    4]\n",
      " [ 981  765    7]\n",
      " [ 143  118   10]]\n"
     ]
    }
   ],
   "source": [
    "bertweet_latenthatred_train_dev = np.concatenate((bertweet_latenthatred_train_embeddings, bertweet_latenthatred_dev_embeddings))\n",
    "\n",
    "grid_results = gridsearch.fit(bertweet_latenthatred_train_dev, latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bertweet_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bertweet_latenthatred\")\n",
    "save_model(mlp, \"Saves/bertweet_latenthatred\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7803625377643505\n",
      "Accuracy Test:  0.7953488372093023\n",
      "Weighted F1 Train Dev:  0.764639622098148\n",
      "Weighted F1 Test:  0.7720922348658694\n",
      "Macro F1 Train Dev:  0.7218640427121553\n",
      "Macro F1 Test:  0.6945702270544268\n",
      "Micro F1 Train Dev:  0.7803625377643505\n",
      "Micro F1 Test:  0.7953488372093023\n",
      "Weighted Recall Train Dev:  0.7803625377643505\n",
      "Weighted Recall Test:  0.7953488372093023\n",
      "Macro Recall Train Dev:  0.7059594816947758\n",
      "Macro Recall Test:  0.6729166666666666\n",
      "Micro Recall Train Dev:  0.7803625377643505\n",
      "Micro Recall Test:  0.7953488372093023\n",
      "Confusion Matrix Train Dev: \n",
      "[[8202  638]\n",
      " [2270 2130]]\n",
      "Confusion Matrix Test: \n",
      "[[589  31]\n",
      " [145  95]]\n"
     ]
    }
   ],
   "source": [
    "bertweet_olid_train_dev = np.concatenate((bertweet_olid_train_embeddings, bertweet_olid_dev_embeddings))\n",
    "\n",
    "grid_results = gridsearch.fit(bertweet_olid_train_dev, olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bertweet_olid_train_dev)\n",
    "test_preds = mlp.predict(bertweet_olid_test_embeddings)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bertweet_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/bertweet_olid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
