{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 3\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # Numpy concat\n",
    "    return np.concatenate((embeddings1, embeddings2), axis=1)\n",
    "\n",
    "def concat_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    return np.concatenate((embeddings1, embeddings2, embeddings3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_concat_dynahate_train = concat_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_concat_dynahate_dev = concat_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_concat_dynahate_test = concat_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_dynahate_train = concat_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_concat_dynahate_dev = concat_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_concat_dynahate_test = concat_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_dynahate_train = concat_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_concat_dynahate_dev = concat_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_concat_dynahate_test = concat_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_dynahate_train = concat_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_dynahate_dev = concat_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_dynahate_test = concat_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_concat_olid_train = concat_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_concat_olid_dev = concat_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_concat_olid_test = concat_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_olid_train = concat_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_concat_olid_dev = concat_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_concat_olid_test = concat_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_olid_train = concat_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_concat_olid_dev = concat_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_concat_olid_test = concat_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_olid_train = concat_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_olid_dev = concat_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_olid_test = concat_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_concat_latenthatred_train = concat_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_concat_latenthatred_dev = concat_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_concat_latenthatred_test = concat_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_latenthatred_train = concat_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_concat_latenthatred_dev = concat_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_concat_latenthatred_test = concat_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_latenthatred_train = concat_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_concat_latenthatred_dev = concat_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_concat_latenthatred_test = concat_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_latenthatred_train = concat_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_latenthatred_dev = concat_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_latenthatred_test = concat_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=3)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7392502160760588\n",
      "Accuracy Test:  0.6966019417475728\n",
      "Weighted F1 Train Dev:  0.7383882785867913\n",
      "Weighted F1 Test:  0.6954802067287899\n",
      "Macro F1 Train Dev:  0.736278799994637\n",
      "Macro F1 Test:  0.6914574328683267\n",
      "Micro F1 Train Dev:  0.7392502160760588\n",
      "Micro F1 Test:  0.6966019417475728\n",
      "Weighted Recall Train Dev:  0.7392502160760588\n",
      "Weighted Recall Test:  0.6966019417475728\n",
      "Macro Recall Train Dev:  0.735427522638797\n",
      "Macro Recall Test:  0.6906047516198703\n",
      "Micro Recall Train Dev:  0.7392502160760588\n",
      "Micro Recall Test:  0.6966019417475728\n",
      "Confusion Matrix Train Dev: \n",
      "[[11720  5397]\n",
      " [ 4257 15650]]\n",
      "Confusion Matrix Test: \n",
      "[[1169  683]\n",
      " [ 567 1701]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_dynahate_train_dev = np.concatenate((bert_bertweet_concat_dynahate_train, bert_bertweet_concat_dynahate_dev))\n",
    "bert_bertweet_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_dynahate_train_dev, bert_bertweet_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_concat_dynahate_seed_3\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_dynahate_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7251396648044692\n",
      "Accuracy Test:  0.7001862197392924\n",
      "Weighted F1 Train Dev:  0.7030304798019015\n",
      "Weighted F1 Test:  0.6749895484423731\n",
      "Macro F1 Train Dev:  0.5332021974849913\n",
      "Macro F1 Test:  0.49524250316720814\n",
      "Micro F1 Train Dev:  0.7251396648044692\n",
      "Micro F1 Test:  0.7001862197392924\n",
      "Weighted Recall Train Dev:  0.7251396648044692\n",
      "Weighted Recall Test:  0.7001862197392924\n",
      "Macro Recall Train Dev:  0.509099302110108\n",
      "Macro Recall Test:  0.47783338032052636\n",
      "Micro Recall Train Dev:  0.7251396648044692\n",
      "Micro Recall Test:  0.7001862197392924\n",
      "Confusion Matrix Train Dev: \n",
      "[[8933  979   33]\n",
      " [2644 2638   65]\n",
      " [ 374  333  111]]\n",
      "Confusion Matrix Test: \n",
      "[[2964  367   15]\n",
      " [ 956  766   31]\n",
      " [ 132  109   30]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_latenthatred_train_dev = np.concatenate((bert_bertweet_concat_latenthatred_train, bert_bertweet_concat_latenthatred_dev))\n",
    "bert_bertweet_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_latenthatred_train_dev, bert_bertweet_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_concat_latenthatred_seed_3\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_latenthatred_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7799848942598188\n",
      "Accuracy Test:  0.8116279069767441\n",
      "Weighted F1 Train Dev:  0.7745503621654941\n",
      "Weighted F1 Test:  0.7962661573432689\n",
      "Macro F1 Train Dev:  0.7407083951265028\n",
      "Macro F1 Test:  0.7314054366685946\n",
      "Micro F1 Train Dev:  0.7799848942598187\n",
      "Micro F1 Test:  0.8116279069767441\n",
      "Weighted Recall Train Dev:  0.7799848942598188\n",
      "Weighted Recall Test:  0.8116279069767441\n",
      "Macro Recall Train Dev:  0.731760078157137\n",
      "Macro Recall Test:  0.7084677419354839\n",
      "Micro Recall Train Dev:  0.7799848942598188\n",
      "Micro Recall Test:  0.8116279069767441\n",
      "Confusion Matrix Train Dev: \n",
      "[[7740 1100]\n",
      " [1813 2587]]\n",
      "Confusion Matrix Test: \n",
      "[[584  36]\n",
      " [126 114]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_olid_train_dev = np.concatenate((bert_bertweet_concat_olid_train, bert_bertweet_concat_olid_dev))\n",
    "bert_bertweet_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_olid_train_dev, bert_bertweet_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_concat_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7306341832324978\n",
      "Accuracy Test:  0.6910194174757281\n",
      "Weighted F1 Train Dev:  0.7272691370114065\n",
      "Weighted F1 Test:  0.6881968140171718\n",
      "Macro F1 Train Dev:  0.724059400615904\n",
      "Macro F1 Test:  0.6831573159967448\n",
      "Micro F1 Train Dev:  0.7306341832324977\n",
      "Micro F1 Test:  0.6910194174757281\n",
      "Weighted Recall Train Dev:  0.7306341832324978\n",
      "Weighted Recall Test:  0.6910194174757281\n",
      "Macro Recall Train Dev:  0.7231084480322546\n",
      "Macro Recall Test:  0.6820678155271388\n",
      "Micro Recall Train Dev:  0.7306341832324978\n",
      "Micro Recall Test:  0.6910194174757281\n",
      "Confusion Matrix Train Dev: \n",
      "[[10668  6449]\n",
      " [ 3524 16383]]\n",
      "Confusion Matrix Test: \n",
      "[[1099  753]\n",
      " [ 520 1748]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_dynahate_train_dev = np.concatenate((bert_hatebert_concat_dynahate_train, bert_hatebert_concat_dynahate_dev))\n",
    "bert_hatebert_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_dynahate_train_dev, bert_hatebert_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_concat_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_dynahate_seed_3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7145872129112353\n",
      "Accuracy Test:  0.6945996275605214\n",
      "Weighted F1 Train Dev:  0.6913444521392624\n",
      "Weighted F1 Test:  0.6689390929737381\n",
      "Macro F1 Train Dev:  0.5245345684962105\n",
      "Macro F1 Test:  0.4967820861264332\n",
      "Micro F1 Train Dev:  0.7145872129112353\n",
      "Micro F1 Test:  0.6945996275605214\n",
      "Weighted Recall Train Dev:  0.7145872129112353\n",
      "Weighted Recall Test:  0.6945996275605214\n",
      "Macro Recall Train Dev:  0.5016950593460093\n",
      "Macro Recall Test:  0.47827751746890607\n",
      "Micro Recall Train Dev:  0.7145872129112353\n",
      "Micro Recall Test:  0.6945996275605214\n",
      "Confusion Matrix Train Dev: \n",
      "[[8918  977   50]\n",
      " [2784 2475   88]\n",
      " [ 362  337  119]]\n",
      "Confusion Matrix Test: \n",
      "[[2965  364   17]\n",
      " [ 984  729   40]\n",
      " [ 127  108   36]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_latenthatred_train_dev = np.concatenate((bert_hatebert_concat_latenthatred_train, bert_hatebert_concat_latenthatred_dev))\n",
    "bert_hatebert_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_latenthatred_train_dev, bert_hatebert_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_concat_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_latenthatred_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7643504531722054\n",
      "Accuracy Test:  0.7930232558139535\n",
      "Weighted F1 Train Dev:  0.7576686153725429\n",
      "Weighted F1 Test:  0.7761442963401348\n",
      "Macro F1 Train Dev:  0.7205844155844157\n",
      "Macro F1 Test:  0.7048775785617891\n",
      "Micro F1 Train Dev:  0.7643504531722054\n",
      "Micro F1 Test:  0.7930232558139535\n",
      "Weighted Recall Train Dev:  0.7643504531722054\n",
      "Weighted Recall Test:  0.7930232558139535\n",
      "Macro Recall Train Dev:  0.7116618675442206\n",
      "Macro Recall Test:  0.6853494623655914\n",
      "Micro Recall Train Dev:  0.7643504531722054\n",
      "Micro Recall Test:  0.7930232558139535\n",
      "Confusion Matrix Train Dev: \n",
      "[[7680 1160]\n",
      " [1960 2440]]\n",
      "Confusion Matrix Test: \n",
      "[[576  44]\n",
      " [134 106]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_olid_train_dev = np.concatenate((bert_hatebert_concat_olid_train, bert_hatebert_concat_olid_dev))\n",
    "bert_hatebert_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_olid_train_dev, bert_hatebert_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_concat_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7356579515989629\n",
      "Accuracy Test:  0.7050970873786407\n",
      "Weighted F1 Train Dev:  0.7340662505677593\n",
      "Weighted F1 Test:  0.703925226901946\n",
      "Macro F1 Train Dev:  0.7315699909404084\n",
      "Macro F1 Test:  0.6999618613872709\n",
      "Micro F1 Train Dev:  0.7356579515989629\n",
      "Micro F1 Test:  0.7050970873786407\n",
      "Weighted Recall Train Dev:  0.7356579515989629\n",
      "Weighted Recall Test:  0.7050970873786407\n",
      "Macro Recall Train Dev:  0.7305067309850652\n",
      "Macro Recall Test:  0.69901407887369\n",
      "Micro Recall Train Dev:  0.7356579515989629\n",
      "Micro Recall Test:  0.7050970873786407\n",
      "Confusion Matrix Train Dev: \n",
      "[[11334  5783]\n",
      " [ 4004 15903]]\n",
      "Confusion Matrix Test: \n",
      "[[1183  669]\n",
      " [ 546 1722]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_dynahate_train_dev = np.concatenate((hatebert_bertweet_concat_dynahate_train, hatebert_bertweet_concat_dynahate_dev))\n",
    "hatebert_bertweet_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_dynahate_train_dev, hatebert_bertweet_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_concat_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_dynahate_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7229050279329609\n",
      "Accuracy Test:  0.7\n",
      "Weighted F1 Train Dev:  0.6968657885859495\n",
      "Weighted F1 Test:  0.6690922254544529\n",
      "Macro F1 Train Dev:  0.5191857263346688\n",
      "Macro F1 Test:  0.48006910738774405\n",
      "Micro F1 Train Dev:  0.7229050279329609\n",
      "Micro F1 Test:  0.7\n",
      "Weighted Recall Train Dev:  0.7229050279329609\n",
      "Weighted Recall Test:  0.7\n",
      "Macro Recall Train Dev:  0.49744219551794205\n",
      "Macro Recall Test:  0.4653851126240469\n",
      "Micro Recall Train Dev:  0.7229050279329609\n",
      "Micro Recall Test:  0.7\n",
      "Confusion Matrix Train Dev: \n",
      "[[9056  867   22]\n",
      " [2792 2496   59]\n",
      " [ 381  343   94]]\n",
      "Confusion Matrix Test: \n",
      "[[3019  316   11]\n",
      " [1018  717   18]\n",
      " [ 135  113   23]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_latenthatred_train_dev = np.concatenate((hatebert_bertweet_concat_latenthatred_train, hatebert_bertweet_concat_latenthatred_dev))\n",
    "hatebert_bertweet_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_latenthatred_train_dev, hatebert_bertweet_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_concat_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_latenthatred_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7669184290030211\n",
      "Accuracy Test:  0.7988372093023256\n",
      "Weighted F1 Train Dev:  0.7547002717653714\n",
      "Weighted F1 Test:  0.7806608213350501\n",
      "Macro F1 Train Dev:  0.7129705655075519\n",
      "Macro F1 Test:  0.7094543530096413\n",
      "Micro F1 Train Dev:  0.7669184290030211\n",
      "Micro F1 Test:  0.7988372093023256\n",
      "Weighted Recall Train Dev:  0.7669184290030211\n",
      "Weighted Recall Test:  0.7988372093023256\n",
      "Macro Recall Train Dev:  0.7002864047716989\n",
      "Macro Recall Test:  0.6881048387096774\n",
      "Micro Recall Train Dev:  0.7669184290030211\n",
      "Micro Recall Test:  0.7988372093023256\n",
      "Confusion Matrix Train Dev: \n",
      "[[7947  893]\n",
      " [2193 2207]]\n",
      "Confusion Matrix Test: \n",
      "[[582  38]\n",
      " [135 105]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_olid_train_dev = np.concatenate((hatebert_bertweet_concat_olid_train, hatebert_bertweet_concat_olid_dev))\n",
    "hatebert_bertweet_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_olid_train_dev, hatebert_bertweet_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_concat_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7490006482281764\n",
      "Accuracy Test:  0.7063106796116505\n",
      "Weighted F1 Train Dev:  0.7493358000358852\n",
      "Weighted F1 Test:  0.7070607910952764\n",
      "Macro F1 Train Dev:  0.7484444048561827\n",
      "Macro F1 Test:  0.7055888742217464\n",
      "Micro F1 Train Dev:  0.7490006482281764\n",
      "Micro F1 Test:  0.7063106796116505\n",
      "Weighted Recall Train Dev:  0.7490006482281764\n",
      "Weighted Recall Test:  0.7063106796116505\n",
      "Macro Recall Train Dev:  0.7497144496342767\n",
      "Macro Recall Test:  0.7085347457917652\n",
      "Micro Recall Train Dev:  0.7490006482281764\n",
      "Micro Recall Test:  0.7063106796116505\n",
      "Confusion Matrix Train Dev: \n",
      "[[12995  4122]\n",
      " [ 5171 14736]]\n",
      "Confusion Matrix Test: \n",
      "[[1353  499]\n",
      " [ 711 1557]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_concat_dynahate_train, bert_hatebert_bertweet_concat_dynahate_dev))\n",
    "bert_bertweet_hatebert_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_dynahate_train_dev, bert_bertweet_hatebert_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_concat_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_dynahate_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7225325884543762\n",
      "Accuracy Test:  0.7007448789571694\n",
      "Weighted F1 Train Dev:  0.70767207968422\n",
      "Weighted F1 Test:  0.6855103592132524\n",
      "Macro F1 Train Dev:  0.5144100443794969\n",
      "Macro F1 Test:  0.49109162611960366\n",
      "Micro F1 Train Dev:  0.7225325884543762\n",
      "Micro F1 Test:  0.7007448789571694\n",
      "Weighted Recall Train Dev:  0.7225325884543762\n",
      "Weighted Recall Test:  0.7007448789571694\n",
      "Macro Recall Train Dev:  0.5062601190152011\n",
      "Macro Recall Test:  0.4840777253071973\n",
      "Micro Recall Train Dev:  0.7225325884543762\n",
      "Micro Recall Test:  0.7007448789571694\n",
      "Confusion Matrix Train Dev: \n",
      "[[8294 1631   20]\n",
      " [2037 3289   21]\n",
      " [ 268  493   57]]\n",
      "Confusion Matrix Test: \n",
      "[[2752  584   10]\n",
      " [ 752  994    7]\n",
      " [  88  166   17]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_concat_latenthatred_train, bert_hatebert_bertweet_concat_latenthatred_dev))\n",
    "bert_bertweet_hatebert_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_latenthatred_train_dev, bert_bertweet_hatebert_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_concat_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_latenthatred_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7825528700906345\n",
      "Accuracy Test:  0.8034883720930233\n",
      "Weighted F1 Train Dev:  0.7689308972890205\n",
      "Weighted F1 Test:  0.7814413592402251\n",
      "Macro F1 Train Dev:  0.7281476476334803\n",
      "Macro F1 Test:  0.7073009620361251\n",
      "Micro F1 Train Dev:  0.7825528700906345\n",
      "Micro F1 Test:  0.8034883720930233\n",
      "Weighted Recall Train Dev:  0.7825528700906345\n",
      "Weighted Recall Test:  0.8034883720930233\n",
      "Macro Recall Train Dev:  0.7126794529000411\n",
      "Macro Recall Test:  0.6836693548387096\n",
      "Micro Recall Train Dev:  0.7825528700906345\n",
      "Micro Recall Test:  0.8034883720930233\n",
      "Confusion Matrix Train Dev: \n",
      "[[8142  698]\n",
      " [2181 2219]]\n",
      "Confusion Matrix Test: \n",
      "[[592  28]\n",
      " [141  99]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_olid_train_dev = np.concatenate((bert_hatebert_bertweet_concat_olid_train, bert_hatebert_bertweet_concat_olid_dev))\n",
    "bert_bertweet_hatebert_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_olid_train_dev, bert_bertweet_hatebert_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_concat_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_olid_seed_3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
