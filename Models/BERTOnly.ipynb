{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_embeddings(embeddings):\n",
    "    for i in range(len(embeddings)):\n",
    "        embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32924, 1, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_dynahate_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\HateSpeechModelCombination\\Models\\BERTOnly.ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/HateSpeechModelCombination/Models/BERTOnly.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# scaling embeddings for all the models with their respective datasets\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Desktop/HateSpeechModelCombination/Models/BERTOnly.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scaled_bert_dynahate_train_embeddings \u001b[39m=\u001b[39m reshape_embeddings(scaling_embeddings(bert_dynahate_train_embeddings))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/HateSpeechModelCombination/Models/BERTOnly.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m scaled_bert_dynahate_dev_embeddings \u001b[39m=\u001b[39m reshape_embeddings(scaling_embeddings(bert_dynahate_dev_embeddings))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/HateSpeechModelCombination/Models/BERTOnly.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m scaled_bert_dynahate_test_embeddings \u001b[39m=\u001b[39m reshape_embeddings(scaling_embeddings(bert_dynahate_test_embeddings))\n",
      "\u001b[1;32md:\\Desktop\\HateSpeechModelCombination\\Models\\BERTOnly.ipynb Cell 5\u001b[0m in \u001b[0;36mscaling_embeddings\u001b[1;34m(embeddings)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/HateSpeechModelCombination/Models/BERTOnly.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscaling_embeddings\u001b[39m(embeddings):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/HateSpeechModelCombination/Models/BERTOnly.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(embeddings)):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Desktop/HateSpeechModelCombination/Models/BERTOnly.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         embeddings[i] \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39;49mfit_transform(embeddings[i])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/HateSpeechModelCombination/Models/BERTOnly.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_data.py:975\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    972\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    974\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m--> 975\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    976\u001b[0m     X,\n\u001b[0;32m    977\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    978\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    979\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    980\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    981\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    982\u001b[0m )\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m    985\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:925\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    918\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    919\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m feature(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m a minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    921\u001b[0m             \u001b[39m%\u001b[39m (n_features, array\u001b[39m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    922\u001b[0m         )\n\u001b[0;32m    924\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 925\u001b[0m     array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(array, dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n\u001b[0;32m    927\u001b[0m \u001b[39mreturn\u001b[39;00m array\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# scaling embeddings for all the models with their respective datasets\n",
    "\n",
    "scaled_bert_dynahate_train_embeddings = reshape_embeddings(scaling_embeddings(bert_dynahate_train_embeddings))\n",
    "scaled_bert_dynahate_dev_embeddings = reshape_embeddings(scaling_embeddings(bert_dynahate_dev_embeddings))\n",
    "scaled_bert_dynahate_test_embeddings = reshape_embeddings(scaling_embeddings(bert_dynahate_test_embeddings))\n",
    "\n",
    "scaled_bert_latenthatred_train_embeddings = reshape_embeddings(scaling_embeddings(bert_latenthatred_train_embeddings))\n",
    "scaled_bert_latenthatred_dev_embeddings = reshape_embeddings(scaling_embeddings(bert_latenthatred_dev_embeddings))\n",
    "scaled_bert_latenthatred_test_embeddings = reshape_embeddings(scaling_embeddings(bert_latenthatred_test_embeddings))\n",
    "\n",
    "scaled_bert_olid_train_embeddings = reshape_embeddings(scaling_embeddings(bert_olid_train_embeddings))\n",
    "scaled_bert_olid_dev_embeddings = reshape_embeddings(scaling_embeddings(bert_olid_dev_embeddings))\n",
    "scaled_bert_olid_test_embeddings = reshape_embeddings(scaling_embeddings(bert_olid_test_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32924, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_bert_dynahate_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping embeddings for all the models with their respective datasets\n",
    "\n",
    "reshaped_bert_dynahate_train_embeddings = reshape_embeddings(bert_dynahate_train_embeddings)\n",
    "reshaped_bert_dynahate_test_embeddings = reshape_embeddings(bert_dynahate_test_embeddings)\n",
    "reshaped_bert_dynahate_dev_embeddings = reshape_embeddings(bert_dynahate_dev_embeddings)\n",
    "\n",
    "reshaped_bert_latenthatred_train_embeddings = reshape_embeddings(bert_latenthatred_train_embeddings)\n",
    "reshaped_bert_latenthatred_test_embeddings = reshape_embeddings(bert_latenthatred_test_embeddings)\n",
    "reshaped_bert_latenthatred_dev_embeddings = reshape_embeddings(bert_latenthatred_dev_embeddings)\n",
    "\n",
    "reshaped_bert_olid_train_embeddings = reshape_embeddings(bert_olid_train_embeddings)\n",
    "reshaped_bert_olid_test_embeddings = reshape_embeddings(bert_olid_test_embeddings)\n",
    "reshaped_bert_olid_dev_embeddings = reshape_embeddings(bert_olid_dev_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32924, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_bert_dynahate_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(256, 128), (256, 128, 64)],\n",
    "        \"activation\": [\"relu\", \"tanh\"],\n",
    "        \"solver\": [\"adam\", \"sgd\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "        # \"early_stopping\": [True]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DynaHate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(reshaped_bert_dynahate_train_embeddings, dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'hidden_layer_sizes': (256, 128),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_bertweet_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bert_bertweet_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bert_bertweet_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bert_bertweet_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bert_bertweet_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bert_bertweet_dynahate_train_embeddings.cpu(), dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_bertweet_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bert_bertweet_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bert_bertweet_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bert_bertweet_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bert_bertweet_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bert_bertweet_dynahate_train_embeddings.cpu(), dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bert_bertweet_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bert_bertweet_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bert_bertweet_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bert_bertweet_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bert_bertweet_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_prescaling_bert_bertweet_latenthatred_train_embeddings = scaling_embeddings(prescaling_bert_bertweet_latenthatred_train_embeddings)\n",
    "scaled_prescaling_bert_bertweet_latenthatred_dev_embeddings = scaling_embeddings(prescaling_bert_bertweet_latenthatred_dev_embeddings)\n",
    "scaled_prescaling_bert_bertweet_latenthatred_test_embeddings = scaling_embeddings(prescaling_bert_bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(prescaling_bert_bertweet_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_bertweet_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bert_bertweet_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bert_bertweet_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bert_bertweet_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bert_bertweet_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bert_bertweet_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_bertweet_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bert_bertweet_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bert_bertweet_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bert_bertweet_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bert_bertweet_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bert_bertweet_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bert_bertweet_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bert_bertweet_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bert_bertweet_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bert_bertweet_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bert_bertweet_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_prescaling_bert_bertweet_olid_train_embeddings = scaling_embeddings(prescaling_bert_bertweet_olid_train_embeddings)\n",
    "scaled_prescaling_bert_bertweet_olid_dev_embeddings = scaling_embeddings(prescaling_bert_bertweet_olid_dev_embeddings)\n",
    "scaled_prescaling_bert_bertweet_olid_test_embeddings = scaling_embeddings(prescaling_bert_bertweet_olid_test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(prescaling_bert_bertweet_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_bertweet_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"olid_bert_bertweet_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bert_bertweet_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bert_bertweet_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bert_bertweet_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bert_bertweet_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_bertweet_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"latenthatred_bert_bertweet_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bert_bertweet_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bert_bertweet_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bert_bertweet_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bert_bertweet_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bert_bertweet_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"olid_bert_bertweet_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bert_bertweet_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bert_bertweet_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bert_bertweet_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_prescaling_bert_hatebert_dynahate_train_embeddings = scaling_embeddings(prescaling_bert_hatebert_dynahate_train_embeddings)\n",
    "scaled_prescaling_bert_hatebert_dynahate_dev_embeddings = scaling_embeddings(prescaling_bert_hatebert_dynahate_dev_embeddings)\n",
    "scaled_prescaling_bert_hatebert_dynahate_test_embeddings = scaling_embeddings(prescaling_bert_hatebert_dynahate_test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(prescaling_bert_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bert_hatebert_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bert_hatebert_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bert_hatebert_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bert_hatebert_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bert_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bert_hatebert_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bert_hatebert_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bert_hatebert_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bert_hatebert_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bert_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bert_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bert_hatebert_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bert_hatebert_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bert_hatebert_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bert_hatebert_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_prescaling_bert_hatebert_latenthatred_train_embeddings = scaling_embeddings(prescaling_bert_hatebert_latenthatred_train_embeddings)\n",
    "scaled_prescaling_bert_hatebert_latenthatred_dev_embeddings = scaling_embeddings(prescaling_bert_hatebert_latenthatred_dev_embeddings)\n",
    "scaled_prescaling_bert_hatebert_latenthatred_test_embeddings = scaling_embeddings(prescaling_bert_hatebert_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(prescaling_bert_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bert_hatebert_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bert_hatebert_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bert_hatebert_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bert_hatebert_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bert_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bert_hatebert_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bert_hatebert_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bert_hatebert_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bert_hatebert_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bert_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bert_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bert_hatebert_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bert_hatebert_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bert_hatebert_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bert_hatebert_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_prescaling_bert_hatebert_olid_train_embeddings = scaling_embeddings(prescaling_bert_hatebert_olid_train_embeddings)\n",
    "scaled_prescaling_bert_hatebert_olid_dev_embeddings = scaling_embeddings(prescaling_bert_hatebert_olid_dev_embeddings)\n",
    "scaled_prescaling_bert_hatebert_olid_test_embeddings = scaling_embeddings(prescaling_bert_hatebert_olid_test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(prescaling_bert_hatebert_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_hatebert_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"olid_bert_hatebert_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bert_hatebert_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bert_hatebert_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bert_hatebert_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bert_hatebert_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bert_hatebert_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"latenthatred_bert_hatebert_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bert_hatebert_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bert_hatebert_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bert_hatebert_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bert_hatebert_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bert_hatebert_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"olid_bert_hatebert_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bert_hatebert_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bert_hatebert_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bert_hatebert_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_prescaling_bertweet_hatebert_dynahate_train_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_dynahate_train_embeddings)\n",
    "scaled_prescaling_bertweet_hatebert_dynahate_dev_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_dynahate_dev_embeddings)\n",
    "scaled_prescaling_bertweet_hatebert_dynahate_test_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_dynahate_test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(prescaling_bertweet_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bertweet_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bertweet_hatebert_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bertweet_hatebert_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bertweet_hatebert_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bertweet_hatebert_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bertweet_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bertweet_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bertweet_hatebert_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bertweet_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bertweet_hatebert_dynahate_train_embeddings.cpu(), dynahate_labels_train)\n",
    "save_model(mlp, \"dynahate_bertweet_hatebert_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bertweet_hatebert_dynahate_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bertweet_hatebert_dynahate_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bertweet_hatebert_dynahate_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, dynahate_labels_train, dynahate_labels_dev, dynahate_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_prescaling_bertweet_hatebert_latenthatred_train_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_latenthatred_train_embeddings)\n",
    "scaled_prescaling_bertweet_hatebert_latenthatred_dev_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_latenthatred_dev_embeddings)\n",
    "scaled_prescaling_bertweet_hatebert_latenthatred_test_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(prescaling_bertweet_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mlp \u001b[39m=\u001b[39m mlp\u001b[39m.\u001b[39mfit(prescaling_bert_hatebert_latenthatred_train_embeddings\u001b[39m.\u001b[39mcpu(), latenthatred_labels_train)\n\u001b[0;32m      2\u001b[0m save_model(mlp, \u001b[39m\"\u001b[39m\u001b[39mlatenthatred_bertweet_hertbert_without_scaling.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "mlp = mlp.fit(prescaling_bertweet_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bertweet_hertbert_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bertweet_hatebert_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bertweet_hatebert_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bertweet_hatebert_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bertweet_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bertweet_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bertweet_hatebert_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bertweet_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bertweet_hatebert_latenthatred_train_embeddings.cpu(), latenthatred_labels_train)\n",
    "save_model(mlp, \"latenthatred_bertweet_hatebert_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bertweet_hatebert_latenthatred_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bertweet_hatebert_latenthatred_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bertweet_hatebert_latenthatred_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, latenthatred_labels_train, latenthatred_labels_dev, latenthatred_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_prescaling_bertweet_hatebert_olid_train_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_olid_train_embeddings)\n",
    "scaled_prescaling_bertweet_hatebert_olid_dev_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_olid_dev_embeddings)\n",
    "scaled_prescaling_bertweet_hatebert_olid_test_embeddings = scaling_embeddings(prescaling_bertweet_hatebert_olid_test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated embeddings without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(prescaling_bertweet_hatebert_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bertweet_hatebert_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"olid_bertweet_hatebert_without_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(prescaling_bertweet_hatebert_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(prescaling_bertweet_hatebert_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(prescaling_bertweet_hatebert_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenated normalized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(scaled_prescaling_bertweet_hatebert_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(prescaling_bertweet_hatebert_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"latenthatred_bertweet_hatebert_with_pre_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(scaled_prescaling_bertweet_hatebert_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized concatenated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "grid_results = gridsearch.fit(postscaling_bertweet_hatebert_olid_train_embeddings.cpu(), olid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(postscaling_bertweet_hatebert_olid_train_embeddings.cpu(), olid_labels_train)\n",
    "save_model(mlp, \"olid_bertweet_hatebert_with_post_scaling.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mlp.predict(postscaling_bertweet_hatebert_olid_train_embeddings.cpu())\n",
    "dev_preds = mlp.predict(postscaling_bertweet_hatebert_olid_dev_embeddings.cpu())\n",
    "test_preds = mlp.predict(postscaling_bertweet_hatebert_olid_test_embeddings.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds, olid_labels_train, olid_labels_dev, olid_labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
