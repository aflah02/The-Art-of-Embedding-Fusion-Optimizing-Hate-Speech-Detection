{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 3\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # Numpy Add\n",
    "    return embeddings1 + embeddings2\n",
    "\n",
    "def add_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    return embeddings1 + embeddings2 + embeddings3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_added_dynahate_train = add_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_added_dynahate_dev = add_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_added_dynahate_test = add_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_added_dynahate_train = add_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_added_dynahate_dev = add_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_added_dynahate_test = add_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_added_dynahate_train = add_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_added_dynahate_dev = add_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_added_dynahate_test = add_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_added_dynahate_train = add_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_added_dynahate_dev = add_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_added_dynahate_test = add_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_added_olid_train = add_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_added_olid_dev = add_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_added_olid_test = add_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_added_olid_train = add_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_added_olid_dev = add_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_added_olid_test = add_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_added_olid_train = add_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_added_olid_dev = add_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_added_olid_test = add_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_added_olid_train = add_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_added_olid_dev = add_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_added_olid_test = add_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_added_latenthatred_train = add_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_added_latenthatred_dev = add_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_added_latenthatred_test = add_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_added_latenthatred_train = add_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_added_latenthatred_dev = add_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_added_latenthatred_test = add_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_added_latenthatred_train = add_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_added_latenthatred_dev = add_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_added_latenthatred_test = add_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_added_latenthatred_train = add_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_added_latenthatred_dev = add_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_added_latenthatred_test = add_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=3)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7013018582541054\n",
      "Accuracy Test:  0.6742718446601942\n",
      "Weighted F1 Train Dev:  0.6995032865054512\n",
      "Weighted F1 Test:  0.6717557235001604\n",
      "Macro F1 Train Dev:  0.6966825921947458\n",
      "Macro F1 Test:  0.6666746244585386\n",
      "Micro F1 Train Dev:  0.7013018582541054\n",
      "Micro F1 Test:  0.6742718446601942\n",
      "Weighted Recall Train Dev:  0.7013018582541054\n",
      "Weighted Recall Test:  0.6742718446601942\n",
      "Macro Recall Train Dev:  0.695954428731564\n",
      "Macro Recall Test:  0.6658162585088432\n",
      "Micro Recall Train Dev:  0.7013018582541054\n",
      "Micro Recall Test:  0.6742718446601942\n",
      "Confusion Matrix Train Dev: \n",
      "[[10698  6419]\n",
      " [ 4640 15267]]\n",
      "Confusion Matrix Test: \n",
      "[[1078  774]\n",
      " [ 568 1700]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_added_dynahate_train_dev = np.concatenate((bert_bertweet_added_dynahate_train, bert_bertweet_added_dynahate_dev))\n",
    "bert_bertweet_added_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_added_dynahate_train_dev, bert_bertweet_added_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_added_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_added_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_added_dynahate_seed_3\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_added_dynahate_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7128491620111732\n",
      "Accuracy Test:  0.6921787709497207\n",
      "Weighted F1 Train Dev:  0.6897682583500261\n",
      "Weighted F1 Test:  0.6657062914755787\n",
      "Macro F1 Train Dev:  0.5095405775167801\n",
      "Macro F1 Test:  0.47210074978256555\n",
      "Micro F1 Train Dev:  0.7128491620111732\n",
      "Micro F1 Test:  0.6921787709497207\n",
      "Weighted Recall Train Dev:  0.7128491620111732\n",
      "Weighted Recall Test:  0.6921787709497207\n",
      "Macro Recall Train Dev:  0.4908103411491855\n",
      "Macro Recall Test:  0.4610248302059598\n",
      "Micro Recall Train Dev:  0.7128491620111732\n",
      "Micro Recall Test:  0.6921787709497207\n",
      "Confusion Matrix Train Dev: \n",
      "[[8792 1121   32]\n",
      " [2699 2610   38]\n",
      " [ 390  346   82]]\n",
      "Confusion Matrix Test: \n",
      "[[2933  403   10]\n",
      " [ 969  765   19]\n",
      " [ 118  134   19]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_added_latenthatred_train_dev = np.concatenate((bert_bertweet_added_latenthatred_train, bert_bertweet_added_latenthatred_dev))\n",
    "bert_bertweet_added_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_added_latenthatred_train_dev, bert_bertweet_added_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_added_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_added_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_added_latenthatred_seed_3\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_added_latenthatred_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7756042296072507\n",
      "Accuracy Test:  0.8069767441860465\n",
      "Weighted F1 Train Dev:  0.7646133560361167\n",
      "Weighted F1 Test:  0.7872236511504099\n",
      "Macro F1 Train Dev:  0.7250996081366549\n",
      "Macro F1 Test:  0.7164106761169955\n",
      "Micro F1 Train Dev:  0.7756042296072507\n",
      "Micro F1 Test:  0.8069767441860464\n",
      "Weighted Recall Train Dev:  0.7756042296072507\n",
      "Weighted Recall Test:  0.8069767441860465\n",
      "Macro Recall Train Dev:  0.7119277046482929\n",
      "Macro Recall Test:  0.6924731182795699\n",
      "Micro Recall Train Dev:  0.7756042296072507\n",
      "Micro Recall Test:  0.8069767441860465\n",
      "Confusion Matrix Train Dev: \n",
      "[[7972  868]\n",
      " [2103 2297]]\n",
      "Confusion Matrix Test: \n",
      "[[590  30]\n",
      " [136 104]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_added_olid_train_dev = np.concatenate((bert_bertweet_added_olid_train, bert_bertweet_added_olid_dev))\n",
    "bert_bertweet_added_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_added_olid_train_dev, bert_bertweet_added_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_added_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_added_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_added_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_added_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_added_dynahate_train_dev = np.concatenate((bert_hatebert_added_dynahate_train, bert_hatebert_added_dynahate_dev))\n",
    "bert_hatebert_added_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_added_dynahate_train_dev, bert_hatebert_added_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_added_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_added_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_added_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_added_dynahate_seed_3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7162631905648665\n",
      "Accuracy Test:  0.6919925512104284\n",
      "Weighted F1 Train Dev:  0.6925040729171136\n",
      "Weighted F1 Test:  0.6650906121217168\n",
      "Macro F1 Train Dev:  0.5022443323200018\n",
      "Macro F1 Test:  0.4589741079486607\n",
      "Micro F1 Train Dev:  0.7162631905648665\n",
      "Micro F1 Test:  0.6919925512104284\n",
      "Weighted Recall Train Dev:  0.7162631905648665\n",
      "Weighted Recall Test:  0.6919925512104284\n",
      "Macro Recall Train Dev:  0.4875362325674826\n",
      "Macro Recall Test:  0.45405477259805105\n",
      "Micro Recall Train Dev:  0.7162631905648665\n",
      "Micro Recall Test:  0.6919925512104284\n",
      "Confusion Matrix Train Dev: \n",
      "[[8809 1118   18]\n",
      " [2649 2666   32]\n",
      " [ 363  391   64]]\n",
      "Confusion Matrix Test: \n",
      "[[2916  420   10]\n",
      " [ 950  789   14]\n",
      " [ 136  124   11]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_added_latenthatred_train_dev = np.concatenate((bert_hatebert_added_latenthatred_train, bert_hatebert_added_latenthatred_dev))\n",
    "bert_hatebert_added_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_added_latenthatred_train_dev, bert_hatebert_added_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_added_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_added_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_added_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_added_latenthatred_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.765785498489426\n",
      "Accuracy Test:  0.7930232558139535\n",
      "Weighted F1 Train Dev:  0.7597481094565556\n",
      "Weighted F1 Test:  0.7771463388620887\n",
      "Macro F1 Train Dev:  0.7234747572157649\n",
      "Macro F1 Test:  0.706992519772454\n",
      "Micro F1 Train Dev:  0.765785498489426\n",
      "Micro F1 Test:  0.7930232558139535\n",
      "Weighted Recall Train Dev:  0.765785498489426\n",
      "Weighted Recall Test:  0.7930232558139535\n",
      "Macro Recall Train Dev:  0.7150195392842451\n",
      "Macro Recall Test:  0.6879032258064516\n",
      "Micro Recall Train Dev:  0.765785498489426\n",
      "Micro Recall Test:  0.7930232558139535\n",
      "Confusion Matrix Train Dev: \n",
      "[[7659 1181]\n",
      " [1920 2480]]\n",
      "Confusion Matrix Test: \n",
      "[[574  46]\n",
      " [132 108]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_added_olid_train_dev = np.concatenate((bert_hatebert_added_olid_train, bert_hatebert_added_olid_dev))\n",
    "bert_hatebert_added_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_added_olid_train_dev, bert_hatebert_added_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_added_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_added_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_added_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_added_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7140773552290406\n",
      "Accuracy Test:  0.6900485436893203\n",
      "Weighted F1 Train Dev:  0.7100476048825624\n",
      "Weighted F1 Test:  0.6853385404548508\n",
      "Macro F1 Train Dev:  0.7064919428121403\n",
      "Macro F1 Test:  0.679454572450228\n",
      "Micro F1 Train Dev:  0.7140773552290406\n",
      "Micro F1 Test:  0.6900485436893203\n",
      "Weighted Recall Train Dev:  0.7140773552290406\n",
      "Weighted Recall Test:  0.6900485436893203\n",
      "Macro Recall Train Dev:  0.7059719323058098\n",
      "Macro Recall Test:  0.6786109492193005\n",
      "Micro Recall Train Dev:  0.7140773552290406\n",
      "Micro Recall Test:  0.6900485436893203\n",
      "Confusion Matrix Train Dev: \n",
      "[[10243  6874]\n",
      " [ 3712 16195]]\n",
      "Confusion Matrix Test: \n",
      "[[1047  805]\n",
      " [ 472 1796]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_added_dynahate_train_dev = np.concatenate((hatebert_bertweet_added_dynahate_train, hatebert_bertweet_added_dynahate_dev))\n",
    "hatebert_bertweet_added_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_added_dynahate_train_dev, hatebert_bertweet_added_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_added_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_added_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_added_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_added_dynahate_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7262569832402235\n",
      "Accuracy Test:  0.6975791433891992\n",
      "Weighted F1 Train Dev:  0.7046068835154048\n",
      "Weighted F1 Test:  0.6746825214261521\n",
      "Macro F1 Train Dev:  0.5161522092417578\n",
      "Macro F1 Test:  0.48533240998450533\n",
      "Micro F1 Train Dev:  0.7262569832402235\n",
      "Micro F1 Test:  0.6975791433891992\n",
      "Weighted Recall Train Dev:  0.7262569832402235\n",
      "Weighted Recall Test:  0.6975791433891992\n",
      "Macro Recall Train Dev:  0.49981760816930487\n",
      "Macro Recall Test:  0.47205900435565895\n",
      "Micro Recall Train Dev:  0.7262569832402235\n",
      "Micro Recall Test:  0.6975791433891992\n",
      "Confusion Matrix Train Dev: \n",
      "[[8791 1145    9]\n",
      " [2480 2840   27]\n",
      " [ 349  400   69]]\n",
      "Confusion Matrix Test: \n",
      "[[2895  442    9]\n",
      " [ 908  830   15]\n",
      " [ 127  123   21]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_added_latenthatred_train_dev = np.concatenate((hatebert_bertweet_added_latenthatred_train, hatebert_bertweet_added_latenthatred_dev))\n",
    "hatebert_bertweet_added_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_added_latenthatred_train_dev, hatebert_bertweet_added_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_added_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_added_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_added_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_added_latenthatred_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7671450151057402\n",
      "Accuracy Test:  0.7941860465116279\n",
      "Weighted F1 Train Dev:  0.7583744389563151\n",
      "Weighted F1 Test:  0.7805405004659259\n",
      "Macro F1 Train Dev:  0.7197037754970822\n",
      "Macro F1 Test:  0.7131988446559686\n",
      "Micro F1 Train Dev:  0.7671450151057402\n",
      "Micro F1 Test:  0.7941860465116279\n",
      "Weighted Recall Train Dev:  0.7671450151057402\n",
      "Weighted Recall Test:  0.7941860465116279\n",
      "Macro Recall Train Dev:  0.7089032291238173\n",
      "Macro Recall Test:  0.6950940860215054\n",
      "Micro Recall Train Dev:  0.7671450151057402\n",
      "Micro Recall Test:  0.7941860465116279\n",
      "Confusion Matrix Train Dev: \n",
      "[[7802 1038]\n",
      " [2045 2355]]\n",
      "Confusion Matrix Test: \n",
      "[[570  50]\n",
      " [127 113]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_added_olid_train_dev = np.concatenate((hatebert_bertweet_added_olid_train, hatebert_bertweet_added_olid_dev))\n",
    "hatebert_bertweet_added_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_added_olid_train_dev, hatebert_bertweet_added_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_added_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_added_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_added_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_added_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.712942955920484\n",
      "Accuracy Test:  0.6803398058252427\n",
      "Weighted F1 Train Dev:  0.7086008693037876\n",
      "Weighted F1 Test:  0.6759861761476528\n",
      "Macro F1 Train Dev:  0.7049387103979284\n",
      "Macro F1 Test:  0.6701249789118034\n",
      "Micro F1 Train Dev:  0.712942955920484\n",
      "Micro F1 Test:  0.6803398058252427\n",
      "Weighted Recall Train Dev:  0.712942955920484\n",
      "Weighted Recall Test:  0.6803398058252427\n",
      "Macro Recall Train Dev:  0.704532197285585\n",
      "Macro Recall Test:  0.6693964482841372\n",
      "Micro Recall Train Dev:  0.712942955920484\n",
      "Micro Recall Test:  0.6803398058252427\n",
      "Confusion Matrix Train Dev: \n",
      "[[10149  6968]\n",
      " [ 3660 16247]]\n",
      "Confusion Matrix Test: \n",
      "[[1039  813]\n",
      " [ 504 1764]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_added_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_added_dynahate_train, bert_hatebert_bertweet_added_dynahate_dev))\n",
    "bert_bertweet_hatebert_added_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_added_dynahate_train_dev, bert_bertweet_hatebert_added_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_added_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_added_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_added_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_added_dynahate_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7141527001862198\n",
      "Accuracy Test:  0.6972067039106146\n",
      "Weighted F1 Train Dev:  0.6846465945723406\n",
      "Weighted F1 Test:  0.6640145574831627\n",
      "Macro F1 Train Dev:  0.47551137467369897\n",
      "Macro F1 Test:  0.44930319495735027\n",
      "Micro F1 Train Dev:  0.7141527001862197\n",
      "Micro F1 Test:  0.6972067039106146\n",
      "Weighted Recall Train Dev:  0.7141527001862198\n",
      "Weighted Recall Test:  0.6972067039106146\n",
      "Macro Recall Train Dev:  0.46987600910795607\n",
      "Macro Recall Test:  0.44770564164353527\n",
      "Micro Recall Train Dev:  0.7141527001862198\n",
      "Micro Recall Test:  0.6972067039106146\n",
      "Confusion Matrix Train Dev: \n",
      "[[8953  986    6]\n",
      " [2816 2521   10]\n",
      " [ 379  408   31]]\n",
      "Confusion Matrix Test: \n",
      "[[2999  344    3]\n",
      " [1009  738    6]\n",
      " [ 139  125    7]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_added_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_added_latenthatred_train, bert_hatebert_bertweet_added_latenthatred_dev))\n",
    "bert_bertweet_hatebert_added_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_added_latenthatred_train_dev, bert_bertweet_hatebert_added_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_added_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_added_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_added_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_added_latenthatred_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7681268882175226\n",
      "Accuracy Test:  0.7988372093023256\n",
      "Weighted F1 Train Dev:  0.7564901078882278\n",
      "Weighted F1 Test:  0.780138449312451\n",
      "Macro F1 Train Dev:  0.7154191184907168\n",
      "Macro F1 Test:  0.7083654311694981\n",
      "Micro F1 Train Dev:  0.7681268882175226\n",
      "Micro F1 Test:  0.7988372093023256\n",
      "Weighted Recall Train Dev:  0.7681268882175226\n",
      "Weighted Recall Test:  0.7988372093023256\n",
      "Macro Recall Train Dev:  0.7028465651995064\n",
      "Macro Recall Test:  0.6868279569892473\n",
      "Micro Recall Train Dev:  0.7681268882175226\n",
      "Micro Recall Test:  0.7988372093023256\n",
      "Confusion Matrix Train Dev: \n",
      "[[7934  906]\n",
      " [2164 2236]]\n",
      "Confusion Matrix Test: \n",
      "[[583  37]\n",
      " [136 104]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_added_olid_train_dev = np.concatenate((bert_hatebert_bertweet_added_olid_train, bert_hatebert_bertweet_added_olid_dev))\n",
    "bert_bertweet_hatebert_added_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_added_olid_train_dev, bert_bertweet_hatebert_added_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_added_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_added_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_added_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_added_olid_seed_3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
