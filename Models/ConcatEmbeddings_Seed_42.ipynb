{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Kyode\\PersonalProjects\\HateSpeechModelCombination\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # Numpy concat\n",
    "    return np.concatenate((embeddings1, embeddings2), axis=1)\n",
    "\n",
    "def concat_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    return np.concatenate((embeddings1, embeddings2, embeddings3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_concat_dynahate_train = concat_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_concat_dynahate_dev = concat_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_concat_dynahate_test = concat_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_dynahate_train = concat_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_concat_dynahate_dev = concat_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_concat_dynahate_test = concat_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_dynahate_train = concat_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_concat_dynahate_dev = concat_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_concat_dynahate_test = concat_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_dynahate_train = concat_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_dynahate_dev = concat_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_dynahate_test = concat_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_concat_olid_train = concat_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_concat_olid_dev = concat_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_concat_olid_test = concat_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_olid_train = concat_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_concat_olid_dev = concat_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_concat_olid_test = concat_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_olid_train = concat_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_concat_olid_dev = concat_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_concat_olid_test = concat_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_olid_train = concat_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_olid_dev = concat_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_olid_test = concat_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_concat_latenthatred_train = concat_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_concat_latenthatred_dev = concat_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_concat_latenthatred_test = concat_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_latenthatred_train = concat_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_concat_latenthatred_dev = concat_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_concat_latenthatred_test = concat_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_latenthatred_train = concat_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_concat_latenthatred_dev = concat_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_concat_latenthatred_test = concat_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_latenthatred_train = concat_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_latenthatred_dev = concat_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_latenthatred_test = concat_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=42)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7177506482281764\n",
      "Accuracy Test:  0.6817961165048544\n",
      "Weighted F1 Train Dev:  0.7157674240197323\n",
      "Weighted F1 Test:  0.6798165675674613\n",
      "Macro F1 Train Dev:  0.7129785149766077\n",
      "Macro F1 Test:  0.6751108969505724\n",
      "Micro F1 Train Dev:  0.7177506482281762\n",
      "Micro F1 Test:  0.6817961165048544\n",
      "Weighted Recall Train Dev:  0.7177506482281764\n",
      "Weighted Recall Test:  0.6817961165048544\n",
      "Macro Recall Train Dev:  0.7120775302064103\n",
      "Macro Recall Test:  0.6741855889624069\n",
      "Micro Recall Train Dev:  0.7177506482281764\n",
      "Micro Recall Test:  0.6817961165048544\n",
      "Confusion Matrix Train Dev: \n",
      "[[10900  6217]\n",
      " [ 4233 15674]]\n",
      "Confusion Matrix Test: \n",
      "[[1109  743]\n",
      " [ 568 1700]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_dynahate_train_dev = np.concatenate((bert_bertweet_concat_dynahate_train, bert_bertweet_concat_dynahate_dev))\n",
    "bert_bertweet_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_dynahate_train_dev, bert_bertweet_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_concat_dynahate_seed_42\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_dynahate_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7286778398510242\n",
      "Accuracy Test:  0.6988826815642458\n",
      "Weighted F1 Train Dev:  0.7119909641619356\n",
      "Weighted F1 Test:  0.6812212303382655\n",
      "Macro F1 Train Dev:  0.5168873562457398\n",
      "Macro F1 Test:  0.4816601083140402\n",
      "Micro F1 Train Dev:  0.7286778398510242\n",
      "Micro F1 Test:  0.6988826815642458\n",
      "Weighted Recall Train Dev:  0.7286778398510242\n",
      "Weighted Recall Test:  0.6988826815642458\n",
      "Macro Recall Train Dev:  0.5074750347588459\n",
      "Macro Recall Test:  0.4761597159116653\n",
      "Micro Recall Train Dev:  0.7286778398510242\n",
      "Micro Recall Test:  0.6988826815642458\n",
      "Confusion Matrix Train Dev: \n",
      "[[8454 1482    9]\n",
      " [2098 3229   20]\n",
      " [ 287  475   56]]\n",
      "Confusion Matrix Test: \n",
      "[[2784  555    7]\n",
      " [ 789  955    9]\n",
      " [ 104  153   14]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_latenthatred_train_dev = np.concatenate((bert_bertweet_concat_latenthatred_train, bert_bertweet_concat_latenthatred_dev))\n",
    "bert_bertweet_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_latenthatred_train_dev, bert_bertweet_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_concat_latenthatred_seed_42\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_latenthatred_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7586858006042296\n",
      "Accuracy Test:  0.8081395348837209\n",
      "Weighted F1 Train Dev:  0.7506868818119321\n",
      "Weighted F1 Test:  0.7892877495599382\n",
      "Macro F1 Train Dev:  0.7116162553677061\n",
      "Macro F1 Test:  0.7197374736081183\n",
      "Micro F1 Train Dev:  0.7586858006042296\n",
      "Micro F1 Test:  0.8081395348837209\n",
      "Weighted Recall Train Dev:  0.7586858006042296\n",
      "Weighted Recall Test:  0.8081395348837209\n",
      "Macro Recall Train Dev:  0.7021688605512135\n",
      "Macro Recall Test:  0.6958333333333333\n",
      "Micro Recall Train Dev:  0.7586858006042296\n",
      "Micro Recall Test:  0.8081395348837209\n",
      "Confusion Matrix Train Dev: \n",
      "[[7697 1143]\n",
      " [2052 2348]]\n",
      "Confusion Matrix Test: \n",
      "[[589  31]\n",
      " [134 106]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_olid_train_dev = np.concatenate((bert_bertweet_concat_olid_train, bert_bertweet_concat_olid_dev))\n",
    "bert_bertweet_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_olid_train_dev, bert_bertweet_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_concat_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7358200086430423\n",
      "Accuracy Test:  0.6973300970873786\n",
      "Weighted F1 Train Dev:  0.7353588003714895\n",
      "Weighted F1 Test:  0.6970275750251803\n",
      "Macro F1 Train Dev:  0.7334748017219539\n",
      "Macro F1 Test:  0.6936262458934364\n",
      "Micro F1 Train Dev:  0.7358200086430422\n",
      "Micro F1 Test:  0.6973300970873786\n",
      "Weighted Recall Train Dev:  0.7358200086430423\n",
      "Weighted Recall Test:  0.6973300970873786\n",
      "Macro Recall Train Dev:  0.73291318887662\n",
      "Macro Recall Test:  0.693296441046621\n",
      "Micro Recall Train Dev:  0.7358200086430423\n",
      "Micro Recall Test:  0.6973300970873786\n",
      "Confusion Matrix Train Dev: \n",
      "[[11885  5232]\n",
      " [ 4549 15358]]\n",
      "Confusion Matrix Test: \n",
      "[[1210  642]\n",
      " [ 605 1663]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_dynahate_train_dev = np.concatenate((bert_hatebert_concat_dynahate_train, bert_hatebert_concat_dynahate_dev))\n",
    "bert_hatebert_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_dynahate_train_dev, bert_hatebert_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_concat_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_dynahate_seed_42\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7187461204220981\n",
      "Accuracy Test:  0.692364990689013\n",
      "Weighted F1 Train Dev:  0.7021761540141129\n",
      "Weighted F1 Test:  0.6751380172928965\n",
      "Macro F1 Train Dev:  0.5398970011063146\n",
      "Macro F1 Test:  0.50815237513305\n",
      "Micro F1 Train Dev:  0.7187461204220981\n",
      "Micro F1 Test:  0.692364990689013\n",
      "Weighted Recall Train Dev:  0.7187461204220981\n",
      "Weighted Recall Test:  0.692364990689013\n",
      "Macro Recall Train Dev:  0.5166169705684788\n",
      "Macro Recall Test:  0.4893010077449918\n",
      "Micro Recall Train Dev:  0.7187461204220981\n",
      "Micro Recall Test:  0.692364990689013\n",
      "Confusion Matrix Train Dev: \n",
      "[[8641 1245   59]\n",
      " [2464 2811   72]\n",
      " [ 307  384  127]]\n",
      "Confusion Matrix Test: \n",
      "[[2841  486   19]\n",
      " [ 877  839   37]\n",
      " [ 110  123   38]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_latenthatred_train_dev = np.concatenate((bert_hatebert_concat_latenthatred_train, bert_hatebert_concat_latenthatred_dev))\n",
    "bert_hatebert_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_latenthatred_train_dev, bert_hatebert_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_concat_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_latenthatred_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7858761329305136\n",
      "Accuracy Test:  0.8\n",
      "Weighted F1 Train Dev:  0.7807450390150636\n",
      "Weighted F1 Test:  0.7766864404032546\n",
      "Macro F1 Train Dev:  0.7479651009077288\n",
      "Macro F1 Test:  0.7003144348277092\n",
      "Micro F1 Train Dev:  0.7858761329305136\n",
      "Micro F1 Test:  0.8000000000000002\n",
      "Weighted Recall Train Dev:  0.7858761329305136\n",
      "Weighted Recall Test:  0.8\n",
      "Macro Recall Train Dev:  0.738911456190868\n",
      "Macro Recall Test:  0.6774193548387097\n",
      "Micro Recall Train Dev:  0.7858761329305136\n",
      "Micro Recall Test:  0.8\n",
      "Confusion Matrix Train Dev: \n",
      "[[7770 1070]\n",
      " [1765 2635]]\n",
      "Confusion Matrix Test: \n",
      "[[592  28]\n",
      " [144  96]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_olid_train_dev = np.concatenate((bert_hatebert_concat_olid_train, bert_hatebert_concat_olid_dev))\n",
    "bert_hatebert_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_olid_train_dev, bert_hatebert_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_concat_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7467858686257562\n",
      "Accuracy Test:  0.7058252427184466\n",
      "Weighted F1 Train Dev:  0.7468912523768161\n",
      "Weighted F1 Test:  0.7063030303474152\n",
      "Macro F1 Train Dev:  0.7455608421258794\n",
      "Macro F1 Test:  0.7038791321321599\n",
      "Micro F1 Train Dev:  0.7467858686257564\n",
      "Micro F1 Test:  0.7058252427184466\n",
      "Weighted Recall Train Dev:  0.7467858686257562\n",
      "Weighted Recall Test:  0.7058252427184466\n",
      "Macro Recall Train Dev:  0.7457921330447608\n",
      "Macro Recall Test:  0.7048255187204071\n",
      "Micro Recall Train Dev:  0.7467858686257562\n",
      "Micro Recall Test:  0.7058252427184466\n",
      "Confusion Matrix Train Dev: \n",
      "[[12540  4577]\n",
      " [ 4798 15109]]\n",
      "Confusion Matrix Test: \n",
      "[[1287  565]\n",
      " [ 647 1621]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_dynahate_train_dev = np.concatenate((hatebert_bertweet_concat_dynahate_train, hatebert_bertweet_concat_dynahate_dev))\n",
    "hatebert_bertweet_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_dynahate_train_dev, hatebert_bertweet_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_concat_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_dynahate_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7227188081936685\n",
      "Accuracy Test:  0.7048417132216015\n",
      "Weighted F1 Train Dev:  0.7072609562233675\n",
      "Weighted F1 Test:  0.6880549652177467\n",
      "Macro F1 Train Dev:  0.5343230394255972\n",
      "Macro F1 Test:  0.5127804634128582\n",
      "Micro F1 Train Dev:  0.7227188081936685\n",
      "Micro F1 Test:  0.7048417132216015\n",
      "Weighted Recall Train Dev:  0.7227188081936685\n",
      "Weighted Recall Test:  0.7048417132216015\n",
      "Macro Recall Train Dev:  0.5148888838567683\n",
      "Macro Recall Test:  0.49498714088611195\n",
      "Micro Recall Train Dev:  0.7227188081936685\n",
      "Micro Recall Test:  0.7048417132216015\n",
      "Confusion Matrix Train Dev: \n",
      "[[8540 1362   43]\n",
      " [2289 3001   57]\n",
      " [ 288  428  102]]\n",
      "Confusion Matrix Test: \n",
      "[[2850  480   16]\n",
      " [ 825  903   25]\n",
      " [ 107  132   32]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_latenthatred_train_dev = np.concatenate((hatebert_bertweet_concat_latenthatred_train, hatebert_bertweet_concat_latenthatred_dev))\n",
    "hatebert_bertweet_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_latenthatred_train_dev, hatebert_bertweet_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_concat_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_latenthatred_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7669939577039275\n",
      "Accuracy Test:  0.813953488372093\n",
      "Weighted F1 Train Dev:  0.7582615842128477\n",
      "Weighted F1 Test:  0.8018262277206726\n",
      "Macro F1 Train Dev:  0.719605813225416\n",
      "Macro F1 Test:  0.7411899244635709\n",
      "Micro F1 Train Dev:  0.7669939577039275\n",
      "Micro F1 Test:  0.8139534883720931\n",
      "Weighted Recall Train Dev:  0.7669939577039275\n",
      "Weighted Recall Test:  0.813953488372093\n",
      "Macro Recall Train Dev:  0.7088471822295351\n",
      "Macro Recall Test:  0.7202956989247311\n",
      "Micro Recall Train Dev:  0.7669939577039275\n",
      "Micro Recall Test:  0.813953488372093\n",
      "Confusion Matrix Train Dev: \n",
      "[[7799 1041]\n",
      " [2044 2356]]\n",
      "Confusion Matrix Test: \n",
      "[[578  42]\n",
      " [118 122]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_olid_train_dev = np.concatenate((hatebert_bertweet_concat_olid_train, hatebert_bertweet_concat_olid_dev))\n",
    "hatebert_bertweet_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_olid_train_dev, hatebert_bertweet_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_concat_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7431125756266206\n",
      "Accuracy Test:  0.7033980582524272\n",
      "Weighted F1 Train Dev:  0.7430087635096067\n",
      "Weighted F1 Test:  0.7038885438208567\n",
      "Macro F1 Train Dev:  0.7414431645557211\n",
      "Macro F1 Test:  0.7014594724343485\n",
      "Micro F1 Train Dev:  0.7431125756266206\n",
      "Micro F1 Test:  0.7033980582524272\n",
      "Weighted Recall Train Dev:  0.7431125756266206\n",
      "Weighted Recall Test:  0.7033980582524272\n",
      "Macro Recall Train Dev:  0.7412667933172068\n",
      "Macro Recall Test:  0.7024228537907444\n",
      "Micro Recall Train Dev:  0.7431125756266206\n",
      "Micro Recall Test:  0.7033980582524272\n",
      "Confusion Matrix Train Dev: \n",
      "[[12269  4848]\n",
      " [ 4663 15244]]\n",
      "Confusion Matrix Test: \n",
      "[[1283  569]\n",
      " [ 653 1615]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_concat_dynahate_train, bert_hatebert_bertweet_concat_dynahate_dev))\n",
    "bert_bertweet_hatebert_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_dynahate_train_dev, bert_bertweet_hatebert_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_concat_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_dynahate_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7289882060831782\n",
      "Accuracy Test:  0.7042830540037244\n",
      "Weighted F1 Train Dev:  0.7104670306803296\n",
      "Weighted F1 Test:  0.6855481001372478\n",
      "Macro F1 Train Dev:  0.5316360646827442\n",
      "Macro F1 Test:  0.5107186664249862\n",
      "Micro F1 Train Dev:  0.7289882060831782\n",
      "Micro F1 Test:  0.7042830540037244\n",
      "Weighted Recall Train Dev:  0.7289882060831782\n",
      "Weighted Recall Test:  0.7042830540037244\n",
      "Macro Recall Train Dev:  0.5122278478127743\n",
      "Macro Recall Test:  0.4917913556060576\n",
      "Micro Recall Train Dev:  0.7289882060831782\n",
      "Micro Recall Test:  0.7042830540037244\n",
      "Confusion Matrix Train Dev: \n",
      "[[8743 1167   35]\n",
      " [2381 2908   58]\n",
      " [ 333  392   93]]\n",
      "Confusion Matrix Test: \n",
      "[[2879  451   16]\n",
      " [ 861  871   21]\n",
      " [ 111  128   32]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_concat_latenthatred_train, bert_hatebert_bertweet_concat_latenthatred_dev))\n",
    "bert_bertweet_hatebert_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_latenthatred_train_dev, bert_bertweet_hatebert_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_concat_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_latenthatred_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7802114803625377\n",
      "Accuracy Test:  0.8081395348837209\n",
      "Weighted F1 Train Dev:  0.7730938625674014\n",
      "Weighted F1 Test:  0.7936503352014264\n",
      "Macro F1 Train Dev:  0.7376653614346593\n",
      "Macro F1 Test:  0.7288750895629329\n",
      "Micro F1 Train Dev:  0.7802114803625377\n",
      "Micro F1 Test:  0.8081395348837209\n",
      "Weighted Recall Train Dev:  0.7802114803625377\n",
      "Weighted Recall Test:  0.8081395348837209\n",
      "Macro Recall Train Dev:  0.7269071369806663\n",
      "Macro Recall Test:  0.7073252688172043\n",
      "Micro Recall Train Dev:  0.7802114803625377\n",
      "Micro Recall Test:  0.8081395348837209\n",
      "Confusion Matrix Train Dev: \n",
      "[[7831 1009]\n",
      " [1901 2499]]\n",
      "Confusion Matrix Test: \n",
      "[[580  40]\n",
      " [125 115]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_olid_train_dev = np.concatenate((bert_hatebert_bertweet_concat_olid_train, bert_hatebert_bertweet_concat_olid_dev))\n",
    "bert_bertweet_hatebert_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_olid_train_dev, bert_bertweet_hatebert_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_concat_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_olid_seed_42\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
