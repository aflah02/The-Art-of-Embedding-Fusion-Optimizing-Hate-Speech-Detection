{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # Numpy concat\n",
    "    return np.concatenate((embeddings1, embeddings2), axis=1)\n",
    "\n",
    "def concat_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    return np.concatenate((embeddings1, embeddings2, embeddings3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_concat_dynahate_train = concat_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_concat_dynahate_dev = concat_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_concat_dynahate_test = concat_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_dynahate_train = concat_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_concat_dynahate_dev = concat_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_concat_dynahate_test = concat_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_dynahate_train = concat_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_concat_dynahate_dev = concat_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_concat_dynahate_test = concat_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_dynahate_train = concat_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_dynahate_dev = concat_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_dynahate_test = concat_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_concat_olid_train = concat_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_concat_olid_dev = concat_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_concat_olid_test = concat_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_olid_train = concat_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_concat_olid_dev = concat_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_concat_olid_test = concat_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_olid_train = concat_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_concat_olid_dev = concat_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_concat_olid_test = concat_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_olid_train = concat_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_olid_dev = concat_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_olid_test = concat_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_concat_latenthatred_train = concat_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_concat_latenthatred_dev = concat_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_concat_latenthatred_test = concat_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_concat_latenthatred_train = concat_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_concat_latenthatred_dev = concat_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_concat_latenthatred_test = concat_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_concat_latenthatred_train = concat_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_concat_latenthatred_dev = concat_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_concat_latenthatred_test = concat_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_concat_latenthatred_train = concat_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_concat_latenthatred_dev = concat_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_concat_latenthatred_test = concat_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=42)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7290676318063959\n",
      "Accuracy Test:  0.6730582524271844\n",
      "Weighted F1 Train Dev:  0.7285946351627042\n",
      "Weighted F1 Test:  0.6730501375127786\n",
      "Macro F1 Train Dev:  0.7266624819622656\n",
      "Macro F1 Test:  0.6696743331199866\n",
      "Micro F1 Train Dev:  0.7290676318063959\n",
      "Micro F1 Test:  0.6730582524271844\n",
      "Weighted Recall Train Dev:  0.7290676318063959\n",
      "Weighted Recall Test:  0.6730582524271844\n",
      "Macro Recall Train Dev:  0.7261222489683061\n",
      "Macro Recall Test:  0.6696659505334812\n",
      "Micro Recall Train Dev:  0.7290676318063959\n",
      "Micro Recall Test:  0.6730582524271844\n",
      "Confusion Matrix Train Dev: \n",
      "[[11760  5357]\n",
      " [ 4674 15233]]\n",
      "Confusion Matrix Test: \n",
      "[[1178  674]\n",
      " [ 673 1595]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_dynahate_train_dev = np.concatenate((bert_bertweet_concat_dynahate_train, bert_bertweet_concat_dynahate_dev))\n",
    "bert_bertweet_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_dynahate_train_dev, bert_bertweet_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_concat_dynahate_seed_42\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_dynahate_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7054003724394786\n",
      "Accuracy Test:  0.695903165735568\n",
      "Weighted F1 Train Dev:  0.682249724829152\n",
      "Weighted F1 Test:  0.671539072225558\n",
      "Macro F1 Train Dev:  0.49380931836260206\n",
      "Macro F1 Test:  0.47856019260538735\n",
      "Micro F1 Train Dev:  0.7054003724394786\n",
      "Micro F1 Test:  0.695903165735568\n",
      "Weighted Recall Train Dev:  0.7054003724394786\n",
      "Weighted Recall Test:  0.695903165735568\n",
      "Macro Recall Train Dev:  0.479914601025245\n",
      "Macro Recall Test:  0.466909996522616\n",
      "Micro Recall Train Dev:  0.7054003724394786\n",
      "Micro Recall Test:  0.695903165735568\n",
      "Confusion Matrix Train Dev: \n",
      "[[8659 1268   18]\n",
      " [2684 2644   19]\n",
      " [ 391  366   61]]\n",
      "Confusion Matrix Test: \n",
      "[[2910  424   12]\n",
      " [ 934  808   11]\n",
      " [ 114  138   19]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_latenthatred_train_dev = np.concatenate((bert_bertweet_concat_latenthatred_train, bert_bertweet_concat_latenthatred_dev))\n",
    "bert_bertweet_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_latenthatred_train_dev, bert_bertweet_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_concat_latenthatred_seed_42\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_latenthatred_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7705438066465257\n",
      "Accuracy Test:  0.8093023255813954\n",
      "Weighted F1 Train Dev:  0.764771943179381\n",
      "Weighted F1 Test:  0.8004580888757631\n",
      "Macro F1 Train Dev:  0.7293754324140186\n",
      "Macro F1 Test:  0.7425130897698975\n",
      "Micro F1 Train Dev:  0.7705438066465257\n",
      "Micro F1 Test:  0.8093023255813954\n",
      "Weighted Recall Train Dev:  0.7705438066465257\n",
      "Weighted Recall Test:  0.8093023255813954\n",
      "Macro Recall Train Dev:  0.7208088235294118\n",
      "Macro Recall Test:  0.7260080645161291\n",
      "Micro Recall Train Dev:  0.7705438066465257\n",
      "Micro Recall Test:  0.8093023255813954\n",
      "Confusion Matrix Train Dev: \n",
      "[[7683 1157]\n",
      " [1881 2519]]\n",
      "Confusion Matrix Test: \n",
      "[[567  53]\n",
      " [111 129]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_concat_olid_train_dev = np.concatenate((bert_bertweet_concat_olid_train, bert_bertweet_concat_olid_dev))\n",
    "bert_bertweet_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_concat_olid_train_dev, bert_bertweet_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_concat_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_concat_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.730039974070873\n",
      "Accuracy Test:  0.6881067961165048\n",
      "Weighted F1 Train Dev:  0.730270195989603\n",
      "Weighted F1 Test:  0.6887393359563769\n",
      "Macro F1 Train Dev:  0.729013211345265\n",
      "Macro F1 Test:  0.6864106937140158\n",
      "Micro F1 Train Dev:  0.730039974070873\n",
      "Micro F1 Test:  0.6881067961165048\n",
      "Weighted Recall Train Dev:  0.730039974070873\n",
      "Weighted Recall Test:  0.6881067961165048\n",
      "Macro Recall Train Dev:  0.7295442223703075\n",
      "Macro Recall Test:  0.6876921274869439\n",
      "Micro Recall Train Dev:  0.730039974070873\n",
      "Micro Recall Test:  0.6881067961165048\n",
      "Confusion Matrix Train Dev: \n",
      "[[12375  4742]\n",
      " [ 5253 14654]]\n",
      "Confusion Matrix Test: \n",
      "[[1266  586]\n",
      " [ 699 1569]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_dynahate_train_dev = np.concatenate((bert_hatebert_concat_dynahate_train, bert_hatebert_concat_dynahate_dev))\n",
    "bert_hatebert_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_dynahate_train_dev, bert_hatebert_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_concat_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_dynahate_seed_42\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7184978274363749\n",
      "Accuracy Test:  0.6981378026070764\n",
      "Weighted F1 Train Dev:  0.6941655246881774\n",
      "Weighted F1 Test:  0.6708684483032371\n",
      "Macro F1 Train Dev:  0.5125039883036244\n",
      "Macro F1 Test:  0.4794746175716493\n",
      "Micro F1 Train Dev:  0.7184978274363749\n",
      "Micro F1 Test:  0.6981378026070764\n",
      "Weighted Recall Train Dev:  0.7184978274363749\n",
      "Weighted Recall Test:  0.6981378026070764\n",
      "Macro Recall Train Dev:  0.4933697531878334\n",
      "Macro Recall Test:  0.46638296918207384\n",
      "Micro Recall Train Dev:  0.7184978274363749\n",
      "Micro Recall Test:  0.6981378026070764\n",
      "Confusion Matrix Train Dev: \n",
      "[[8912 1008   25]\n",
      " [2718 2580   49]\n",
      " [ 379  356   83]]\n",
      "Confusion Matrix Test: \n",
      "[[2964  371   11]\n",
      " [ 969  764   20]\n",
      " [ 135  115   21]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_latenthatred_train_dev = np.concatenate((bert_hatebert_concat_latenthatred_train, bert_hatebert_concat_latenthatred_dev))\n",
    "bert_hatebert_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_latenthatred_train_dev, bert_hatebert_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_concat_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_latenthatred_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.766465256797583\n",
      "Accuracy Test:  0.7976744186046512\n",
      "Weighted F1 Train Dev:  0.757724054715453\n",
      "Weighted F1 Test:  0.7764096068527517\n",
      "Macro F1 Train Dev:  0.7189905844114034\n",
      "Macro F1 Test:  0.7015889729108834\n",
      "Micro F1 Train Dev:  0.766465256797583\n",
      "Micro F1 Test:  0.7976744186046512\n",
      "Weighted Recall Train Dev:  0.766465256797583\n",
      "Weighted Recall Test:  0.7976744186046512\n",
      "Macro Recall Train Dev:  0.7082800287947346\n",
      "Macro Recall Test:  0.6796370967741936\n",
      "Micro Recall Train Dev:  0.766465256797583\n",
      "Micro Recall Test:  0.7976744186046512\n",
      "Confusion Matrix Train Dev: \n",
      "[[7795 1045]\n",
      " [2047 2353]]\n",
      "Confusion Matrix Test: \n",
      "[[587  33]\n",
      " [141  99]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_concat_olid_train_dev = np.concatenate((bert_hatebert_concat_olid_train, bert_hatebert_concat_olid_dev))\n",
    "bert_hatebert_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_concat_olid_train_dev, bert_hatebert_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_concat_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_concat_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7184528954191876\n",
      "Accuracy Test:  0.6881067961165048\n",
      "Weighted F1 Train Dev:  0.7172441169227889\n",
      "Weighted F1 Test:  0.6869658149516107\n",
      "Macro F1 Train Dev:  0.7148178636818158\n",
      "Macro F1 Test:  0.6828384396072977\n",
      "Micro F1 Train Dev:  0.7184528954191874\n",
      "Micro F1 Test:  0.6881067961165048\n",
      "Weighted Recall Train Dev:  0.7184528954191876\n",
      "Weighted Recall Test:  0.6881067961165048\n",
      "Macro Recall Train Dev:  0.7139996860848408\n",
      "Macro Recall Test:  0.6820468648222429\n",
      "Micro Recall Train Dev:  0.7184528954191876\n",
      "Micro Recall Test:  0.6881067961165048\n",
      "Confusion Matrix Train Dev: \n",
      "[[11210  5907]\n",
      " [ 4517 15390]]\n",
      "Confusion Matrix Test: \n",
      "[[1152  700]\n",
      " [ 585 1683]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_dynahate_train_dev = np.concatenate((hatebert_bertweet_concat_dynahate_train, hatebert_bertweet_concat_dynahate_dev))\n",
    "hatebert_bertweet_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_dynahate_train_dev, hatebert_bertweet_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_concat_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_dynahate_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7237740533829919\n",
      "Accuracy Test:  0.7018621973929237\n",
      "Weighted F1 Train Dev:  0.6919429506811297\n",
      "Weighted F1 Test:  0.6652894451532908\n",
      "Macro F1 Train Dev:  0.5035285128411652\n",
      "Macro F1 Test:  0.47105559390880264\n",
      "Micro F1 Train Dev:  0.7237740533829919\n",
      "Micro F1 Test:  0.7018621973929237\n",
      "Weighted Recall Train Dev:  0.7237740533829919\n",
      "Weighted Recall Test:  0.7018621973929237\n",
      "Macro Recall Train Dev:  0.485187555529584\n",
      "Macro Recall Test:  0.4583731866375163\n",
      "Micro Recall Train Dev:  0.7237740533829919\n",
      "Micro Recall Test:  0.7018621973929237\n",
      "Confusion Matrix Train Dev: \n",
      "[[9248  685   12]\n",
      " [2973 2340   34]\n",
      " [ 411  335   72]]\n",
      "Confusion Matrix Test: \n",
      "[[3083  257    6]\n",
      " [1072  666   15]\n",
      " [ 141  110   20]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_latenthatred_train_dev = np.concatenate((hatebert_bertweet_concat_latenthatred_train, hatebert_bertweet_concat_latenthatred_dev))\n",
    "hatebert_bertweet_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_latenthatred_train_dev, hatebert_bertweet_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_concat_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_latenthatred_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7690332326283988\n",
      "Accuracy Test:  0.8069767441860465\n",
      "Weighted F1 Train Dev:  0.7653551002021992\n",
      "Weighted F1 Test:  0.7987704090182155\n",
      "Macro F1 Train Dev:  0.731890124849072\n",
      "Macro F1 Test:  0.7410221245038495\n",
      "Micro F1 Train Dev:  0.7690332326283988\n",
      "Micro F1 Test:  0.8069767441860464\n",
      "Weighted Recall Train Dev:  0.7690332326283988\n",
      "Weighted Recall Test:  0.8069767441860465\n",
      "Macro Recall Train Dev:  0.7258417317976141\n",
      "Macro Recall Test:  0.7256720430107526\n",
      "Micro Recall Train Dev:  0.7690332326283988\n",
      "Micro Recall Test:  0.8069767441860465\n",
      "Confusion Matrix Train Dev: \n",
      "[[7555 1285]\n",
      " [1773 2627]]\n",
      "Confusion Matrix Test: \n",
      "[[564  56]\n",
      " [110 130]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_concat_olid_train_dev = np.concatenate((hatebert_bertweet_concat_olid_train, hatebert_bertweet_concat_olid_dev))\n",
    "hatebert_bertweet_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_concat_olid_train_dev, hatebert_bertweet_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_concat_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_concat_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7522417891097667\n",
      "Accuracy Test:  0.7048543689320388\n",
      "Weighted F1 Train Dev:  0.7513325930653146\n",
      "Weighted F1 Test:  0.7040923951583962\n",
      "Macro F1 Train Dev:  0.7492786198150951\n",
      "Macro F1 Test:  0.700406568532404\n",
      "Micro F1 Train Dev:  0.7522417891097667\n",
      "Micro F1 Test:  0.7048543689320388\n",
      "Weighted Recall Train Dev:  0.7522417891097667\n",
      "Weighted Recall Test:  0.7048543689320388\n",
      "Macro Recall Train Dev:  0.7482988292005803\n",
      "Macro Recall Test:  0.6996849775827457\n",
      "Micro Recall Train Dev:  0.7522417891097667\n",
      "Micro Recall Test:  0.7048543689320388\n",
      "Confusion Matrix Train Dev: \n",
      "[[11913  5204]\n",
      " [ 3969 15938]]\n",
      "Confusion Matrix Test: \n",
      "[[1201  651]\n",
      " [ 565 1703]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_concat_dynahate_train, bert_hatebert_bertweet_concat_dynahate_dev))\n",
    "bert_bertweet_hatebert_concat_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_dynahate_train_dev, bert_bertweet_hatebert_concat_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_concat_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_dynahate_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7144630664183736\n",
      "Accuracy Test:  0.6986964618249535\n",
      "Weighted F1 Train Dev:  0.7013844492113639\n",
      "Weighted F1 Test:  0.6847678302906718\n",
      "Macro F1 Train Dev:  0.5431007947368226\n",
      "Macro F1 Test:  0.5241980728365611\n",
      "Micro F1 Train Dev:  0.7144630664183736\n",
      "Micro F1 Test:  0.6986964618249535\n",
      "Weighted Recall Train Dev:  0.7144630664183736\n",
      "Weighted Recall Test:  0.6986964618249535\n",
      "Macro Recall Train Dev:  0.5215892298486023\n",
      "Macro Recall Test:  0.5036812889912919\n",
      "Micro Recall Train Dev:  0.7144630664183736\n",
      "Micro Recall Test:  0.6986964618249535\n",
      "Confusion Matrix Train Dev: \n",
      "[[8439 1437   69]\n",
      " [2316 2934   97]\n",
      " [ 306  375  137]]\n",
      "Confusion Matrix Test: \n",
      "[[2811  515   20]\n",
      " [ 820  898   35]\n",
      " [  98  130   43]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_concat_latenthatred_train, bert_hatebert_bertweet_concat_latenthatred_dev))\n",
    "bert_bertweet_hatebert_concat_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_latenthatred_train_dev, bert_bertweet_hatebert_concat_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_concat_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_latenthatred_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7874622356495469\n",
      "Accuracy Test:  0.8081395348837209\n",
      "Weighted F1 Train Dev:  0.7837286961474602\n",
      "Weighted F1 Test:  0.7936503352014264\n",
      "Macro F1 Train Dev:  0.752569080754105\n",
      "Macro F1 Test:  0.7288750895629329\n",
      "Micro F1 Train Dev:  0.7874622356495469\n",
      "Micro F1 Test:  0.8081395348837209\n",
      "Weighted Recall Train Dev:  0.7874622356495469\n",
      "Weighted Recall Test:  0.8081395348837209\n",
      "Macro Recall Train Dev:  0.745350164541341\n",
      "Macro Recall Test:  0.7073252688172043\n",
      "Micro Recall Train Dev:  0.7874622356495469\n",
      "Micro Recall Test:  0.8081395348837209\n",
      "Confusion Matrix Train Dev: \n",
      "[[7699 1141]\n",
      " [1673 2727]]\n",
      "Confusion Matrix Test: \n",
      "[[580  40]\n",
      " [125 115]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_concat_olid_train_dev = np.concatenate((bert_hatebert_bertweet_concat_olid_train, bert_hatebert_bertweet_concat_olid_dev))\n",
    "bert_bertweet_hatebert_concat_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_concat_olid_train_dev, bert_bertweet_hatebert_concat_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_concat_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_concat_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_concat_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_concat_olid_seed_42\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
