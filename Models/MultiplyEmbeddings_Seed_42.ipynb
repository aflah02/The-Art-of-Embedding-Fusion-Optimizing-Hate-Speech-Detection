{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # Numpy multiplication\n",
    "    return np.multiply(embeddings1, embeddings2)\n",
    "\n",
    "def multiply_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    # Numpy multiplication\n",
    "    return np.multiply(embeddings1, np.multiply(embeddings2, embeddings3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_multiplied_dynahate_train = multiply_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_multiplied_dynahate_dev = multiply_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_multiplied_dynahate_test = multiply_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_dynahate_train = multiply_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_multiplied_dynahate_dev = multiply_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_multiplied_dynahate_test = multiply_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_dynahate_train = multiply_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_multiplied_dynahate_dev = multiply_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_dynahate_test = multiply_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_dynahate_train = multiply_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_dynahate_dev = multiply_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_dynahate_test = multiply_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_multiplied_olid_train = multiply_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_multiplied_olid_dev = multiply_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_multiplied_olid_test = multiply_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_olid_train = multiply_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_multiplied_olid_dev = multiply_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_multiplied_olid_test = multiply_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_olid_train = multiply_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_multiplied_olid_dev = multiply_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_olid_test = multiply_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_olid_train = multiply_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_olid_dev = multiply_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_olid_test = multiply_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_multiplied_latenthatred_train = multiply_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_multiplied_latenthatred_dev = multiply_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_multiplied_latenthatred_test = multiply_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_latenthatred_train = multiply_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_multiplied_latenthatred_dev = multiply_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_multiplied_latenthatred_test = multiply_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_latenthatred_train = multiply_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_multiplied_latenthatred_dev = multiply_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_latenthatred_test = multiply_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_train = multiply_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_dev = multiply_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_test = multiply_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=42)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.737602636127917\n",
      "Accuracy Test:  0.6604368932038835\n",
      "Weighted F1 Train Dev:  0.7365245789824373\n",
      "Weighted F1 Test:  0.6594007783149078\n",
      "Macro F1 Train Dev:  0.7342883117438583\n",
      "Macro F1 Test:  0.6550470026198182\n",
      "Micro F1 Train Dev:  0.737602636127917\n",
      "Micro F1 Test:  0.6604368932038835\n",
      "Weighted Recall Train Dev:  0.737602636127917\n",
      "Weighted Recall Test:  0.6604368932038835\n",
      "Macro Recall Train Dev:  0.7333509051593621\n",
      "Macro Recall Test:  0.654488117141105\n",
      "Micro Recall Train Dev:  0.737602636127917\n",
      "Micro Recall Test:  0.6604368932038835\n",
      "Confusion Matrix Train Dev: \n",
      "[[11587  5530]\n",
      " [ 4185 15722]]\n",
      "Confusion Matrix Test: \n",
      "[[1103  749]\n",
      " [ 650 1618]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_dynahate_train_dev = np.concatenate((bert_bertweet_multiplied_dynahate_train, bert_bertweet_multiplied_dynahate_dev))\n",
    "bert_bertweet_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_dynahate_train_dev, bert_bertweet_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_multiplied_dynahate_seed_42\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_dynahate_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7261949099937927\n",
      "Accuracy Test:  0.6944134078212291\n",
      "Weighted F1 Train Dev:  0.6947093083181946\n",
      "Weighted F1 Test:  0.6591696217286133\n",
      "Macro F1 Train Dev:  0.5299983498517727\n",
      "Macro F1 Test:  0.4893958783206624\n",
      "Micro F1 Train Dev:  0.7261949099937928\n",
      "Micro F1 Test:  0.6944134078212291\n",
      "Weighted Recall Train Dev:  0.7261949099937927\n",
      "Weighted Recall Test:  0.6944134078212291\n",
      "Macro Recall Train Dev:  0.5026847690373029\n",
      "Macro Recall Test:  0.46980276497734813\n",
      "Micro Recall Train Dev:  0.7261949099937927\n",
      "Micro Recall Test:  0.6944134078212291\n",
      "Confusion Matrix Train Dev: \n",
      "[[9348  568   29]\n",
      " [3057 2227   63]\n",
      " [ 414  280  124]]\n",
      "Confusion Matrix Test: \n",
      "[[3068  263   15]\n",
      " [1100  624   29]\n",
      " [ 137   97   37]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_latenthatred_train_dev = np.concatenate((bert_bertweet_multiplied_latenthatred_train, bert_bertweet_multiplied_latenthatred_dev))\n",
    "bert_bertweet_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_latenthatred_train_dev, bert_bertweet_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_multiplied_latenthatred_seed_42\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_latenthatred_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7601208459214501\n",
      "Accuracy Test:  0.7965116279069767\n",
      "Weighted F1 Train Dev:  0.741275936417673\n",
      "Weighted F1 Test:  0.7765173101393285\n",
      "Macro F1 Train Dev:  0.6932441349269899\n",
      "Macro F1 Test:  0.7027518659480043\n",
      "Micro F1 Train Dev:  0.7601208459214501\n",
      "Micro F1 Test:  0.7965116279069767\n",
      "Weighted Recall Train Dev:  0.7601208459214501\n",
      "Weighted Recall Test:  0.7965116279069767\n",
      "Macro Recall Train Dev:  0.6800138831756479\n",
      "Macro Recall Test:  0.6813844086021505\n",
      "Micro Recall Train Dev:  0.7601208459214501\n",
      "Micro Recall Test:  0.7965116279069767\n",
      "Confusion Matrix Train Dev: \n",
      "[[8123  717]\n",
      " [2459 1941]]\n",
      "Confusion Matrix Test: \n",
      "[[584  36]\n",
      " [139 101]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_olid_train_dev = np.concatenate((bert_bertweet_multiplied_olid_train, bert_bertweet_multiplied_olid_dev))\n",
    "bert_bertweet_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_olid_train_dev, bert_bertweet_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_multiplied_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7115384615384616\n",
      "Accuracy Test:  0.6825242718446602\n",
      "Weighted F1 Train Dev:  0.7106994952366154\n",
      "Weighted F1 Test:  0.681375208826411\n",
      "Macro F1 Train Dev:  0.7084313595949965\n",
      "Macro F1 Test:  0.6771821367598168\n",
      "Micro F1 Train Dev:  0.7115384615384616\n",
      "Micro F1 Test:  0.6825242718446602\n",
      "Weighted Recall Train Dev:  0.7115384615384616\n",
      "Weighted Recall Test:  0.6825242718446602\n",
      "Macro Recall Train Dev:  0.7077785776419796\n",
      "Macro Recall Test:  0.6764315997577337\n",
      "Micro Recall Train Dev:  0.7115384615384616\n",
      "Micro Recall Test:  0.6825242718446602\n",
      "Confusion Matrix Train Dev: \n",
      "[[11261  5856]\n",
      " [ 4824 15083]]\n",
      "Confusion Matrix Test: \n",
      "[[1141  711]\n",
      " [ 597 1671]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_dynahate_train_dev = np.concatenate((bert_hatebert_multiplied_dynahate_train, bert_hatebert_multiplied_dynahate_dev))\n",
    "bert_hatebert_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_dynahate_train_dev, bert_hatebert_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_multiplied_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_dynahate_seed_42\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7063935443823712\n",
      "Accuracy Test:  0.6905027932960894\n",
      "Weighted F1 Train Dev:  0.6789544330264619\n",
      "Weighted F1 Test:  0.6611802603184534\n",
      "Macro F1 Train Dev:  0.4710106128185127\n",
      "Macro F1 Test:  0.44867438510666685\n",
      "Micro F1 Train Dev:  0.7063935443823712\n",
      "Micro F1 Test:  0.6905027932960894\n",
      "Weighted Recall Train Dev:  0.7063935443823712\n",
      "Weighted Recall Test:  0.6905027932960894\n",
      "Macro Recall Train Dev:  0.46637875393738143\n",
      "Macro Recall Test:  0.44737830594133715\n",
      "Micro Recall Train Dev:  0.7063935443823712\n",
      "Micro Recall Test:  0.6905027932960894\n",
      "Confusion Matrix Train Dev: \n",
      "[[8792 1132   21]\n",
      " [2782 2558    7]\n",
      " [ 376  412   30]]\n",
      "Confusion Matrix Test: \n",
      "[[2927  414    5]\n",
      " [ 973  774    6]\n",
      " [ 139  125    7]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_latenthatred_train_dev = np.concatenate((bert_hatebert_multiplied_latenthatred_train, bert_hatebert_multiplied_latenthatred_dev))\n",
    "bert_hatebert_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_latenthatred_train_dev, bert_hatebert_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_multiplied_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_latenthatred_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7577794561933535\n",
      "Accuracy Test:  0.8034883720930233\n",
      "Weighted F1 Train Dev:  0.7479382649828166\n",
      "Weighted F1 Test:  0.7825598890216661\n",
      "Macro F1 Train Dev:  0.7070637196369008\n",
      "Macro F1 Test:  0.709598204919687\n",
      "Micro F1 Train Dev:  0.7577794561933535\n",
      "Micro F1 Test:  0.8034883720930233\n",
      "Weighted Recall Train Dev:  0.7577794561933535\n",
      "Weighted Recall Test:  0.8034883720930233\n",
      "Macro Recall Train Dev:  0.6965816536404772\n",
      "Macro Recall Test:  0.6862231182795699\n",
      "Micro Recall Train Dev:  0.7577794561933535\n",
      "Micro Recall Test:  0.8034883720930233\n",
      "Confusion Matrix Train Dev: \n",
      "[[7771 1069]\n",
      " [2138 2262]]\n",
      "Confusion Matrix Test: \n",
      "[[590  30]\n",
      " [139 101]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_olid_train_dev = np.concatenate((bert_hatebert_multiplied_olid_train, bert_hatebert_multiplied_olid_dev))\n",
    "bert_hatebert_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_olid_train_dev, bert_hatebert_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_multiplied_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7588050993949871\n",
      "Accuracy Test:  0.6912621359223301\n",
      "Weighted F1 Train Dev:  0.7588255199045713\n",
      "Weighted F1 Test:  0.6918402917827109\n",
      "Macro F1 Train Dev:  0.7574690146250479\n",
      "Macro F1 Test:  0.6894351634035265\n",
      "Micro F1 Train Dev:  0.7588050993949871\n",
      "Micro F1 Test:  0.6912621359223301\n",
      "Weighted Recall Train Dev:  0.7588050993949871\n",
      "Weighted Recall Test:  0.6912621359223301\n",
      "Macro Recall Train Dev:  0.7575135990699335\n",
      "Macro Recall Test:  0.6905580886862384\n",
      "Micro Recall Train Dev:  0.7588050993949871\n",
      "Micro Recall Test:  0.6912621359223301\n",
      "Confusion Matrix Train Dev: \n",
      "[[12673  4444]\n",
      " [ 4486 15421]]\n",
      "Confusion Matrix Test: \n",
      "[[1266  586]\n",
      " [ 686 1582]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_dynahate_train_dev = np.concatenate((hatebert_bertweet_multiplied_dynahate_train, hatebert_bertweet_multiplied_dynahate_dev))\n",
    "hatebert_bertweet_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_dynahate_train_dev, hatebert_bertweet_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev ,dynahate_labels_test, \"Results/hatebert_bertweet_multiplied_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_dynahate_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.737554314090627\n",
      "Accuracy Test:  0.7068901303538175\n",
      "Weighted F1 Train Dev:  0.7103921707160721\n",
      "Weighted F1 Test:  0.6753662811167274\n",
      "Macro F1 Train Dev:  0.5347752972046343\n",
      "Macro F1 Test:  0.4964175898952261\n",
      "Micro F1 Train Dev:  0.737554314090627\n",
      "Micro F1 Test:  0.7068901303538175\n",
      "Weighted Recall Train Dev:  0.737554314090627\n",
      "Weighted Recall Test:  0.7068901303538175\n",
      "Macro Recall Train Dev:  0.5093811098394735\n",
      "Macro Recall Test:  0.4768468298205561\n",
      "Micro Recall Train Dev:  0.737554314090627\n",
      "Micro Recall Test:  0.7068901303538175\n",
      "Confusion Matrix Train Dev: \n",
      "[[9260  664   21]\n",
      " [2777 2519   51]\n",
      " [ 394  321  103]]\n",
      "Confusion Matrix Test: \n",
      "[[3062  271   13]\n",
      " [1028  703   22]\n",
      " [ 134  106   31]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_latenthatred_train_dev = np.concatenate((hatebert_bertweet_multiplied_latenthatred_train, hatebert_bertweet_multiplied_latenthatred_dev))\n",
    "hatebert_bertweet_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_latenthatred_train_dev, hatebert_bertweet_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_multiplied_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_latenthatred_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7682779456193354\n",
      "Accuracy Test:  0.7883720930232558\n",
      "Weighted F1 Train Dev:  0.7548855982024079\n",
      "Weighted F1 Test:  0.7695220025066148\n",
      "Macro F1 Train Dev:  0.7123519626293333\n",
      "Macro F1 Test:  0.6949070608782435\n",
      "Micro F1 Train Dev:  0.7682779456193355\n",
      "Micro F1 Test:  0.7883720930232558\n",
      "Weighted Recall Train Dev:  0.7682779456193354\n",
      "Weighted Recall Test:  0.7883720930232558\n",
      "Macro Recall Train Dev:  0.6990214932126697\n",
      "Macro Recall Test:  0.675739247311828\n",
      "Micro Recall Train Dev:  0.7682779456193354\n",
      "Micro Recall Test:  0.7883720930232558\n",
      "Confusion Matrix Train Dev: \n",
      "[[8005  835]\n",
      " [2233 2167]]\n",
      "Confusion Matrix Test: \n",
      "[[577  43]\n",
      " [139 101]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_olid_train_dev = np.concatenate((hatebert_bertweet_multiplied_olid_train, hatebert_bertweet_multiplied_olid_dev))\n",
    "hatebert_bertweet_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_olid_train_dev, hatebert_bertweet_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_multiplied_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7494868193604148\n",
      "Accuracy Test:  0.6788834951456311\n",
      "Weighted F1 Train Dev:  0.7485041215087284\n",
      "Weighted F1 Test:  0.6787079120860618\n",
      "Macro F1 Train Dev:  0.7463934771621501\n",
      "Macro F1 Test:  0.6752296952869767\n",
      "Micro F1 Train Dev:  0.7494868193604148\n",
      "Micro F1 Test:  0.6788834951456311\n",
      "Weighted Recall Train Dev:  0.7494868193604148\n",
      "Weighted Recall Test:  0.6788834951456311\n",
      "Macro Recall Train Dev:  0.7453971198590827\n",
      "Macro Recall Test:  0.6750559955203583\n",
      "Micro Recall Train Dev:  0.7494868193604148\n",
      "Micro Recall Test:  0.6788834951456311\n",
      "Confusion Matrix Train Dev: \n",
      "[[11830  5287]\n",
      " [ 3988 15919]]\n",
      "Confusion Matrix Test: \n",
      "[[1180  672]\n",
      " [ 651 1617]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_dynahate_train, bert_hatebert_bertweet_multiplied_dynahate_dev))\n",
    "bert_bertweet_hatebert_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_dynahate_train_dev, bert_bertweet_hatebert_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_multiplied_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_dynahate_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7281191806331471\n",
      "Accuracy Test:  0.6990689013035382\n",
      "Weighted F1 Train Dev:  0.7116467296176724\n",
      "Weighted F1 Test:  0.6821391820728786\n",
      "Macro F1 Train Dev:  0.5230675503250849\n",
      "Macro F1 Test:  0.4938795919430556\n",
      "Micro F1 Train Dev:  0.7281191806331471\n",
      "Micro F1 Test:  0.6990689013035382\n",
      "Weighted Recall Train Dev:  0.7281191806331471\n",
      "Weighted Recall Test:  0.6990689013035382\n",
      "Macro Recall Train Dev:  0.5100470749554659\n",
      "Macro Recall Test:  0.4823614977785413\n",
      "Micro Recall Train Dev:  0.7281191806331471\n",
      "Micro Recall Test:  0.6990689013035382\n",
      "Confusion Matrix Train Dev: \n",
      "[[8489 1437   19]\n",
      " [2148 3173   26]\n",
      " [ 315  435   68]]\n",
      "Confusion Matrix Test: \n",
      "[[2798  539    9]\n",
      " [ 806  935   12]\n",
      " [  99  151   21]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_latenthatred_train, bert_hatebert_bertweet_multiplied_latenthatred_dev))\n",
    "bert_bertweet_hatebert_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_latenthatred_train_dev, bert_bertweet_hatebert_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_multiplied_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_latenthatred_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.8077039274924471\n",
      "Accuracy Test:  0.7953488372093023\n",
      "Weighted F1 Train Dev:  0.7972491869945597\n",
      "Weighted F1 Test:  0.7755145265629444\n",
      "Macro F1 Train Dev:  0.7625043907291249\n",
      "Macro F1 Test:  0.7016219967039639\n",
      "Micro F1 Train Dev:  0.8077039274924471\n",
      "Micro F1 Test:  0.7953488372093023\n",
      "Weighted Recall Train Dev:  0.8077039274924471\n",
      "Weighted Recall Test:  0.7953488372093023\n",
      "Macro Recall Train Dev:  0.7452123611682435\n",
      "Macro Recall Test:  0.6805779569892473\n",
      "Micro Recall Train Dev:  0.8077039274924471\n",
      "Micro Recall Test:  0.7953488372093023\n",
      "Confusion Matrix Train Dev: \n",
      "[[8235  605]\n",
      " [1941 2459]]\n",
      "Confusion Matrix Test: \n",
      "[[583  37]\n",
      " [139 101]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_olid_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_olid_train, bert_hatebert_bertweet_multiplied_olid_dev))\n",
    "bert_bertweet_hatebert_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_olid_train_dev, bert_bertweet_hatebert_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_multiplied_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_olid_seed_42\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
