{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleave_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    new_embeddings = []\n",
    "    for i in range(len(embeddings1)):\n",
    "        embedding = []\n",
    "        for j in range(len(embeddings1[i])):\n",
    "            embedding.append(embeddings1[i][j])\n",
    "            embedding.append(embeddings2[i][j])\n",
    "        new_embeddings.append(np.array(embedding))\n",
    "    return np.array(new_embeddings)\n",
    "    \n",
    "\n",
    "def interleave_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    new_embeddings = []\n",
    "    for i in range(len(embeddings1)):\n",
    "        embedding = []\n",
    "        for j in range(len(embeddings1[i])):\n",
    "            embedding.append(embeddings1[i][j])\n",
    "            embedding.append(embeddings2[i][j])\n",
    "            embedding.append(embeddings3[i][j])\n",
    "        new_embeddings.append(np.array(embedding))\n",
    "    return np.array(new_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_interleaved_dynahate_train = interleave_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_interleaved_dynahate_dev = interleave_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_interleaved_dynahate_test = interleave_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_interleaved_dynahate_train = interleave_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_interleaved_dynahate_dev = interleave_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_interleaved_dynahate_test = interleave_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_interleaved_dynahate_train = interleave_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_interleaved_dynahate_dev = interleave_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_interleaved_dynahate_test = interleave_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_interleaved_dynahate_train = interleave_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_dynahate_dev = interleave_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_dynahate_test = interleave_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_interleaved_olid_train = interleave_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_interleaved_olid_dev = interleave_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_interleaved_olid_test = interleave_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_interleaved_olid_train = interleave_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_interleaved_olid_dev = interleave_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_interleaved_olid_test = interleave_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_interleaved_olid_train = interleave_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_interleaved_olid_dev = interleave_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_interleaved_olid_test = interleave_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_interleaved_olid_train = interleave_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_olid_dev = interleave_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_olid_test = interleave_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_interleaved_latenthatred_train = interleave_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_interleaved_latenthatred_dev = interleave_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_interleaved_latenthatred_test = interleave_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_interleaved_latenthatred_train = interleave_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_interleaved_latenthatred_dev = interleave_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_interleaved_latenthatred_test = interleave_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_interleaved_latenthatred_train = interleave_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_interleaved_latenthatred_dev = interleave_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_interleaved_latenthatred_test = interleave_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_interleaved_latenthatred_train = interleave_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_latenthatred_dev = interleave_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_latenthatred_test = interleave_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5370, 2304)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_hatebert_bertweet_interleaved_latenthatred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=7)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6973314606741573\n",
      "Accuracy Test:  0.6699029126213593\n",
      "Weighted F1 Train Dev:  0.6975788570311768\n",
      "Weighted F1 Test:  0.6703772585928595\n",
      "Macro F1 Train Dev:  0.6961527499318289\n",
      "Macro F1 Test:  0.6675582882479434\n",
      "Micro F1 Train Dev:  0.6973314606741573\n",
      "Micro F1 Test:  0.6699029126213593\n",
      "Weighted Recall Train Dev:  0.6973314606741573\n",
      "Weighted Recall Test:  0.6699029126213593\n",
      "Macro Recall Train Dev:  0.6965936413577092\n",
      "Macro Recall Test:  0.6682360649243299\n",
      "Micro Recall Train Dev:  0.6973314606741573\n",
      "Micro Recall Test:  0.6699029126213593\n",
      "Confusion Matrix Train Dev: \n",
      "[[11756  5361]\n",
      " [ 5845 14062]]\n",
      "Confusion Matrix Test: \n",
      "[[1207  645]\n",
      " [ 715 1553]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_interleaved_dynahate_train_dev = np.concatenate((bert_bertweet_interleaved_dynahate_train, bert_bertweet_interleaved_dynahate_dev))\n",
    "bert_bertweet_interleaved_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_interleaved_dynahate_train_dev, bert_bertweet_interleaved_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_interleaved_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_interleaved_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_interleaved_dynahate\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_interleaved_dynahate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7202979515828678\n",
      "Accuracy Test:  0.7044692737430167\n",
      "Weighted F1 Train Dev:  0.6948439832954735\n",
      "Weighted F1 Test:  0.6760859648391471\n",
      "Macro F1 Train Dev:  0.4853464659246973\n",
      "Macro F1 Test:  0.45857413952010906\n",
      "Micro F1 Train Dev:  0.7202979515828678\n",
      "Micro F1 Test:  0.7044692737430167\n",
      "Weighted Recall Train Dev:  0.7202979515828678\n",
      "Weighted Recall Test:  0.7044692737430167\n",
      "Macro Recall Train Dev:  0.4801404994635365\n",
      "Macro Recall Test:  0.4581554331965854\n",
      "Micro Recall Train Dev:  0.7202979515828678\n",
      "Micro Recall Test:  0.7044692737430167\n",
      "Confusion Matrix Train Dev: \n",
      "[[8811 1128    6]\n",
      " [2573 2762   12]\n",
      " [ 380  407   31]]\n",
      "Confusion Matrix Test: \n",
      "[[2954  390    2]\n",
      " [ 924  823    6]\n",
      " [ 121  144    6]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_interleaved_latenthatred_train_dev = np.concatenate((bert_bertweet_interleaved_latenthatred_train, bert_bertweet_interleaved_latenthatred_dev))\n",
    "bert_bertweet_interleaved_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_interleaved_latenthatred_train_dev, bert_bertweet_interleaved_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_interleaved_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_interleaved_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_interleaved_latenthatred\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_interleaved_latenthatred\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7707703927492447\n",
      "Accuracy Test:  0.8174418604651162\n",
      "Weighted F1 Train Dev:  0.7646696195903286\n",
      "Weighted F1 Test:  0.8045084985053871\n",
      "Macro F1 Train Dev:  0.7289813022970655\n",
      "Macro F1 Test:  0.7438334670893737\n",
      "Micro F1 Train Dev:  0.7707703927492449\n",
      "Micro F1 Test:  0.8174418604651161\n",
      "Weighted Recall Train Dev:  0.7707703927492447\n",
      "Weighted Recall Test:  0.8174418604651162\n",
      "Macro Recall Train Dev:  0.7200653023447141\n",
      "Macro Recall Test:  0.7214381720430108\n",
      "Micro Recall Train Dev:  0.7707703927492447\n",
      "Micro Recall Test:  0.8174418604651162\n",
      "Confusion Matrix Train Dev: \n",
      "[[7702 1138]\n",
      " [1897 2503]]\n",
      "Confusion Matrix Test: \n",
      "[[582  38]\n",
      " [119 121]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_interleaved_olid_train_dev = np.concatenate((bert_bertweet_interleaved_olid_train, bert_bertweet_interleaved_olid_dev))\n",
    "bert_bertweet_interleaved_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_interleaved_olid_train_dev, bert_bertweet_interleaved_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_interleaved_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_interleaved_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_interleaved_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_interleaved_olid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.707460025929127\n",
      "Accuracy Test:  0.6861650485436893\n",
      "Weighted F1 Train Dev:  0.7049990512931114\n",
      "Weighted F1 Test:  0.683973961579324\n",
      "Macro F1 Train Dev:  0.7019433685007286\n",
      "Macro F1 Test:  0.6792017512276172\n",
      "Micro F1 Train Dev:  0.707460025929127\n",
      "Micro F1 Test:  0.6861650485436893\n",
      "Weighted Recall Train Dev:  0.707460025929127\n",
      "Weighted Recall Test:  0.6861650485436893\n",
      "Macro Recall Train Dev:  0.7011897855847005\n",
      "Macro Recall Test:  0.6782033627785968\n",
      "Micro Recall Train Dev:  0.707460025929127\n",
      "Micro Recall Test:  0.6861650485436893\n",
      "Confusion Matrix Train Dev: \n",
      "[[10578  6539]\n",
      " [ 4292 15615]]\n",
      "Confusion Matrix Test: \n",
      "[[1110  742]\n",
      " [ 551 1717]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_interleaved_dynahate_train_dev = np.concatenate((bert_hatebert_interleaved_dynahate_train, bert_hatebert_interleaved_dynahate_dev))\n",
    "bert_hatebert_interleaved_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_interleaved_dynahate_train_dev, bert_hatebert_interleaved_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_interleaved_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_interleaved_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_interleaved_dynahate\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_interleaved_dynahate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7127870887647424\n",
      "Accuracy Test:  0.6918063314711359\n",
      "Weighted F1 Train Dev:  0.6836828246129403\n",
      "Weighted F1 Test:  0.6616025896052177\n",
      "Macro F1 Train Dev:  0.4716090898739498\n",
      "Macro F1 Test:  0.45251182566969855\n",
      "Micro F1 Train Dev:  0.7127870887647423\n",
      "Micro F1 Test:  0.6918063314711359\n",
      "Weighted Recall Train Dev:  0.7127870887647424\n",
      "Weighted Recall Test:  0.6918063314711359\n",
      "Macro Recall Train Dev:  0.4680181056112525\n",
      "Macro Recall Test:  0.4490690348123025\n",
      "Micro Recall Train Dev:  0.7127870887647424\n",
      "Micro Recall Test:  0.6918063314711359\n",
      "Confusion Matrix Train Dev: \n",
      "[[8910 1027    8]\n",
      " [2794 2547    6]\n",
      " [ 356  436   26]]\n",
      "Confusion Matrix Test: \n",
      "[[2946  396    4]\n",
      " [ 991  760    2]\n",
      " [ 129  133    9]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_interleaved_latenthatred_train_dev = np.concatenate((bert_hatebert_interleaved_latenthatred_train, bert_hatebert_interleaved_latenthatred_dev))\n",
    "bert_hatebert_interleaved_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_interleaved_latenthatred_train_dev, bert_hatebert_interleaved_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_interleaved_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_interleaved_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_interleaved_latenthatred\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_interleaved_latenthatred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7639728096676737\n",
      "Accuracy Test:  0.7872093023255814\n",
      "Weighted F1 Train Dev:  0.755719618351784\n",
      "Weighted F1 Test:  0.76271734364365\n",
      "Macro F1 Train Dev:  0.7171061626694332\n",
      "Macro F1 Test:  0.6817873932163979\n",
      "Micro F1 Train Dev:  0.7639728096676736\n",
      "Micro F1 Test:  0.7872093023255814\n",
      "Weighted Recall Train Dev:  0.7639728096676737\n",
      "Weighted Recall Test:  0.7872093023255814\n",
      "Macro Recall Train Dev:  0.7069842657342658\n",
      "Macro Recall Test:  0.6621639784946236\n",
      "Micro Recall Train Dev:  0.7639728096676737\n",
      "Micro Recall Test:  0.7872093023255814\n",
      "Confusion Matrix Train Dev: \n",
      "[[7752 1088]\n",
      " [2037 2363]]\n",
      "Confusion Matrix Test: \n",
      "[[586  34]\n",
      " [149  91]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_interleaved_olid_train_dev = np.concatenate((bert_hatebert_interleaved_olid_train, bert_hatebert_interleaved_olid_dev))\n",
    "bert_hatebert_interleaved_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_interleaved_olid_train_dev, bert_hatebert_interleaved_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_interleaved_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_interleaved_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_interleaved_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_interleaved_olid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7410868625756266\n",
      "Accuracy Test:  0.7048543689320388\n",
      "Weighted F1 Train Dev:  0.7412176779633145\n",
      "Weighted F1 Test:  0.7054289816262611\n",
      "Macro F1 Train Dev:  0.7398856526653244\n",
      "Macro F1 Test:  0.703173897845162\n",
      "Micro F1 Train Dev:  0.7410868625756265\n",
      "Micro F1 Test:  0.7048543689320388\n",
      "Weighted Recall Train Dev:  0.7410868625756266\n",
      "Weighted Recall Test:  0.7048543689320388\n",
      "Macro Recall Train Dev:  0.7401690689890499\n",
      "Macro Recall Test:  0.7044388829845993\n",
      "Micro Recall Train Dev:  0.7410868625756266\n",
      "Micro Recall Test:  0.7048543689320388\n",
      "Confusion Matrix Train Dev: \n",
      "[[12461  4656]\n",
      " [ 4930 14977]]\n",
      "Confusion Matrix Test: \n",
      "[[1297  555]\n",
      " [ 661 1607]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_interleaved_dynahate_train_dev = np.concatenate((hatebert_bertweet_interleaved_dynahate_train, hatebert_bertweet_interleaved_dynahate_dev))\n",
    "hatebert_bertweet_interleaved_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_interleaved_dynahate_train_dev, hatebert_bertweet_interleaved_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_interleaved_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_interleaved_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_interleaved_dynahate\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_interleaved_dynahate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7150217256362508\n",
      "Accuracy Test:  0.6964618249534451\n",
      "Weighted F1 Train Dev:  0.6934980136822416\n",
      "Weighted F1 Test:  0.6727028038051881\n",
      "Macro F1 Train Dev:  0.5186072721279694\n",
      "Macro F1 Test:  0.4972429294388078\n",
      "Micro F1 Train Dev:  0.7150217256362508\n",
      "Micro F1 Test:  0.6964618249534451\n",
      "Weighted Recall Train Dev:  0.7150217256362508\n",
      "Weighted Recall Test:  0.6964618249534451\n",
      "Macro Recall Train Dev:  0.4982560833664416\n",
      "Macro Recall Test:  0.478735434734008\n",
      "Micro Recall Train Dev:  0.7150217256362508\n",
      "Micro Recall Test:  0.6964618249534451\n",
      "Confusion Matrix Train Dev: \n",
      "[[8789 1112   44]\n",
      " [2654 2633   60]\n",
      " [ 365  356   97]]\n",
      "Confusion Matrix Test: \n",
      "[[2935  393   18]\n",
      " [ 955  773   25]\n",
      " [ 118  121   32]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_interleaved_latenthatred_train_dev = np.concatenate((hatebert_bertweet_interleaved_latenthatred_train, hatebert_bertweet_interleaved_latenthatred_dev))\n",
    "hatebert_bertweet_interleaved_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_interleaved_latenthatred_train_dev, hatebert_bertweet_interleaved_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_interleaved_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_interleaved_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_interleaved_latenthatred\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_interleaved_latenthatred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7789274924471299\n",
      "Accuracy Test:  0.7988372093023256\n",
      "Weighted F1 Train Dev:  0.7625355651690972\n",
      "Weighted F1 Test:  0.7744889173685495\n",
      "Macro F1 Train Dev:  0.7190327814784423\n",
      "Macro F1 Test:  0.6967380691766595\n",
      "Micro F1 Train Dev:  0.7789274924471299\n",
      "Micro F1 Test:  0.7988372093023256\n",
      "Weighted Recall Train Dev:  0.7789274924471299\n",
      "Weighted Recall Test:  0.7988372093023256\n",
      "Macro Recall Train Dev:  0.7031725627313863\n",
      "Macro Recall Test:  0.6740591397849462\n",
      "Micro Recall Train Dev:  0.7789274924471299\n",
      "Micro Recall Test:  0.7988372093023256\n",
      "Confusion Matrix Train Dev: \n",
      "[[8213  627]\n",
      " [2300 2100]]\n",
      "Confusion Matrix Test: \n",
      "[[593  27]\n",
      " [146  94]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_interleaved_olid_train_dev = np.concatenate((hatebert_bertweet_interleaved_olid_train, hatebert_bertweet_interleaved_olid_dev))\n",
    "hatebert_bertweet_interleaved_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_interleaved_olid_train_dev, hatebert_bertweet_interleaved_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_interleaved_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_interleaved_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_interleaved_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_interleaved_olid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7430585566119274\n",
      "Accuracy Test:  0.6990291262135923\n",
      "Weighted F1 Train Dev:  0.7419861189171056\n",
      "Weighted F1 Test:  0.6981876634219085\n",
      "Macro F1 Train Dev:  0.7397876610416076\n",
      "Macro F1 Test:  0.6943827881899478\n",
      "Micro F1 Train Dev:  0.7430585566119273\n",
      "Micro F1 Test:  0.6990291262135923\n",
      "Weighted Recall Train Dev:  0.7430585566119274\n",
      "Weighted Recall Test:  0.6990291262135923\n",
      "Macro Recall Train Dev:  0.7388052331405532\n",
      "Macro Recall Test:  0.6936511745727009\n",
      "Micro Recall Train Dev:  0.7430585566119274\n",
      "Micro Recall Test:  0.6990291262135923\n",
      "Confusion Matrix Train Dev: \n",
      "[[11680  5437]\n",
      " [ 4076 15831]]\n",
      "Confusion Matrix Test: \n",
      "[[1186  666]\n",
      " [ 574 1694]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_interleaved_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_interleaved_dynahate_train, bert_hatebert_bertweet_interleaved_dynahate_dev))\n",
    "bert_bertweet_hatebert_interleaved_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_interleaved_dynahate_train_dev, bert_bertweet_hatebert_interleaved_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_interleaved_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_interleaved_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_interleaved_dynahate\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_interleaved_dynahate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7118559900682806\n",
      "Accuracy Test:  0.6899441340782123\n",
      "Weighted F1 Train Dev:  0.6911149051770351\n",
      "Weighted F1 Test:  0.6685199868851459\n",
      "Macro F1 Train Dev:  0.47505176525570153\n",
      "Macro F1 Test:  0.4482138528985112\n",
      "Micro F1 Train Dev:  0.7118559900682806\n",
      "Micro F1 Test:  0.6899441340782123\n",
      "Weighted Recall Train Dev:  0.7118559900682806\n",
      "Weighted Recall Test:  0.6899441340782123\n",
      "Macro Recall Train Dev:  0.47818682384572986\n",
      "Macro Recall Test:  0.4550973331188053\n",
      "Micro Recall Train Dev:  0.7118559900682806\n",
      "Micro Recall Test:  0.6899441340782123\n",
      "Confusion Matrix Train Dev: \n",
      "[[8405 1534    6]\n",
      " [2298 3047    2]\n",
      " [ 323  479   16]]\n",
      "Confusion Matrix Test: \n",
      "[[2778  568    0]\n",
      " [ 826  925    2]\n",
      " [ 106  163    2]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_interleaved_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_interleaved_latenthatred_train, bert_hatebert_bertweet_interleaved_latenthatred_dev))\n",
    "bert_bertweet_hatebert_interleaved_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_interleaved_latenthatred_train_dev, bert_bertweet_hatebert_interleaved_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_interleaved_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_interleaved_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_interleaved_latenthatred\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_interleaved_latenthatred\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7802114803625377\n",
      "Accuracy Test:  0.8046511627906977\n",
      "Weighted F1 Train Dev:  0.7698445597774969\n",
      "Weighted F1 Test:  0.7830155377794796\n",
      "Macro F1 Train Dev:  0.7314869536128457\n",
      "Macro F1 Test:  0.7096089529199897\n",
      "Micro F1 Train Dev:  0.7802114803625377\n",
      "Micro F1 Test:  0.8046511627906977\n",
      "Weighted Recall Train Dev:  0.7802114803625377\n",
      "Weighted Recall Test:  0.8046511627906977\n",
      "Macro Recall Train Dev:  0.7181175442204855\n",
      "Macro Recall Test:  0.685752688172043\n",
      "Micro Recall Train Dev:  0.7802114803625377\n",
      "Micro Recall Test:  0.8046511627906977\n",
      "Confusion Matrix Train Dev: \n",
      "[[7985  855]\n",
      " [2055 2345]]\n",
      "Confusion Matrix Test: \n",
      "[[592  28]\n",
      " [140 100]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_interleaved_olid_train_dev = np.concatenate((bert_hatebert_bertweet_interleaved_olid_train, bert_hatebert_bertweet_interleaved_olid_dev))\n",
    "bert_bertweet_hatebert_interleaved_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_interleaved_olid_train_dev, bert_bertweet_hatebert_interleaved_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_interleaved_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_interleaved_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_interleaved_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_interleaved_olid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60376b4f6a889c7c18c5269982bf59a6dce4489e4bd41e29110865ea8d913ab2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
