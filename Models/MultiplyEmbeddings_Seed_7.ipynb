{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # Numpy multiplication\n",
    "    return np.multiply(embeddings1, embeddings2)\n",
    "\n",
    "def multiply_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    # Numpy multiplication\n",
    "    return np.multiply(embeddings1, np.multiply(embeddings2, embeddings3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_multiplied_dynahate_train = multiply_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_multiplied_dynahate_dev = multiply_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_multiplied_dynahate_test = multiply_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_dynahate_train = multiply_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_multiplied_dynahate_dev = multiply_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_multiplied_dynahate_test = multiply_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_dynahate_train = multiply_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_multiplied_dynahate_dev = multiply_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_dynahate_test = multiply_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_dynahate_train = multiply_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_dynahate_dev = multiply_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_dynahate_test = multiply_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_multiplied_olid_train = multiply_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_multiplied_olid_dev = multiply_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_multiplied_olid_test = multiply_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_olid_train = multiply_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_multiplied_olid_dev = multiply_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_multiplied_olid_test = multiply_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_olid_train = multiply_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_multiplied_olid_dev = multiply_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_olid_test = multiply_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_olid_train = multiply_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_olid_dev = multiply_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_olid_test = multiply_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_multiplied_latenthatred_train = multiply_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_multiplied_latenthatred_dev = multiply_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_multiplied_latenthatred_test = multiply_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_latenthatred_train = multiply_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_multiplied_latenthatred_dev = multiply_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_multiplied_latenthatred_test = multiply_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_latenthatred_train = multiply_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_multiplied_latenthatred_dev = multiply_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_latenthatred_test = multiply_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_train = multiply_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_dev = multiply_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_test = multiply_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=7)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7621272687986171\n",
      "Accuracy Test:  0.6555825242718447\n",
      "Weighted F1 Train Dev:  0.7624575031321679\n",
      "Weighted F1 Test:  0.6563858905283342\n",
      "Macro F1 Train Dev:  0.7618841653657668\n",
      "Macro F1 Test:  0.6551435099978522\n",
      "Micro F1 Train Dev:  0.7621272687986171\n",
      "Micro F1 Test:  0.6555825242718447\n",
      "Weighted Recall Train Dev:  0.7621272687986171\n",
      "Weighted Recall Test:  0.6555825242718447\n",
      "Macro Recall Train Dev:  0.7640582441483705\n",
      "Macro Recall Test:  0.6586953996061267\n",
      "Micro Recall Train Dev:  0.7621272687986171\n",
      "Micro Recall Test:  0.6555825242718447\n",
      "Confusion Matrix Train Dev: \n",
      "[[13517  3600]\n",
      " [ 5207 14700]]\n",
      "Confusion Matrix Test: \n",
      "[[1277  575]\n",
      " [ 844 1424]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_dynahate_train_dev = np.concatenate((bert_bertweet_multiplied_dynahate_train, bert_bertweet_multiplied_dynahate_dev))\n",
    "bert_bertweet_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_dynahate_train_dev, bert_bertweet_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_multiplied_dynahate_seed_7\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_dynahate_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7633767846058349\n",
      "Accuracy Test:  0.6929236499068901\n",
      "Weighted F1 Train Dev:  0.7494971443631945\n",
      "Weighted F1 Test:  0.6746950668277012\n",
      "Macro F1 Train Dev:  0.6101472763421486\n",
      "Macro F1 Test:  0.5078609463519149\n",
      "Micro F1 Train Dev:  0.7633767846058349\n",
      "Micro F1 Test:  0.6929236499068901\n",
      "Weighted Recall Train Dev:  0.7633767846058349\n",
      "Weighted Recall Test:  0.6929236499068901\n",
      "Macro Recall Train Dev:  0.5751394847022518\n",
      "Macro Recall Test:  0.49018465246104626\n",
      "Micro Recall Train Dev:  0.7633767846058349\n",
      "Micro Recall Test:  0.6929236499068901\n",
      "Confusion Matrix Train Dev: \n",
      "[[8980  931   34]\n",
      " [2146 3123   78]\n",
      " [ 339  284  195]]\n",
      "Confusion Matrix Test: \n",
      "[[2872  448   26]\n",
      " [ 896  808   49]\n",
      " [ 112  118   41]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_latenthatred_train_dev = np.concatenate((bert_bertweet_multiplied_latenthatred_train, bert_bertweet_multiplied_latenthatred_dev))\n",
    "bert_bertweet_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_latenthatred_train_dev, bert_bertweet_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_multiplied_latenthatred_seed_7\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_latenthatred_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7766616314199396\n",
      "Accuracy Test:  0.786046511627907\n",
      "Weighted F1 Train Dev:  0.7660007456732917\n",
      "Weighted F1 Test:  0.7721001618787737\n",
      "Macro F1 Train Dev:  0.7269137657268695\n",
      "Macro F1 Test:  0.7023684131331067\n",
      "Micro F1 Train Dev:  0.7766616314199396\n",
      "Micro F1 Test:  0.786046511627907\n",
      "Weighted Recall Train Dev:  0.7766616314199396\n",
      "Weighted Recall Test:  0.786046511627907\n",
      "Macro Recall Train Dev:  0.7138039901275195\n",
      "Macro Recall Test:  0.6856182795698925\n",
      "Micro Recall Train Dev:  0.7766616314199396\n",
      "Micro Recall Test:  0.786046511627907\n",
      "Confusion Matrix Train Dev: \n",
      "[[7967  873]\n",
      " [2084 2316]]\n",
      "Confusion Matrix Test: \n",
      "[[566  54]\n",
      " [130 110]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_olid_train_dev = np.concatenate((bert_bertweet_multiplied_olid_train, bert_bertweet_multiplied_olid_dev))\n",
    "bert_bertweet_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_olid_train_dev, bert_bertweet_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_multiplied_olid_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_olid_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7265557476231633\n",
      "Accuracy Test:  0.6771844660194175\n",
      "Weighted F1 Train Dev:  0.7226675811641364\n",
      "Weighted F1 Test:  0.6729315614391645\n",
      "Macro F1 Train Dev:  0.7192562653085752\n",
      "Macro F1 Test:  0.6670732557921938\n",
      "Micro F1 Train Dev:  0.7265557476231633\n",
      "Micro F1 Test:  0.6771844660194175\n",
      "Weighted Recall Train Dev:  0.7265557476231633\n",
      "Weighted Recall Test:  0.6771844660194175\n",
      "Macro Recall Train Dev:  0.7184847438585567\n",
      "Macro Recall Test:  0.6663819275410348\n",
      "Micro Recall Train Dev:  0.7265557476231633\n",
      "Micro Recall Test:  0.6771844660194175\n",
      "Confusion Matrix Train Dev: \n",
      "[[10465  6652]\n",
      " [ 3472 16435]]\n",
      "Confusion Matrix Test: \n",
      "[[1036  816]\n",
      " [ 514 1754]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_dynahate_train_dev = np.concatenate((bert_hatebert_multiplied_dynahate_train, bert_hatebert_multiplied_dynahate_dev))\n",
    "bert_hatebert_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_dynahate_train_dev, bert_hatebert_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_multiplied_dynahate_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_dynahate_seed_7\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7153941651148356\n",
      "Accuracy Test:  0.6972067039106146\n",
      "Weighted F1 Train Dev:  0.6942106835697914\n",
      "Weighted F1 Test:  0.6755893285460162\n",
      "Macro F1 Train Dev:  0.48833475817456784\n",
      "Macro F1 Test:  0.4729291451827023\n",
      "Micro F1 Train Dev:  0.7153941651148356\n",
      "Micro F1 Test:  0.6972067039106146\n",
      "Weighted Recall Train Dev:  0.7153941651148356\n",
      "Weighted Recall Test:  0.6972067039106146\n",
      "Macro Recall Train Dev:  0.48388907431585465\n",
      "Macro Recall Test:  0.4674800856531944\n",
      "Micro Recall Train Dev:  0.7153941651148356\n",
      "Micro Recall Test:  0.6972067039106146\n",
      "Confusion Matrix Train Dev: \n",
      "[[8546 1385   14]\n",
      " [2396 2945    6]\n",
      " [ 333  451   34]]\n",
      "Confusion Matrix Test: \n",
      "[[2838  503    5]\n",
      " [ 856  894    3]\n",
      " [ 119  140   12]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_latenthatred_train_dev = np.concatenate((bert_hatebert_multiplied_latenthatred_train, bert_hatebert_multiplied_latenthatred_dev))\n",
    "bert_hatebert_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_latenthatred_train_dev, bert_hatebert_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_multiplied_latenthatred_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_latenthatred_seed_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7533232628398792\n",
      "Accuracy Test:  0.7988372093023256\n",
      "Weighted F1 Train Dev:  0.7325424156350877\n",
      "Weighted F1 Test:  0.7693545362625241\n",
      "Macro F1 Train Dev:  0.6820681478072577\n",
      "Macro F1 Test:  0.6863662714097496\n",
      "Micro F1 Train Dev:  0.7533232628398792\n",
      "Micro F1 Test:  0.7988372093023256\n",
      "Weighted Recall Train Dev:  0.7533232628398792\n",
      "Weighted Recall Test:  0.7988372093023256\n",
      "Macro Recall Train Dev:  0.6699007610037022\n",
      "Macro Recall Test:  0.6638440860215054\n",
      "Micro Recall Train Dev:  0.7533232628398792\n",
      "Micro Recall Test:  0.7988372093023256\n",
      "Confusion Matrix Train Dev: \n",
      "[[8121  719]\n",
      " [2547 1853]]\n",
      "Confusion Matrix Test: \n",
      "[[601  19]\n",
      " [154  86]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_olid_train_dev = np.concatenate((bert_hatebert_multiplied_olid_train, bert_hatebert_multiplied_olid_dev))\n",
    "bert_hatebert_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_olid_train_dev, bert_hatebert_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_multiplied_olid_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_olid_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7243409680207433\n",
      "Accuracy Test:  0.6861650485436893\n",
      "Weighted F1 Train Dev:  0.7242454438011822\n",
      "Weighted F1 Test:  0.6867405954337112\n",
      "Macro F1 Train Dev:  0.7225797402225869\n",
      "Macro F1 Test:  0.6842722706270192\n",
      "Micro F1 Train Dev:  0.7243409680207433\n",
      "Micro F1 Test:  0.6861650485436893\n",
      "Weighted Recall Train Dev:  0.7243409680207433\n",
      "Weighted Recall Test:  0.6861650485436893\n",
      "Macro Recall Train Dev:  0.7224391545357292\n",
      "Macro Recall Test:  0.6853342208813771\n",
      "Micro Recall Train Dev:  0.7243409680207433\n",
      "Micro Recall Test:  0.6861650485436893\n",
      "Confusion Matrix Train Dev: \n",
      "[[11934  5183]\n",
      " [ 5023 14884]]\n",
      "Confusion Matrix Test: \n",
      "[[1254  598]\n",
      " [ 695 1573]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_dynahate_train_dev = np.concatenate((hatebert_bertweet_multiplied_dynahate_train, hatebert_bertweet_multiplied_dynahate_dev))\n",
    "hatebert_bertweet_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_dynahate_train_dev, hatebert_bertweet_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_multiplied_dynahate_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_dynahate_seed_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7014897579143389\n",
      "Accuracy Test:  0.6942271880819367\n",
      "Weighted F1 Train Dev:  0.6594937368245172\n",
      "Weighted F1 Test:  0.6501573523217258\n",
      "Macro F1 Train Dev:  0.4344332572077865\n",
      "Macro F1 Test:  0.4236403196224852\n",
      "Micro F1 Train Dev:  0.7014897579143389\n",
      "Micro F1 Test:  0.6942271880819367\n",
      "Weighted Recall Train Dev:  0.7014897579143389\n",
      "Weighted Recall Test:  0.6942271880819367\n",
      "Macro Recall Train Dev:  0.43985548673182445\n",
      "Macro Recall Test:  0.4299143603229869\n",
      "Micro Recall Train Dev:  0.7014897579143389\n",
      "Micro Recall Test:  0.6942271880819367\n",
      "Confusion Matrix Train Dev: \n",
      "[[9230  715    0]\n",
      " [3279 2067    1]\n",
      " [ 488  326    4]]\n",
      "Confusion Matrix Test: \n",
      "[[3093  253    0]\n",
      " [1119  634    0]\n",
      " [ 175   95    1]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_latenthatred_train_dev = np.concatenate((hatebert_bertweet_multiplied_latenthatred_train, hatebert_bertweet_multiplied_latenthatred_dev))\n",
    "hatebert_bertweet_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_latenthatred_train_dev, hatebert_bertweet_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_multiplied_latenthatred_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_latenthatred_seed_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7843655589123867\n",
      "Accuracy Test:  0.8116279069767441\n",
      "Weighted F1 Train Dev:  0.7784809845932034\n",
      "Weighted F1 Test:  0.8013725250341815\n",
      "Macro F1 Train Dev:  0.7447680684936246\n",
      "Macro F1 Test:  0.7423263865770025\n",
      "Micro F1 Train Dev:  0.7843655589123867\n",
      "Micro F1 Test:  0.8116279069767441\n",
      "Weighted Recall Train Dev:  0.7843655589123867\n",
      "Weighted Recall Test:  0.8116279069767441\n",
      "Macro Recall Train Dev:  0.7349264705882352\n",
      "Macro Recall Test:  0.7237903225806452\n",
      "Micro Recall Train Dev:  0.7843655589123867\n",
      "Micro Recall Test:  0.8116279069767441\n",
      "Confusion Matrix Train Dev: \n",
      "[[7800 1040]\n",
      " [1815 2585]]\n",
      "Confusion Matrix Test: \n",
      "[[572  48]\n",
      " [114 126]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_olid_train_dev = np.concatenate((hatebert_bertweet_multiplied_olid_train, hatebert_bertweet_multiplied_olid_dev))\n",
    "hatebert_bertweet_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_olid_train_dev, hatebert_bertweet_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_multiplied_olid_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_olid_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7627484874675886\n",
      "Accuracy Test:  0.6740291262135922\n",
      "Weighted F1 Train Dev:  0.763005372075428\n",
      "Weighted F1 Test:  0.674832096322329\n",
      "Macro F1 Train Dev:  0.7619987596374058\n",
      "Macro F1 Test:  0.6734797256128775\n",
      "Micro F1 Train Dev:  0.7627484874675886\n",
      "Micro F1 Test:  0.6740291262135922\n",
      "Weighted Recall Train Dev:  0.7627484874675886\n",
      "Weighted Recall Test:  0.6740291262135922\n",
      "Macro Recall Train Dev:  0.7628509755618049\n",
      "Macro Recall Test:  0.6767872855885815\n",
      "Micro Recall Train Dev:  0.7627484874675886\n",
      "Micro Recall Test:  0.6740291262135922\n",
      "Confusion Matrix Train Dev: \n",
      "[[13081  4036]\n",
      " [ 4748 15159]]\n",
      "Confusion Matrix Test: \n",
      "[[1304  548]\n",
      " [ 795 1473]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_dynahate_train, bert_hatebert_bertweet_multiplied_dynahate_dev))\n",
    "bert_bertweet_hatebert_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_dynahate_train_dev, bert_bertweet_hatebert_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_multiplied_dynahate_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_dynahate_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7095592799503414\n",
      "Accuracy Test:  0.6966480446927374\n",
      "Weighted F1 Train Dev:  0.6757358770726692\n",
      "Weighted F1 Test:  0.6595785845129077\n",
      "Macro F1 Train Dev:  0.47073886232245093\n",
      "Macro F1 Test:  0.4510222965033594\n",
      "Micro F1 Train Dev:  0.7095592799503414\n",
      "Micro F1 Test:  0.6966480446927374\n",
      "Weighted Recall Train Dev:  0.7095592799503414\n",
      "Weighted Recall Test:  0.6966480446927374\n",
      "Macro Recall Train Dev:  0.46301110391705474\n",
      "Macro Recall Test:  0.4460904533454655\n",
      "Micro Recall Train Dev:  0.7095592799503414\n",
      "Micro Recall Test:  0.6966480446927374\n",
      "Confusion Matrix Train Dev: \n",
      "[[9091  849    5]\n",
      " [3037 2304    6]\n",
      " [ 449  333   36]]\n",
      "Confusion Matrix Test: \n",
      "[[3045  298    3]\n",
      " [1065  686    2]\n",
      " [ 161  100   10]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_latenthatred_train, bert_hatebert_bertweet_multiplied_latenthatred_dev))\n",
    "bert_bertweet_hatebert_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_latenthatred_train_dev, bert_bertweet_hatebert_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_multiplied_latenthatred_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_latenthatred_seed_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.8097432024169184\n",
      "Accuracy Test:  0.7872093023255814\n",
      "Weighted F1 Train Dev:  0.7981322801255034\n",
      "Weighted F1 Test:  0.76271734364365\n",
      "Macro F1 Train Dev:  0.762701012102216\n",
      "Macro F1 Test:  0.6817873932163979\n",
      "Micro F1 Train Dev:  0.8097432024169184\n",
      "Micro F1 Test:  0.7872093023255814\n",
      "Weighted Recall Train Dev:  0.8097432024169184\n",
      "Weighted Recall Test:  0.7872093023255814\n",
      "Macro Recall Train Dev:  0.744114047716989\n",
      "Macro Recall Test:  0.6621639784946236\n",
      "Micro Recall Train Dev:  0.8097432024169184\n",
      "Micro Recall Test:  0.7872093023255814\n",
      "Confusion Matrix Train Dev: \n",
      "[[8308  532]\n",
      " [1987 2413]]\n",
      "Confusion Matrix Test: \n",
      "[[586  34]\n",
      " [149  91]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_olid_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_olid_train, bert_hatebert_bertweet_multiplied_olid_dev))\n",
    "bert_bertweet_hatebert_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_olid_train_dev, bert_bertweet_hatebert_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_multiplied_olid_seed_7\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_olid_seed_7\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
