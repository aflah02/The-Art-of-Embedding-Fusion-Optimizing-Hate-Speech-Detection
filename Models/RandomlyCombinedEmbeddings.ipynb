{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomlycombined_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # new_embeddings = []\n",
    "    # for i in range(len(embeddings1)):\n",
    "    #     embedding = []\n",
    "    #     elements = list(range(len(embeddings1[i])+len(embeddings2[i])))\n",
    "    #     random.shuffle(elements)\n",
    "    #     for j in elements:\n",
    "    #         if j < len(embeddings1[i]):\n",
    "    #             embedding.append(embeddings1[i][j])\n",
    "    #         else:\n",
    "    #             embedding.append(embeddings2[i][j-len(embeddings1[i])])\n",
    "    #     new_embeddings.append(np.array(embedding))\n",
    "    new_embeddings = np.concatenate((embeddings1, embeddings2), axis=1)\n",
    "    # Shuffle values\n",
    "    np.random.shuffle(new_embeddings)\n",
    "    return np.array(new_embeddings)\n",
    "\n",
    "def randomlycombined_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    # new_embeddings = []\n",
    "    # for i in range(len(embeddings1)):\n",
    "    #     embedding = []\n",
    "    #     elements = list(range(len(embeddings1[i])+len(embeddings2[i])+len(embeddings3[i])))\n",
    "    #     random.shuffle(elements)\n",
    "    #     for j in elements:\n",
    "    #         if j < len(embeddings1[i]):\n",
    "    #             embedding.append(embeddings1[i][j])\n",
    "    #         elif j < len(embeddings1[i])+len(embeddings2[i]):\n",
    "    #             embedding.append(embeddings2[i][j-len(embeddings1[i])])\n",
    "    #         else:\n",
    "    #             embedding.append(embeddings3[i][j-len(embeddings1[i])-len(embeddings2[i])])\n",
    "    #     new_embeddings.append(np.array(embedding))\n",
    "    new_embeddings = np.concatenate((embeddings1, embeddings2, embeddings3), axis=1)\n",
    "    # Shuffle values\n",
    "    np.random.shuffle(new_embeddings)\n",
    "    return np.array(new_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_randomlycombined_dynahate_train = randomlycombined_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_randomlycombined_dynahate_dev = randomlycombined_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_randomlycombined_dynahate_test = randomlycombined_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_randomlycombined_dynahate_train = randomlycombined_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_randomlycombined_dynahate_dev = randomlycombined_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_randomlycombined_dynahate_test = randomlycombined_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_randomlycombined_dynahate_train = randomlycombined_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_randomlycombined_dynahate_dev = randomlycombined_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_randomlycombined_dynahate_test = randomlycombined_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_randomlycombined_dynahate_train = randomlycombined_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_randomlycombined_dynahate_dev = randomlycombined_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_randomlycombined_dynahate_test = randomlycombined_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_randomlycombined_olid_train = randomlycombined_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_randomlycombined_olid_dev = randomlycombined_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_randomlycombined_olid_test = randomlycombined_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_randomlycombined_olid_train = randomlycombined_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_randomlycombined_olid_dev = randomlycombined_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_randomlycombined_olid_test = randomlycombined_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_randomlycombined_olid_train = randomlycombined_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_randomlycombined_olid_dev = randomlycombined_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_randomlycombined_olid_test = randomlycombined_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_randomlycombined_olid_train = randomlycombined_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_randomlycombined_olid_dev = randomlycombined_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_randomlycombined_olid_test = randomlycombined_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_randomlycombined_latenthatred_train = randomlycombined_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_randomlycombined_latenthatred_dev = randomlycombined_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_randomlycombined_latenthatred_test = randomlycombined_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_randomlycombined_latenthatred_train = randomlycombined_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_randomlycombined_latenthatred_dev = randomlycombined_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_randomlycombined_latenthatred_test = randomlycombined_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_randomlycombined_latenthatred_train = randomlycombined_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_randomlycombined_latenthatred_dev = randomlycombined_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_randomlycombined_latenthatred_test = randomlycombined_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_randomlycombined_latenthatred_train = randomlycombined_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_randomlycombined_latenthatred_dev = randomlycombined_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_randomlycombined_latenthatred_test = randomlycombined_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32924, 1536)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_hatebert_randomlycombined_dynahate_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32924"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dynahate_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.5345181503889369\n",
      "Accuracy Test:  0.5463592233009709\n",
      "Weighted F1 Train Dev:  0.4031062610319841\n",
      "Weighted F1 Test:  0.41449584415673074\n",
      "Macro F1 Train Dev:  0.3797593958189239\n",
      "Macro F1 Test:  0.3823604219399739\n",
      "Micro F1 Train Dev:  0.5345181503889369\n",
      "Micro F1 Test:  0.5463592233009709\n",
      "Weighted Recall Train Dev:  0.5345181503889369\n",
      "Weighted Recall Test:  0.5463592233009709\n",
      "Macro Recall Train Dev:  0.49971420385155524\n",
      "Macro Recall Test:  0.4994214748534403\n",
      "Micro Recall Train Dev:  0.5345181503889369\n",
      "Micro Recall Test:  0.5463592233009709\n",
      "Confusion Matrix Train Dev: \n",
      "[[  648 16469]\n",
      " [  765 19142]]\n",
      "Confusion Matrix Test: \n",
      "[[  64 1788]\n",
      " [  81 2187]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_randomlycombined_dynahate_train_dev = np.concatenate((bert_bertweet_randomlycombined_dynahate_train, bert_bertweet_randomlycombined_dynahate_dev))\n",
    "bert_bertweet_randomlycombined_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_randomlycombined_dynahate_train_dev, dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_randomlycombined_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_randomlycombined_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_randomlycombined_dynahate\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_randomlycombined_dynahate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37024"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dynahate_labels_train_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32924, 4100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_bertweet_randomlycombined_dynahate_train), len(bert_bertweet_randomlycombined_dynahate_dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.61731843575419\n",
      "Accuracy Test:  0.6230912476722532\n",
      "Weighted F1 Train Dev:  0.471251724703544\n",
      "Weighted F1 Test:  0.47839910846979333\n",
      "Macro F1 Train Dev:  0.25446171560161196\n",
      "Macro F1 Test:  0.25592779562490436\n",
      "Micro F1 Train Dev:  0.61731843575419\n",
      "Micro F1 Test:  0.6230912476722532\n",
      "Weighted Recall Train Dev:  0.61731843575419\n",
      "Weighted Recall Test:  0.6230912476722532\n",
      "Macro Recall Train Dev:  0.3333333333333333\n",
      "Macro Recall Test:  0.3333333333333333\n",
      "Micro Recall Train Dev:  0.61731843575419\n",
      "Micro Recall Test:  0.6230912476722532\n",
      "Confusion Matrix Train Dev: \n",
      "[[9945    0    0]\n",
      " [5347    0    0]\n",
      " [ 818    0    0]]\n",
      "Confusion Matrix Test: \n",
      "[[3346    0    0]\n",
      " [1753    0    0]\n",
      " [ 271    0    0]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_randomlycombined_latenthatred_train_dev = np.concatenate((bert_bertweet_randomlycombined_latenthatred_train, bert_bertweet_randomlycombined_latenthatred_dev))\n",
    "bert_bertweet_randomlycombined_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_randomlycombined_latenthatred_train_dev, bert_bertweet_randomlycombined_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_randomlycombined_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_randomlycombined_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_randomlycombined_latenthatred\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_randomlycombined_latenthatred\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6677492447129909\n",
      "Accuracy Test:  0.7209302325581395\n",
      "Weighted F1 Train Dev:  0.5347980315069222\n",
      "Weighted F1 Test:  0.6040226272784412\n",
      "Macro F1 Train Dev:  0.40060767309934203\n",
      "Macro F1 Test:  0.4189189189189189\n",
      "Micro F1 Train Dev:  0.6677492447129909\n",
      "Micro F1 Test:  0.7209302325581395\n",
      "Weighted Recall Train Dev:  0.6677492447129909\n",
      "Weighted Recall Test:  0.7209302325581395\n",
      "Macro Recall Train Dev:  0.5001136363636364\n",
      "Macro Recall Test:  0.5\n",
      "Micro Recall Train Dev:  0.6677492447129909\n",
      "Micro Recall Test:  0.7209302325581395\n",
      "Confusion Matrix Train Dev: \n",
      "[[8840    0]\n",
      " [4399    1]]\n",
      "Confusion Matrix Test: \n",
      "[[620   0]\n",
      " [240   0]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_randomlycombined_olid_train_dev = np.concatenate((bert_bertweet_randomlycombined_olid_train, bert_bertweet_randomlycombined_olid_dev))\n",
    "bert_bertweet_randomlycombined_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_randomlycombined_olid_train_dev, bert_bertweet_randomlycombined_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_randomlycombined_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_randomlycombined_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_randomlycombined_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_randomlycombined_olid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.5376512532411409\n",
      "Accuracy Test:  0.5504854368932038\n",
      "Weighted F1 Train Dev:  0.37615139644344825\n",
      "Weighted F1 Test:  0.3908894711564766\n",
      "Macro F1 Train Dev:  0.34981682014505183\n",
      "Macro F1 Test:  0.3550407013149655\n",
      "Micro F1 Train Dev:  0.5376512532411409\n",
      "Micro F1 Test:  0.5504854368932038\n",
      "Weighted Recall Train Dev:  0.5376512532411409\n",
      "Weighted Recall Test:  0.5504854368932038\n",
      "Macro Recall Train Dev:  0.4999871650061845\n",
      "Macro Recall Test:  0.5\n",
      "Micro Recall Train Dev:  0.5376512532411409\n",
      "Micro Recall Test:  0.5504854368932038\n",
      "Confusion Matrix Train Dev: \n",
      "[[    3 17114]\n",
      " [    4 19903]]\n",
      "Confusion Matrix Test: \n",
      "[[   0 1852]\n",
      " [   0 2268]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_randomlycombined_dynahate_train_dev = np.concatenate((bert_hatebert_randomlycombined_dynahate_train, bert_hatebert_randomlycombined_dynahate_dev))\n",
    "bert_hatebert_randomlycombined_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_randomlycombined_dynahate_train_dev, bert_hatebert_randomlycombined_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_randomlycombined_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_randomlycombined_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_randomlycombined_dynahate\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_randomlycombined_dynahate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.61731843575419\n",
      "Accuracy Test:  0.6230912476722532\n",
      "Weighted F1 Train Dev:  0.471251724703544\n",
      "Weighted F1 Test:  0.47839910846979333\n",
      "Macro F1 Train Dev:  0.25446171560161196\n",
      "Macro F1 Test:  0.25592779562490436\n",
      "Micro F1 Train Dev:  0.61731843575419\n",
      "Micro F1 Test:  0.6230912476722532\n",
      "Weighted Recall Train Dev:  0.61731843575419\n",
      "Weighted Recall Test:  0.6230912476722532\n",
      "Macro Recall Train Dev:  0.3333333333333333\n",
      "Macro Recall Test:  0.3333333333333333\n",
      "Micro Recall Train Dev:  0.61731843575419\n",
      "Micro Recall Test:  0.6230912476722532\n",
      "Confusion Matrix Train Dev: \n",
      "[[9945    0    0]\n",
      " [5347    0    0]\n",
      " [ 818    0    0]]\n",
      "Confusion Matrix Test: \n",
      "[[3346    0    0]\n",
      " [1753    0    0]\n",
      " [ 271    0    0]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_randomlycombined_latenthatred_train_dev = np.concatenate((bert_hatebert_randomlycombined_latenthatred_train, bert_hatebert_randomlycombined_latenthatred_dev))\n",
    "bert_hatebert_randomlycombined_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_randomlycombined_latenthatred_train_dev, bert_hatebert_randomlycombined_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_randomlycombined_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_randomlycombined_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_randomlycombined_latenthatred\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_randomlycombined_latenthatred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6676737160120846\n",
      "Accuracy Test:  0.7209302325581395\n",
      "Weighted F1 Train Dev:  0.5346227943430097\n",
      "Weighted F1 Test:  0.6040226272784412\n",
      "Macro F1 Train Dev:  0.4003623188405797\n",
      "Macro F1 Test:  0.4189189189189189\n",
      "Micro F1 Train Dev:  0.6676737160120846\n",
      "Micro F1 Test:  0.7209302325581395\n",
      "Weighted Recall Train Dev:  0.6676737160120846\n",
      "Weighted Recall Test:  0.7209302325581395\n",
      "Macro Recall Train Dev:  0.5\n",
      "Macro Recall Test:  0.5\n",
      "Micro Recall Train Dev:  0.6676737160120846\n",
      "Micro Recall Test:  0.7209302325581395\n",
      "Confusion Matrix Train Dev: \n",
      "[[8840    0]\n",
      " [4400    0]]\n",
      "Confusion Matrix Test: \n",
      "[[620   0]\n",
      " [240   0]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_randomlycombined_olid_train_dev = np.concatenate((bert_hatebert_randomlycombined_olid_train, bert_hatebert_randomlycombined_olid_dev))\n",
    "bert_hatebert_randomlycombined_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_randomlycombined_olid_train_dev, bert_hatebert_randomlycombined_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_randomlycombined_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_randomlycombined_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_randomlycombined_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_randomlycombined_olid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.5388666810717373\n",
      "Accuracy Test:  0.5495145631067961\n",
      "Weighted F1 Train Dev:  0.3809662197357423\n",
      "Weighted F1 Test:  0.39345816947187595\n",
      "Macro F1 Train Dev:  0.3550168595939371\n",
      "Macro F1 Test:  0.35806042696799006\n",
      "Micro F1 Train Dev:  0.5388666810717373\n",
      "Micro F1 Test:  0.5495145631067961\n",
      "Weighted Recall Train Dev:  0.5388666810717373\n",
      "Weighted Recall Test:  0.5495145631067961\n",
      "Macro Recall Train Dev:  0.5014817807402189\n",
      "Macro Recall Test:  0.4994648047203843\n",
      "Micro Recall Train Dev:  0.5388666810717373\n",
      "Micro Recall Test:  0.5495145631067961\n",
      "Confusion Matrix Train Dev: \n",
      "[[   92 17025]\n",
      " [   48 19859]]\n",
      "Confusion Matrix Test: \n",
      "[[   7 1845]\n",
      " [  11 2257]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_randomlycombined_dynahate_train_dev = np.concatenate((hatebert_bertweet_randomlycombined_dynahate_train, hatebert_bertweet_randomlycombined_dynahate_dev))\n",
    "hatebert_bertweet_randomlycombined_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_randomlycombined_dynahate_train_dev, hatebert_bertweet_randomlycombined_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_randomlycombined_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_randomlycombined_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_randomlycombined_dynahate\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_randomlycombined_dynahate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.61731843575419\n",
      "Accuracy Test:  0.6230912476722532\n",
      "Weighted F1 Train Dev:  0.471251724703544\n",
      "Weighted F1 Test:  0.47839910846979333\n",
      "Macro F1 Train Dev:  0.25446171560161196\n",
      "Macro F1 Test:  0.25592779562490436\n",
      "Micro F1 Train Dev:  0.61731843575419\n",
      "Micro F1 Test:  0.6230912476722532\n",
      "Weighted Recall Train Dev:  0.61731843575419\n",
      "Weighted Recall Test:  0.6230912476722532\n",
      "Macro Recall Train Dev:  0.3333333333333333\n",
      "Macro Recall Test:  0.3333333333333333\n",
      "Micro Recall Train Dev:  0.61731843575419\n",
      "Micro Recall Test:  0.6230912476722532\n",
      "Confusion Matrix Train Dev: \n",
      "[[9945    0    0]\n",
      " [5347    0    0]\n",
      " [ 818    0    0]]\n",
      "Confusion Matrix Test: \n",
      "[[3346    0    0]\n",
      " [1753    0    0]\n",
      " [ 271    0    0]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_randomlycombined_latenthatred_train_dev = np.concatenate((hatebert_bertweet_randomlycombined_latenthatred_train, hatebert_bertweet_randomlycombined_latenthatred_dev))\n",
    "hatebert_bertweet_randomlycombined_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_randomlycombined_latenthatred_train_dev, hatebert_bertweet_randomlycombined_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_randomlycombined_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_randomlycombined_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_randomlycombined_latenthatred\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_randomlycombined_latenthatred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6676737160120846\n",
      "Accuracy Test:  0.7209302325581395\n",
      "Weighted F1 Train Dev:  0.5346227943430097\n",
      "Weighted F1 Test:  0.6040226272784412\n",
      "Macro F1 Train Dev:  0.4003623188405797\n",
      "Macro F1 Test:  0.4189189189189189\n",
      "Micro F1 Train Dev:  0.6676737160120846\n",
      "Micro F1 Test:  0.7209302325581395\n",
      "Weighted Recall Train Dev:  0.6676737160120846\n",
      "Weighted Recall Test:  0.7209302325581395\n",
      "Macro Recall Train Dev:  0.5\n",
      "Macro Recall Test:  0.5\n",
      "Micro Recall Train Dev:  0.6676737160120846\n",
      "Micro Recall Test:  0.7209302325581395\n",
      "Confusion Matrix Train Dev: \n",
      "[[8840    0]\n",
      " [4400    0]]\n",
      "Confusion Matrix Test: \n",
      "[[620   0]\n",
      " [240   0]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_randomlycombined_olid_train_dev = np.concatenate((hatebert_bertweet_randomlycombined_olid_train, hatebert_bertweet_randomlycombined_olid_dev))\n",
    "hatebert_bertweet_randomlycombined_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_randomlycombined_olid_train_dev, hatebert_bertweet_randomlycombined_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_randomlycombined_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_randomlycombined_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_randomlycombined_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_randomlycombined_olid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.5410004321521176\n",
      "Accuracy Test:  0.5434466019417475\n",
      "Weighted F1 Train Dev:  0.4254050025716923\n",
      "Weighted F1 Test:  0.4255652682306326\n",
      "Macro F1 Train Dev:  0.40385828634177595\n",
      "Macro F1 Test:  0.39535045934349533\n",
      "Micro F1 Train Dev:  0.5410004321521176\n",
      "Micro F1 Test:  0.5434466019417475\n",
      "Weighted Recall Train Dev:  0.5410004321521176\n",
      "Weighted Recall Test:  0.5434466019417475\n",
      "Macro Recall Train Dev:  0.5077400735409489\n",
      "Macro Recall Test:  0.49855868673363274\n",
      "Micro Recall Train Dev:  0.5410004321521176\n",
      "Micro Recall Test:  0.5434466019417475\n",
      "Confusion Matrix Train Dev: \n",
      "[[ 1136 15981]\n",
      " [ 1013 18894]]\n",
      "Confusion Matrix Test: \n",
      "[[ 100 1752]\n",
      " [ 129 2139]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_randomlycombined_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_randomlycombined_dynahate_train, bert_hatebert_bertweet_randomlycombined_dynahate_dev))\n",
    "bert_bertweet_hatebert_randomlycombined_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_randomlycombined_dynahate_train_dev, bert_bertweet_hatebert_randomlycombined_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_randomlycombined_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_randomlycombined_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_randomlycombined_dynahate\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_randomlycombined_dynahate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.61731843575419\n",
      "Accuracy Test:  0.6230912476722532\n",
      "Weighted F1 Train Dev:  0.471251724703544\n",
      "Weighted F1 Test:  0.47839910846979333\n",
      "Macro F1 Train Dev:  0.25446171560161196\n",
      "Macro F1 Test:  0.25592779562490436\n",
      "Micro F1 Train Dev:  0.61731843575419\n",
      "Micro F1 Test:  0.6230912476722532\n",
      "Weighted Recall Train Dev:  0.61731843575419\n",
      "Weighted Recall Test:  0.6230912476722532\n",
      "Macro Recall Train Dev:  0.3333333333333333\n",
      "Macro Recall Test:  0.3333333333333333\n",
      "Micro Recall Train Dev:  0.61731843575419\n",
      "Micro Recall Test:  0.6230912476722532\n",
      "Confusion Matrix Train Dev: \n",
      "[[9945    0    0]\n",
      " [5347    0    0]\n",
      " [ 818    0    0]]\n",
      "Confusion Matrix Test: \n",
      "[[3346    0    0]\n",
      " [1753    0    0]\n",
      " [ 271    0    0]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_randomlycombined_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_randomlycombined_latenthatred_train, bert_hatebert_bertweet_randomlycombined_latenthatred_dev))\n",
    "bert_bertweet_hatebert_randomlycombined_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_randomlycombined_latenthatred_train_dev, bert_bertweet_hatebert_randomlycombined_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_randomlycombined_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_randomlycombined_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_randomlycombined_latenthatred\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_randomlycombined_latenthatred\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6676737160120846\n",
      "Accuracy Test:  0.7209302325581395\n",
      "Weighted F1 Train Dev:  0.5346227943430097\n",
      "Weighted F1 Test:  0.6040226272784412\n",
      "Macro F1 Train Dev:  0.4003623188405797\n",
      "Macro F1 Test:  0.4189189189189189\n",
      "Micro F1 Train Dev:  0.6676737160120846\n",
      "Micro F1 Test:  0.7209302325581395\n",
      "Weighted Recall Train Dev:  0.6676737160120846\n",
      "Weighted Recall Test:  0.7209302325581395\n",
      "Macro Recall Train Dev:  0.5\n",
      "Macro Recall Test:  0.5\n",
      "Micro Recall Train Dev:  0.6676737160120846\n",
      "Micro Recall Test:  0.7209302325581395\n",
      "Confusion Matrix Train Dev: \n",
      "[[8840    0]\n",
      " [4400    0]]\n",
      "Confusion Matrix Test: \n",
      "[[620   0]\n",
      " [240   0]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_randomlycombined_olid_train_dev = np.concatenate((bert_hatebert_bertweet_randomlycombined_olid_train, bert_hatebert_bertweet_randomlycombined_olid_dev))\n",
    "bert_bertweet_hatebert_randomlycombined_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_randomlycombined_olid_train_dev, bert_bertweet_hatebert_randomlycombined_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_randomlycombined_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_randomlycombined_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_randomlycombined_olid\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_randomlycombined_olid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
