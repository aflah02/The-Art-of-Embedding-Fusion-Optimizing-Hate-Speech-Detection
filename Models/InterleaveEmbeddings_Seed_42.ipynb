{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleave_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    new_embeddings = []\n",
    "    for i in range(len(embeddings1)):\n",
    "        embedding = []\n",
    "        for j in range(len(embeddings1[i])):\n",
    "            embedding.append(embeddings1[i][j])\n",
    "            embedding.append(embeddings2[i][j])\n",
    "        new_embeddings.append(np.array(embedding))\n",
    "    return np.array(new_embeddings)\n",
    "    \n",
    "\n",
    "def interleave_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    new_embeddings = []\n",
    "    for i in range(len(embeddings1)):\n",
    "        embedding = []\n",
    "        for j in range(len(embeddings1[i])):\n",
    "            embedding.append(embeddings1[i][j])\n",
    "            embedding.append(embeddings2[i][j])\n",
    "            embedding.append(embeddings3[i][j])\n",
    "        new_embeddings.append(np.array(embedding))\n",
    "    return np.array(new_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_interleaved_dynahate_train = interleave_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_interleaved_dynahate_dev = interleave_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_interleaved_dynahate_test = interleave_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_interleaved_dynahate_train = interleave_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_interleaved_dynahate_dev = interleave_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_interleaved_dynahate_test = interleave_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_interleaved_dynahate_train = interleave_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_interleaved_dynahate_dev = interleave_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_interleaved_dynahate_test = interleave_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_interleaved_dynahate_train = interleave_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_dynahate_dev = interleave_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_dynahate_test = interleave_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_interleaved_olid_train = interleave_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_interleaved_olid_dev = interleave_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_interleaved_olid_test = interleave_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_interleaved_olid_train = interleave_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_interleaved_olid_dev = interleave_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_interleaved_olid_test = interleave_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_interleaved_olid_train = interleave_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_interleaved_olid_dev = interleave_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_interleaved_olid_test = interleave_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_interleaved_olid_train = interleave_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_olid_dev = interleave_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_olid_test = interleave_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_interleaved_latenthatred_train = interleave_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_interleaved_latenthatred_dev = interleave_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_interleaved_latenthatred_test = interleave_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_interleaved_latenthatred_train = interleave_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_interleaved_latenthatred_dev = interleave_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_interleaved_latenthatred_test = interleave_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_interleaved_latenthatred_train = interleave_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_interleaved_latenthatred_dev = interleave_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_interleaved_latenthatred_test = interleave_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_interleaved_latenthatred_train = interleave_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_latenthatred_dev = interleave_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_interleaved_latenthatred_test = interleave_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5370, 2304)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_hatebert_bertweet_interleaved_latenthatred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=42)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.6924697493517719\n",
      "Accuracy Test:  0.6696601941747573\n",
      "Weighted F1 Train Dev:  0.6780999075257311\n",
      "Weighted F1 Test:  0.6519720008415162\n",
      "Macro F1 Train Dev:  0.6719109821329163\n",
      "Macro F1 Test:  0.641905942802353\n",
      "Micro F1 Train Dev:  0.6924697493517719\n",
      "Micro F1 Test:  0.6696601941747573\n",
      "Weighted Recall Train Dev:  0.6924697493517719\n",
      "Weighted Recall Test:  0.6696601941747573\n",
      "Macro Recall Train Dev:  0.6774531835346683\n",
      "Macro Recall Test:  0.6481581473482122\n",
      "Micro Recall Train Dev:  0.6924697493517719\n",
      "Micro Recall Test:  0.6696601941747573\n",
      "Confusion Matrix Train Dev: \n",
      "[[ 8185  8932]\n",
      " [ 2454 17453]]\n",
      "Confusion Matrix Test: \n",
      "[[ 806 1046]\n",
      " [ 315 1953]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_interleaved_dynahate_train_dev = np.concatenate((bert_bertweet_interleaved_dynahate_train, bert_bertweet_interleaved_dynahate_dev))\n",
    "bert_bertweet_interleaved_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_interleaved_dynahate_train_dev, bert_bertweet_interleaved_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_interleaved_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_interleaved_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_interleaved_dynahate_seed_42\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_interleaved_dynahate_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7279329608938547\n",
      "Accuracy Test:  0.7080074487895717\n",
      "Weighted F1 Train Dev:  0.7104410384280689\n",
      "Weighted F1 Test:  0.6893742182444357\n",
      "Macro F1 Train Dev:  0.5310261451092892\n",
      "Macro F1 Test:  0.5103472377930791\n",
      "Micro F1 Train Dev:  0.7279329608938547\n",
      "Micro F1 Test:  0.7080074487895716\n",
      "Weighted Recall Train Dev:  0.7279329608938547\n",
      "Weighted Recall Test:  0.7080074487895717\n",
      "Macro Recall Train Dev:  0.5123533547880236\n",
      "Macro Recall Test:  0.4924747737351618\n",
      "Micro Recall Train Dev:  0.7279329608938547\n",
      "Micro Recall Test:  0.7080074487895717\n",
      "Confusion Matrix Train Dev: \n",
      "[[8642 1281   22]\n",
      " [2306 2997   44]\n",
      " [ 316  414   88]]\n",
      "Confusion Matrix Test: \n",
      "[[2879  459    8]\n",
      " [ 838  894   21]\n",
      " [ 107  135   29]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_interleaved_latenthatred_train_dev = np.concatenate((bert_bertweet_interleaved_latenthatred_train, bert_bertweet_interleaved_latenthatred_dev))\n",
    "bert_bertweet_interleaved_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_interleaved_latenthatred_train_dev, bert_bertweet_interleaved_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_interleaved_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_interleaved_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_interleaved_latenthatred_seed_42\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_interleaved_latenthatred_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7759063444108761\n",
      "Accuracy Test:  0.8174418604651162\n",
      "Weighted F1 Train Dev:  0.7658267599180697\n",
      "Weighted F1 Test:  0.8014139679674042\n",
      "Macro F1 Train Dev:  0.7271462455290796\n",
      "Macro F1 Test:  0.7373023979765554\n",
      "Micro F1 Train Dev:  0.7759063444108761\n",
      "Micro F1 Test:  0.8174418604651161\n",
      "Weighted Recall Train Dev:  0.7759063444108761\n",
      "Weighted Recall Test:  0.8174418604651162\n",
      "Macro Recall Train Dev:  0.7144940353763883\n",
      "Macro Recall Test:  0.7124999999999999\n",
      "Micro Recall Train Dev:  0.7759063444108761\n",
      "Micro Recall Test:  0.8174418604651162\n",
      "Confusion Matrix Train Dev: \n",
      "[[7935  905]\n",
      " [2062 2338]]\n",
      "Confusion Matrix Test: \n",
      "[[589  31]\n",
      " [126 114]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_interleaved_olid_train_dev = np.concatenate((bert_bertweet_interleaved_olid_train, bert_bertweet_interleaved_olid_dev))\n",
    "bert_bertweet_interleaved_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_interleaved_olid_train_dev, bert_bertweet_interleaved_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_interleaved_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_interleaved_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_interleaved_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_interleaved_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7144824978392394\n",
      "Accuracy Test:  0.6861650485436893\n",
      "Weighted F1 Train Dev:  0.710997684497674\n",
      "Weighted F1 Test:  0.6829153382637936\n",
      "Macro F1 Train Dev:  0.7076229433581505\n",
      "Macro F1 Test:  0.6776138501209048\n",
      "Micro F1 Train Dev:  0.7144824978392394\n",
      "Micro F1 Test:  0.6861650485436893\n",
      "Weighted Recall Train Dev:  0.7144824978392394\n",
      "Weighted Recall Test:  0.6861650485436893\n",
      "Macro Recall Train Dev:  0.7069545862995652\n",
      "Macro Recall Test:  0.6766187276446456\n",
      "Micro Recall Train Dev:  0.7144824978392394\n",
      "Micro Recall Test:  0.6861650485436893\n",
      "Confusion Matrix Train Dev: \n",
      "[[10391  6726]\n",
      " [ 3845 16062]]\n",
      "Confusion Matrix Test: \n",
      "[[1078  774]\n",
      " [ 519 1749]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_interleaved_dynahate_train_dev = np.concatenate((bert_hatebert_interleaved_dynahate_train, bert_hatebert_interleaved_dynahate_dev))\n",
    "bert_hatebert_interleaved_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_interleaved_dynahate_train_dev, bert_hatebert_interleaved_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_interleaved_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_interleaved_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_interleaved_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_interleaved_dynahate_seed_42\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7148355058969584\n",
      "Accuracy Test:  0.6972067039106146\n",
      "Weighted F1 Train Dev:  0.6855581603234941\n",
      "Weighted F1 Test:  0.6641530693568959\n",
      "Macro F1 Train Dev:  0.5096210673617565\n",
      "Macro F1 Test:  0.47755254086379395\n",
      "Micro F1 Train Dev:  0.7148355058969585\n",
      "Micro F1 Test:  0.6972067039106146\n",
      "Weighted Recall Train Dev:  0.7148355058969584\n",
      "Weighted Recall Test:  0.6972067039106146\n",
      "Macro Recall Train Dev:  0.48832774625460357\n",
      "Macro Recall Test:  0.46271147912393346\n",
      "Micro Recall Train Dev:  0.7148355058969584\n",
      "Micro Recall Test:  0.6972067039106146\n",
      "Confusion Matrix Train Dev: \n",
      "[[9115  801   29]\n",
      " [2978 2305   64]\n",
      " [ 416  306   96]]\n",
      "Confusion Matrix Test: \n",
      "[[3040  289   17]\n",
      " [1052  679   22]\n",
      " [ 151   95   25]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_interleaved_latenthatred_train_dev = np.concatenate((bert_hatebert_interleaved_latenthatred_train, bert_hatebert_interleaved_latenthatred_dev))\n",
    "bert_hatebert_interleaved_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_interleaved_latenthatred_train_dev, bert_hatebert_interleaved_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_interleaved_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_interleaved_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_interleaved_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_interleaved_latenthatred_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7608006042296073\n",
      "Accuracy Test:  0.7965116279069767\n",
      "Weighted F1 Train Dev:  0.759814110894104\n",
      "Weighted F1 Test:  0.7834730123172956\n",
      "Macro F1 Train Dev:  0.7283031007528467\n",
      "Macro F1 Test:  0.7174106933295781\n",
      "Micro F1 Train Dev:  0.7608006042296073\n",
      "Micro F1 Test:  0.7965116279069767\n",
      "Weighted Recall Train Dev:  0.7608006042296073\n",
      "Weighted Recall Test:  0.7965116279069767\n",
      "Macro Recall Train Dev:  0.7265256067461949\n",
      "Macro Recall Test:  0.699260752688172\n",
      "Micro Recall Train Dev:  0.7608006042296073\n",
      "Micro Recall Test:  0.7965116279069767\n",
      "Confusion Matrix Train Dev: \n",
      "[[7326 1514]\n",
      " [1653 2747]]\n",
      "Confusion Matrix Test: \n",
      "[[570  50]\n",
      " [125 115]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_interleaved_olid_train_dev = np.concatenate((bert_hatebert_interleaved_olid_train, bert_hatebert_interleaved_olid_dev))\n",
    "bert_hatebert_interleaved_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_interleaved_olid_train_dev, bert_hatebert_interleaved_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_interleaved_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_interleaved_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_interleaved_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_interleaved_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7538623595505618\n",
      "Accuracy Test:  0.7007281553398058\n",
      "Weighted F1 Train Dev:  0.7529105823867874\n",
      "Weighted F1 Test:  0.7000286058655765\n",
      "Macro F1 Train Dev:  0.7508440778833396\n",
      "Macro F1 Test:  0.6963449023050772\n",
      "Micro F1 Train Dev:  0.7538623595505618\n",
      "Micro F1 Test:  0.7007281553398058\n",
      "Weighted Recall Train Dev:  0.7538623595505618\n",
      "Weighted Recall Test:  0.7007281553398058\n",
      "Macro Recall Train Dev:  0.7498263064513058\n",
      "Macro Recall Test:  0.6956895829286038\n",
      "Micro Recall Train Dev:  0.7538623595505618\n",
      "Micro Recall Test:  0.7007281553398058\n",
      "Confusion Matrix Train Dev: \n",
      "[[11918  5199]\n",
      " [ 3914 15993]]\n",
      "Confusion Matrix Test: \n",
      "[[1196  656]\n",
      " [ 577 1691]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_interleaved_dynahate_train_dev = np.concatenate((hatebert_bertweet_interleaved_dynahate_train, hatebert_bertweet_interleaved_dynahate_dev))\n",
    "hatebert_bertweet_interleaved_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_interleaved_dynahate_train_dev, hatebert_bertweet_interleaved_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_interleaved_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_interleaved_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_interleaved_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_interleaved_dynahate_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7394165114835506\n",
      "Accuracy Test:  0.7100558659217877\n",
      "Weighted F1 Train Dev:  0.7195510009103481\n",
      "Weighted F1 Test:  0.6874701121504219\n",
      "Macro F1 Train Dev:  0.5427116404396695\n",
      "Macro F1 Test:  0.5079223173799048\n",
      "Micro F1 Train Dev:  0.7394165114835506\n",
      "Micro F1 Test:  0.7100558659217877\n",
      "Weighted Recall Train Dev:  0.7394165114835506\n",
      "Weighted Recall Test:  0.7100558659217877\n",
      "Macro Recall Train Dev:  0.5200731641078138\n",
      "Macro Recall Test:  0.4889071584917131\n",
      "Micro Recall Train Dev:  0.7394165114835506\n",
      "Micro Recall Test:  0.7100558659217877\n",
      "Confusion Matrix Train Dev: \n",
      "[[8918 1008   19]\n",
      " [2397 2894   56]\n",
      " [ 330  388  100]]\n",
      "Confusion Matrix Test: \n",
      "[[2953  380   13]\n",
      " [ 902  830   21]\n",
      " [ 115  126   30]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_interleaved_latenthatred_train_dev = np.concatenate((hatebert_bertweet_interleaved_latenthatred_train, hatebert_bertweet_interleaved_latenthatred_dev))\n",
    "hatebert_bertweet_interleaved_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_interleaved_latenthatred_train_dev, hatebert_bertweet_interleaved_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_interleaved_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_interleaved_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_interleaved_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_interleaved_latenthatred_seed_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7757552870090635\n",
      "Accuracy Test:  0.7953488372093023\n",
      "Weighted F1 Train Dev:  0.7627573809101216\n",
      "Weighted F1 Test:  0.7760572900491423\n",
      "Macro F1 Train Dev:  0.721564873358871\n",
      "Macro F1 Test:  0.7027494108405341\n",
      "Micro F1 Train Dev:  0.7757552870090636\n",
      "Micro F1 Test:  0.7953488372093023\n",
      "Weighted Recall Train Dev:  0.7757552870090635\n",
      "Weighted Recall Test:  0.7953488372093023\n",
      "Macro Recall Train Dev:  0.7073606540518305\n",
      "Macro Recall Test:  0.6818548387096774\n",
      "Micro Recall Train Dev:  0.7757552870090635\n",
      "Micro Recall Test:  0.7953488372093023\n",
      "Confusion Matrix Train Dev: \n",
      "[[8056  784]\n",
      " [2185 2215]]\n",
      "Confusion Matrix Test: \n",
      "[[582  38]\n",
      " [138 102]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_interleaved_olid_train_dev = np.concatenate((hatebert_bertweet_interleaved_olid_train, hatebert_bertweet_interleaved_olid_dev))\n",
    "hatebert_bertweet_interleaved_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_interleaved_olid_train_dev, hatebert_bertweet_interleaved_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_interleaved_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_interleaved_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_interleaved_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_interleaved_olid_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7628835350043215\n",
      "Accuracy Test:  0.7182038834951456\n",
      "Weighted F1 Train Dev:  0.7606924889403566\n",
      "Weighted F1 Test:  0.7156599759171588\n",
      "Macro F1 Train Dev:  0.7581400803731488\n",
      "Macro F1 Test:  0.711078739759399\n",
      "Micro F1 Train Dev:  0.7628835350043215\n",
      "Micro F1 Test:  0.7182038834951456\n",
      "Weighted Recall Train Dev:  0.7628835350043215\n",
      "Weighted Recall Test:  0.7182038834951456\n",
      "Macro Recall Train Dev:  0.7566268693034224\n",
      "Macro Recall Test:  0.7095818048841807\n",
      "Micro Recall Train Dev:  0.7628835350043215\n",
      "Micro Recall Test:  0.7182038834951456\n",
      "Confusion Matrix Train Dev: \n",
      "[[11530  5587]\n",
      " [ 3192 16715]]\n",
      "Confusion Matrix Test: \n",
      "[[1156  696]\n",
      " [ 465 1803]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_interleaved_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_interleaved_dynahate_train, bert_hatebert_bertweet_interleaved_dynahate_dev))\n",
    "bert_bertweet_hatebert_interleaved_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_interleaved_dynahate_train_dev, bert_bertweet_hatebert_interleaved_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_interleaved_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_interleaved_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_interleaved_dynahate_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_interleaved_dynahate_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7129733085040347\n",
      "Accuracy Test:  0.6893854748603352\n",
      "Weighted F1 Train Dev:  0.6895555792164443\n",
      "Weighted F1 Test:  0.6636341837855085\n",
      "Macro F1 Train Dev:  0.4836559644927296\n",
      "Macro F1 Test:  0.4541776833515045\n",
      "Micro F1 Train Dev:  0.7129733085040346\n",
      "Micro F1 Test:  0.6893854748603352\n",
      "Weighted Recall Train Dev:  0.7129733085040347\n",
      "Weighted Recall Test:  0.6893854748603352\n",
      "Macro Recall Train Dev:  0.47831614403968237\n",
      "Macro Recall Test:  0.4522563496184057\n",
      "Micro Recall Train Dev:  0.7129733085040347\n",
      "Micro Recall Test:  0.6893854748603352\n",
      "Confusion Matrix Train Dev: \n",
      "[[8655 1276   14]\n",
      " [2542 2797    8]\n",
      " [ 353  431   34]]\n",
      "Confusion Matrix Test: \n",
      "[[2872  469    5]\n",
      " [ 929  822    2]\n",
      " [ 126  137    8]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_interleaved_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_interleaved_latenthatred_train, bert_hatebert_bertweet_interleaved_latenthatred_dev))\n",
    "bert_bertweet_hatebert_interleaved_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_interleaved_latenthatred_train_dev, bert_bertweet_hatebert_interleaved_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_interleaved_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_interleaved_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_interleaved_latenthatred_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_interleaved_latenthatred_seed_42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7828549848942599\n",
      "Accuracy Test:  0.8104651162790698\n",
      "Weighted F1 Train Dev:  0.7784488909786428\n",
      "Weighted F1 Test:  0.7965976255054642\n",
      "Macro F1 Train Dev:  0.74600601040594\n",
      "Macro F1 Test:  0.7331079087106436\n",
      "Micro F1 Train Dev:  0.7828549848942599\n",
      "Micro F1 Test:  0.8104651162790698\n",
      "Weighted Recall Train Dev:  0.7828549848942599\n",
      "Weighted Recall Test:  0.8104651162790698\n",
      "Macro Recall Train Dev:  0.7381329699712053\n",
      "Macro Recall Test:  0.7114919354838709\n",
      "Micro Recall Train Dev:  0.7828549848942599\n",
      "Micro Recall Test:  0.8104651162790698\n",
      "Confusion Matrix Train Dev: \n",
      "[[7704 1136]\n",
      " [1739 2661]]\n",
      "Confusion Matrix Test: \n",
      "[[580  40]\n",
      " [123 117]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_interleaved_olid_train_dev = np.concatenate((bert_hatebert_bertweet_interleaved_olid_train, bert_hatebert_bertweet_interleaved_olid_dev))\n",
    "bert_bertweet_hatebert_interleaved_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_interleaved_olid_train_dev, bert_bertweet_hatebert_interleaved_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_interleaved_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_interleaved_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_interleaved_olid_seed_42\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_interleaved_olid_seed_42\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
