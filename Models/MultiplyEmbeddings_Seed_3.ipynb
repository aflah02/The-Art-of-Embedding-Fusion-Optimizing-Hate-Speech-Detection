{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 3\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaling_embeddings(embeddings):\n",
    "#     for i in range(len(embeddings)):\n",
    "#         embeddings[i] = StandardScaler().fit_transform(embeddings[i])\n",
    "#     return embeddings\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    if embeddings.shape[1] == 1:\n",
    "        embeddings = embeddings.squeeze(1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_2_embeddings(embeddings1, embeddings2):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    # Numpy multiplication\n",
    "    return np.multiply(embeddings1, embeddings2)\n",
    "\n",
    "def multiply_3_embeddings(embeddings1, embeddings2, embeddings3):\n",
    "    embeddings1 = reshape_embeddings(embeddings1)\n",
    "    embeddings2 = reshape_embeddings(embeddings2)\n",
    "    embeddings3 = reshape_embeddings(embeddings3)\n",
    "    # Numpy multiplication\n",
    "    return np.multiply(embeddings1, np.multiply(embeddings2, embeddings3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hatebert_multiplied_dynahate_train = multiply_2_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings)\n",
    "bert_hatebert_multiplied_dynahate_dev = multiply_2_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings)\n",
    "bert_hatebert_multiplied_dynahate_test = multiply_2_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_dynahate_train = multiply_2_embeddings(bert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_bertweet_multiplied_dynahate_dev = multiply_2_embeddings(bert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_bertweet_multiplied_dynahate_test = multiply_2_embeddings(bert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_dynahate_train = multiply_2_embeddings(hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "hatebert_bertweet_multiplied_dynahate_dev = multiply_2_embeddings(hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_dynahate_test = multiply_2_embeddings(hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_dynahate_train = multiply_3_embeddings(bert_dynahate_train_embeddings, hatebert_dynahate_train_embeddings, bertweet_dynahate_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_dynahate_dev = multiply_3_embeddings(bert_dynahate_dev_embeddings, hatebert_dynahate_dev_embeddings, bertweet_dynahate_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_dynahate_test = multiply_3_embeddings(bert_dynahate_test_embeddings, hatebert_dynahate_test_embeddings, bertweet_dynahate_test_embeddings)\n",
    "\n",
    "bert_hatebert_multiplied_olid_train = multiply_2_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings)\n",
    "bert_hatebert_multiplied_olid_dev = multiply_2_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings)\n",
    "bert_hatebert_multiplied_olid_test = multiply_2_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_olid_train = multiply_2_embeddings(bert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_bertweet_multiplied_olid_dev = multiply_2_embeddings(bert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_bertweet_multiplied_olid_test = multiply_2_embeddings(bert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_olid_train = multiply_2_embeddings(hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "hatebert_bertweet_multiplied_olid_dev = multiply_2_embeddings(hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_olid_test = multiply_2_embeddings(hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_olid_train = multiply_3_embeddings(bert_olid_train_embeddings, hatebert_olid_train_embeddings, bertweet_olid_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_olid_dev = multiply_3_embeddings(bert_olid_dev_embeddings, hatebert_olid_dev_embeddings, bertweet_olid_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_olid_test = multiply_3_embeddings(bert_olid_test_embeddings, hatebert_olid_test_embeddings, bertweet_olid_test_embeddings)\n",
    "\n",
    "bert_hatebert_multiplied_latenthatred_train = multiply_2_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings)\n",
    "bert_hatebert_multiplied_latenthatred_dev = multiply_2_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings)\n",
    "bert_hatebert_multiplied_latenthatred_test = multiply_2_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings)\n",
    "\n",
    "bert_bertweet_multiplied_latenthatred_train = multiply_2_embeddings(bert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_bertweet_multiplied_latenthatred_dev = multiply_2_embeddings(bert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_bertweet_multiplied_latenthatred_test = multiply_2_embeddings(bert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "hatebert_bertweet_multiplied_latenthatred_train = multiply_2_embeddings(hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "hatebert_bertweet_multiplied_latenthatred_dev = multiply_2_embeddings(hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "hatebert_bertweet_multiplied_latenthatred_test = multiply_2_embeddings(hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)\n",
    "\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_train = multiply_3_embeddings(bert_latenthatred_train_embeddings, hatebert_latenthatred_train_embeddings, bertweet_latenthatred_train_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_dev = multiply_3_embeddings(bert_latenthatred_dev_embeddings, hatebert_latenthatred_dev_embeddings, bertweet_latenthatred_dev_embeddings)\n",
    "bert_hatebert_bertweet_multiplied_latenthatred_test = multiply_3_embeddings(bert_latenthatred_test_embeddings, hatebert_latenthatred_test_embeddings, bertweet_latenthatred_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train = process_labels(read_labels(\"dynahate\", \"train\"))\n",
    "dynahate_labels_dev = process_labels(read_labels(\"dynahate\", \"dev\"))\n",
    "dynahate_labels_test = process_labels(read_labels(\"dynahate\", \"test\"))\n",
    "\n",
    "latenthatred_labels_train = read_labels(\"latenthatred\", \"train\")\n",
    "latenthatred_labels_dev = read_labels(\"latenthatred\", \"dev\")\n",
    "latenthatred_labels_test = read_labels(\"latenthatred\", \"test\")\n",
    "\n",
    "olid_labels_train = read_labels(\"olid\", \"train\")\n",
    "olid_labels_dev = read_labels(\"olid\", \"dev\")\n",
    "olid_labels_test = read_labels(\"olid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=3)\n",
    "gridsearch = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(128), (128,64)],\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"solver\": [\"adam\"],\n",
    "        \"learning_rate_init\": [0.001, 0.0001],\n",
    "        \"learning_rate\": [\"adaptive\"],\n",
    "        \"early_stopping\": [True],\n",
    "        \"max_iter\": [10000]\n",
    "    },\n",
    "    verbose=4,\n",
    "    n_jobs=os.cpu_count()//3,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7207216940363008\n",
      "Accuracy Test:  0.6725728155339806\n",
      "Weighted F1 Train Dev:  0.7172236453112285\n",
      "Weighted F1 Test:  0.6679441853562256\n",
      "Macro F1 Train Dev:  0.7138927388460574\n",
      "Macro F1 Test:  0.6618700208327364\n",
      "Micro F1 Train Dev:  0.7207216940363008\n",
      "Micro F1 Test:  0.6725728155339806\n",
      "Weighted Recall Train Dev:  0.7207216940363008\n",
      "Weighted Recall Test:  0.6725728155339806\n",
      "Macro Recall Train Dev:  0.7131291134141228\n",
      "Macro Recall Test:  0.6613513776040774\n",
      "Micro Recall Train Dev:  0.7207216940363008\n",
      "Micro Recall Test:  0.6725728155339806\n",
      "Confusion Matrix Train Dev: \n",
      "[[10482  6635]\n",
      " [ 3705 16202]]\n",
      "Confusion Matrix Test: \n",
      "[[1019  833]\n",
      " [ 516 1752]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_dynahate_train_dev = np.concatenate((bert_bertweet_multiplied_dynahate_train, bert_bertweet_multiplied_dynahate_dev))\n",
    "bert_bertweet_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_dynahate_train_dev, bert_bertweet_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_multiplied_dynahate_seed_3\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_dynahate_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7608317815021726\n",
      "Accuracy Test:  0.7014897579143389\n",
      "Weighted F1 Train Dev:  0.7403282603721897\n",
      "Weighted F1 Test:  0.6792742171171294\n",
      "Macro F1 Train Dev:  0.5484093137663972\n",
      "Macro F1 Test:  0.4818478077700079\n",
      "Micro F1 Train Dev:  0.7608317815021727\n",
      "Micro F1 Test:  0.7014897579143389\n",
      "Weighted Recall Train Dev:  0.7608317815021726\n",
      "Weighted Recall Test:  0.7014897579143389\n",
      "Macro Recall Train Dev:  0.5295800808680616\n",
      "Macro Recall Test:  0.4723918378029015\n",
      "Micro Recall Train Dev:  0.7608317815021726\n",
      "Micro Recall Test:  0.7014897579143389\n",
      "Confusion Matrix Train Dev: \n",
      "[[9023  916    6]\n",
      " [2172 3160   15]\n",
      " [ 335  409   74]]\n",
      "Confusion Matrix Test: \n",
      "[[2878  467    1]\n",
      " [ 867  873   13]\n",
      " [ 122  133   16]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_latenthatred_train_dev = np.concatenate((bert_bertweet_multiplied_latenthatred_train, bert_bertweet_multiplied_latenthatred_dev))\n",
    "bert_bertweet_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_latenthatred_train_dev, bert_bertweet_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_multiplied_latenthatred_seed_3\")\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_latenthatred_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7691842900302115\n",
      "Accuracy Test:  0.7941860465116279\n",
      "Weighted F1 Train Dev:  0.7522585133554481\n",
      "Weighted F1 Test:  0.768650489389287\n",
      "Macro F1 Train Dev:  0.70698715887596\n",
      "Macro F1 Test:  0.6884561777654068\n",
      "Micro F1 Train Dev:  0.7691842900302115\n",
      "Micro F1 Test:  0.7941860465116279\n",
      "Weighted Recall Train Dev:  0.7691842900302115\n",
      "Weighted Recall Test:  0.7941860465116279\n",
      "Macro Recall Train Dev:  0.6925658165364048\n",
      "Macro Recall Test:  0.667002688172043\n",
      "Micro Recall Train Dev:  0.7691842900302115\n",
      "Micro Recall Test:  0.7941860465116279\n",
      "Confusion Matrix Train Dev: \n",
      "[[8142  698]\n",
      " [2358 2042]]\n",
      "Confusion Matrix Test: \n",
      "[[592  28]\n",
      " [149  91]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_multiplied_olid_train_dev = np.concatenate((bert_bertweet_multiplied_olid_train, bert_bertweet_multiplied_olid_dev))\n",
    "bert_bertweet_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_multiplied_olid_train_dev, bert_bertweet_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_multiplied_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_multiplied_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-HateBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7281763180639585\n",
      "Accuracy Test:  0.6849514563106797\n",
      "Weighted F1 Train Dev:  0.7271756229432083\n",
      "Weighted F1 Test:  0.6839314715619538\n",
      "Macro F1 Train Dev:  0.7249204214998373\n",
      "Macro F1 Test:  0.6798515325670499\n",
      "Micro F1 Train Dev:  0.7281763180639587\n",
      "Micro F1 Test:  0.6849514563106797\n",
      "Weighted Recall Train Dev:  0.7281763180639585\n",
      "Weighted Recall Test:  0.6849514563106797\n",
      "Macro Recall Train Dev:  0.7240897784677133\n",
      "Macro Recall Test:  0.6791313837750123\n",
      "Micro Recall Train Dev:  0.7281763180639585\n",
      "Micro Recall Test:  0.6849514563106797\n",
      "Confusion Matrix Train Dev: \n",
      "[[11466  5651]\n",
      " [ 4413 15494]]\n",
      "Confusion Matrix Test: \n",
      "[[1151  701]\n",
      " [ 597 1671]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_dynahate_train_dev = np.concatenate((bert_hatebert_multiplied_dynahate_train, bert_hatebert_multiplied_dynahate_dev))\n",
    "bert_hatebert_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_dynahate_train_dev, bert_hatebert_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_hatebert_multiplied_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_dynahate_seed_3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7145872129112353\n",
      "Accuracy Test:  0.6912476722532589\n",
      "Weighted F1 Train Dev:  0.6911839326795488\n",
      "Weighted F1 Test:  0.6670442950795114\n",
      "Macro F1 Train Dev:  0.47341644492270235\n",
      "Macro F1 Test:  0.4481639257107363\n",
      "Micro F1 Train Dev:  0.7145872129112353\n",
      "Micro F1 Test:  0.6912476722532589\n",
      "Weighted Recall Train Dev:  0.7145872129112353\n",
      "Weighted Recall Test:  0.6912476722532589\n",
      "Macro Recall Train Dev:  0.4755118645083974\n",
      "Macro Recall Test:  0.45257969260344916\n",
      "Micro Recall Train Dev:  0.7145872129112353\n",
      "Micro Recall Test:  0.6912476722532589\n",
      "Confusion Matrix Train Dev: \n",
      "[[8581 1357    7]\n",
      " [2431 2916    0]\n",
      " [ 355  448   15]]\n",
      "Confusion Matrix Test: \n",
      "[[2832  513    1]\n",
      " [ 875  877    1]\n",
      " [ 123  145    3]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_latenthatred_train_dev = np.concatenate((bert_hatebert_multiplied_latenthatred_train, bert_hatebert_multiplied_latenthatred_dev))\n",
    "bert_hatebert_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_latenthatred_train_dev, bert_hatebert_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_hatebert_multiplied_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_latenthatred_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7589123867069486\n",
      "Accuracy Test:  0.8034883720930233\n",
      "Weighted F1 Train Dev:  0.7416240701350088\n",
      "Weighted F1 Test:  0.7797030464467334\n",
      "Macro F1 Train Dev:  0.6946472490949764\n",
      "Macro F1 Test:  0.7037499057274883\n",
      "Micro F1 Train Dev:  0.7589123867069486\n",
      "Micro F1 Test:  0.8034883720930233\n",
      "Weighted Recall Train Dev:  0.7589123867069486\n",
      "Weighted Recall Test:  0.8034883720930233\n",
      "Macro Recall Train Dev:  0.6817343685726038\n",
      "Macro Recall Test:  0.6798387096774194\n",
      "Micro Recall Train Dev:  0.7589123867069486\n",
      "Micro Recall Test:  0.8034883720930233\n",
      "Confusion Matrix Train Dev: \n",
      "[[8061  779]\n",
      " [2413 1987]]\n",
      "Confusion Matrix Test: \n",
      "[[595  25]\n",
      " [144  96]]\n"
     ]
    }
   ],
   "source": [
    "bert_hatebert_multiplied_olid_train_dev = np.concatenate((bert_hatebert_multiplied_olid_train, bert_hatebert_multiplied_olid_dev))\n",
    "bert_hatebert_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_hatebert_multiplied_olid_train_dev, bert_hatebert_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_hatebert_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_hatebert_multiplied_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_hatebert_multiplied_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7797104580812446\n",
      "Accuracy Test:  0.6747572815533981\n",
      "Weighted F1 Train Dev:  0.7799097162471168\n",
      "Weighted F1 Test:  0.6755110563004881\n",
      "Macro F1 Train Dev:  0.7789025961696104\n",
      "Macro F1 Test:  0.6733334848088947\n",
      "Micro F1 Train Dev:  0.7797104580812446\n",
      "Micro F1 Test:  0.6747572815533981\n",
      "Weighted Recall Train Dev:  0.7797104580812446\n",
      "Weighted Recall Test:  0.6747572815533981\n",
      "Macro Recall Train Dev:  0.779582301964226\n",
      "Macro Recall Test:  0.6749726688531584\n",
      "Micro Recall Train Dev:  0.7797104580812446\n",
      "Micro Recall Test:  0.6747572815533981\n",
      "Confusion Matrix Train Dev: \n",
      "[[13315  3802]\n",
      " [ 4354 15553]]\n",
      "Confusion Matrix Test: \n",
      "[[1254  598]\n",
      " [ 742 1526]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_dynahate_train_dev = np.concatenate((hatebert_bertweet_multiplied_dynahate_train, hatebert_bertweet_multiplied_dynahate_dev))\n",
    "hatebert_bertweet_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_dynahate_train_dev, hatebert_bertweet_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/hatebert_bertweet_multiplied_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_dynahate_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7238361266294228\n",
      "Accuracy Test:  0.7003724394785847\n",
      "Weighted F1 Train Dev:  0.702564221741285\n",
      "Weighted F1 Test:  0.6765114491858124\n",
      "Macro F1 Train Dev:  0.5168166280174501\n",
      "Macro F1 Test:  0.4883063689144597\n",
      "Micro F1 Train Dev:  0.7238361266294228\n",
      "Micro F1 Test:  0.7003724394785847\n",
      "Weighted Recall Train Dev:  0.7238361266294228\n",
      "Weighted Recall Test:  0.7003724394785847\n",
      "Macro Recall Train Dev:  0.499745510280051\n",
      "Macro Recall Test:  0.4737784289938602\n",
      "Micro Recall Train Dev:  0.7238361266294228\n",
      "Micro Recall Test:  0.7003724394785847\n",
      "Confusion Matrix Train Dev: \n",
      "[[8781 1139   25]\n",
      " [2506 2805   36]\n",
      " [ 358  385   75]]\n",
      "Confusion Matrix Test: \n",
      "[[2919  419    8]\n",
      " [ 919  820   14]\n",
      " [ 128  121   22]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_latenthatred_train_dev = np.concatenate((hatebert_bertweet_multiplied_latenthatred_train, hatebert_bertweet_multiplied_latenthatred_dev))\n",
    "hatebert_bertweet_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_latenthatred_train_dev, hatebert_bertweet_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/hatebert_bertweet_multiplied_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_latenthatred_seed_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.763821752265861\n",
      "Accuracy Test:  0.8023255813953488\n",
      "Weighted F1 Train Dev:  0.7533884257546595\n",
      "Weighted F1 Test:  0.7885482734319943\n",
      "Macro F1 Train Dev:  0.7127889781562944\n",
      "Macro F1 Test:  0.7231060606060605\n",
      "Micro F1 Train Dev:  0.763821752265861\n",
      "Micro F1 Test:  0.8023255813953488\n",
      "Weighted Recall Train Dev:  0.763821752265861\n",
      "Weighted Recall Test:  0.8023255813953488\n",
      "Macro Recall Train Dev:  0.7013348416289593\n",
      "Macro Recall Test:  0.7032930107526881\n",
      "Micro Recall Train Dev:  0.763821752265861\n",
      "Micro Recall Test:  0.8023255813953488\n",
      "Confusion Matrix Train Dev: \n",
      "[[7847  993]\n",
      " [2134 2266]]\n",
      "Confusion Matrix Test: \n",
      "[[575  45]\n",
      " [125 115]]\n"
     ]
    }
   ],
   "source": [
    "hatebert_bertweet_multiplied_olid_train_dev = np.concatenate((hatebert_bertweet_multiplied_olid_train, hatebert_bertweet_multiplied_olid_dev))\n",
    "hatebert_bertweet_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(hatebert_bertweet_multiplied_olid_train_dev, hatebert_bertweet_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(hatebert_bertweet_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(hatebert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/hatebert_bertweet_multiplied_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/hatebert_bertweet_multiplied_olid_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-BERTweet-HateBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DynaHate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 128, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7270959377700951\n",
      "Accuracy Test:  0.6774271844660195\n",
      "Weighted F1 Train Dev:  0.725883298257661\n",
      "Weighted F1 Test:  0.6764902469967116\n",
      "Macro F1 Train Dev:  0.7235107426898552\n",
      "Macro F1 Test:  0.6723874471311105\n",
      "Micro F1 Train Dev:  0.7270959377700952\n",
      "Micro F1 Test:  0.6774271844660195\n",
      "Weighted Recall Train Dev:  0.7270959377700951\n",
      "Weighted Recall Test:  0.6774271844660195\n",
      "Macro Recall Train Dev:  0.7226183983718484\n",
      "Macro Recall Test:  0.6717524502801681\n",
      "Micro Recall Train Dev:  0.7270959377700951\n",
      "Micro Recall Test:  0.6774271844660195\n",
      "Confusion Matrix Train Dev: \n",
      "[[11352  5765]\n",
      " [ 4339 15568]]\n",
      "Confusion Matrix Test: \n",
      "[[1140  712]\n",
      " [ 617 1651]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_dynahate_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_dynahate_train, bert_hatebert_bertweet_multiplied_dynahate_dev))\n",
    "bert_bertweet_hatebert_multiplied_dynahate_labels_train_dev = np.concatenate((dynahate_labels_train, dynahate_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_dynahate_train_dev, bert_bertweet_hatebert_multiplied_dynahate_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_dynahate_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_dynahate_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, dynahate_labels_train_dev, dynahate_labels_test, \"Results/bert_bertweet_hatebert_multiplied_dynahate_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_dynahate_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentHatred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.7741154562383613\n",
      "Accuracy Test:  0.7050279329608938\n",
      "Weighted F1 Train Dev:  0.7591855032503969\n",
      "Weighted F1 Test:  0.6863747011319468\n",
      "Macro F1 Train Dev:  0.6050209277965567\n",
      "Macro F1 Test:  0.5124896475292248\n",
      "Micro F1 Train Dev:  0.7741154562383613\n",
      "Micro F1 Test:  0.7050279329608938\n",
      "Weighted Recall Train Dev:  0.7741154562383613\n",
      "Weighted Recall Test:  0.7050279329608938\n",
      "Macro Recall Train Dev:  0.5709637108896708\n",
      "Macro Recall Test:  0.4936358640621181\n",
      "Micro Recall Train Dev:  0.7741154562383613\n",
      "Micro Recall Test:  0.7050279329608938\n",
      "Confusion Matrix Train Dev: \n",
      "[[9044  883   18]\n",
      " [2038 3270   39]\n",
      " [ 280  381  157]]\n",
      "Confusion Matrix Test: \n",
      "[[2890  439   17]\n",
      " [ 862  862   29]\n",
      " [ 108  129   34]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_latenthatred_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_latenthatred_train, bert_hatebert_bertweet_multiplied_latenthatred_dev))\n",
    "bert_bertweet_hatebert_multiplied_latenthatred_labels_train_dev = np.concatenate((latenthatred_labels_train, latenthatred_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_latenthatred_train_dev, bert_bertweet_hatebert_multiplied_latenthatred_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_latenthatred_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_latenthatred_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, latenthatred_labels_train_dev, latenthatred_labels_test, \"Results/bert_bertweet_hatebert_multiplied_latenthatred_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_latenthatred_seed_3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best params:  {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 10000, 'solver': 'adam'}\n",
      "Accuracy Train Dev:  0.8029456193353475\n",
      "Accuracy Test:  0.7930232558139535\n",
      "Weighted F1 Train Dev:  0.7953743350133985\n",
      "Weighted F1 Test:  0.7756326213530721\n",
      "Macro F1 Train Dev:  0.7625136288653499\n",
      "Macro F1 Test:  0.703801739884214\n",
      "Micro F1 Train Dev:  0.8029456193353475\n",
      "Micro F1 Test:  0.7930232558139535\n",
      "Weighted Recall Train Dev:  0.8029456193353475\n",
      "Weighted Recall Test:  0.7930232558139535\n",
      "Macro Recall Train Dev:  0.748783422459893\n",
      "Macro Recall Test:  0.6840725806451613\n",
      "Micro Recall Train Dev:  0.8029456193353475\n",
      "Micro Recall Test:  0.7930232558139535\n",
      "Confusion Matrix Train Dev: \n",
      "[[8047  793]\n",
      " [1816 2584]]\n",
      "Confusion Matrix Test: \n",
      "[[577  43]\n",
      " [135 105]]\n"
     ]
    }
   ],
   "source": [
    "bert_bertweet_hatebert_multiplied_olid_train_dev = np.concatenate((bert_hatebert_bertweet_multiplied_olid_train, bert_hatebert_bertweet_multiplied_olid_dev))\n",
    "bert_bertweet_hatebert_multiplied_olid_labels_train_dev = np.concatenate((olid_labels_train, olid_labels_dev))\n",
    "\n",
    "grid_results = gridsearch.fit(bert_bertweet_hatebert_multiplied_olid_train_dev, bert_bertweet_hatebert_multiplied_olid_labels_train_dev)\n",
    "\n",
    "best_params = grid_results.best_params_\n",
    "mlp = grid_results.best_estimator_\n",
    "\n",
    "print(\"Best params: \", best_params)\n",
    "\n",
    "train_dev_preds = mlp.predict(bert_bertweet_hatebert_multiplied_olid_train_dev)\n",
    "test_preds = mlp.predict(bert_hatebert_bertweet_multiplied_olid_test)\n",
    "\n",
    "computeAllScores(train_dev_preds, test_preds, olid_labels_train_dev, olid_labels_test, \"Results/bert_bertweet_hatebert_multiplied_olid_seed_3\")\n",
    "\n",
    "save_model(mlp, \"Saves/bert_bertweet_hatebert_multiplied_olid_seed_3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
